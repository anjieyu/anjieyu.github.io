<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>98de74fe15e745cfbdeb8c3a4d687203</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="cell code" data-execution_count="1">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OneHotEncoder</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> Normalizer</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="2">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">&#39;DogBreeds.csv&#39;</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>df</span></code></pre></div>
<div class="output execute_result" data-execution_count="2">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Origin</th>
      <th>Type</th>
      <th>Unique Feature</th>
      <th>Friendly Rating (1-10)</th>
      <th>Life Span</th>
      <th>Size</th>
      <th>Grooming Needs</th>
      <th>Exercise Requirements (hrs/day)</th>
      <th>Good with Children</th>
      <th>Intelligence Rating (1-10)</th>
      <th>Shedding Level</th>
      <th>Health Issues Risk</th>
      <th>Average Weight (kg)</th>
      <th>Training Difficulty (1-10)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Affenpinscher</td>
      <td>Germany</td>
      <td>Toy</td>
      <td>Monkey-like face</td>
      <td>7</td>
      <td>14</td>
      <td>Small</td>
      <td>High</td>
      <td>1.5</td>
      <td>Yes</td>
      <td>8</td>
      <td>Moderate</td>
      <td>Low</td>
      <td>4.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Afghan Hound</td>
      <td>Afghanistan</td>
      <td>Hound</td>
      <td>Long silky coat</td>
      <td>5</td>
      <td>13</td>
      <td>Large</td>
      <td>Very High</td>
      <td>2.0</td>
      <td>No</td>
      <td>4</td>
      <td>High</td>
      <td>Moderate</td>
      <td>25.0</td>
      <td>8</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Airedale Terrier</td>
      <td>England</td>
      <td>Terrier</td>
      <td>Largest of terriers</td>
      <td>8</td>
      <td>12</td>
      <td>Medium</td>
      <td>High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>7</td>
      <td>Moderate</td>
      <td>Low</td>
      <td>21.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Akita</td>
      <td>Japan</td>
      <td>Working</td>
      <td>Strong loyalty</td>
      <td>6</td>
      <td>11</td>
      <td>Large</td>
      <td>Moderate</td>
      <td>2.0</td>
      <td>With Training</td>
      <td>7</td>
      <td>High</td>
      <td>High</td>
      <td>45.0</td>
      <td>9</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Alaskan Malamute</td>
      <td>Alaska USA</td>
      <td>Working</td>
      <td>Strong pulling ability</td>
      <td>7</td>
      <td>11</td>
      <td>Large</td>
      <td>High</td>
      <td>3.0</td>
      <td>Yes</td>
      <td>6</td>
      <td>Very High</td>
      <td>Moderate</td>
      <td>36.0</td>
      <td>8</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>154</th>
      <td>Wire Fox Terrier</td>
      <td>England</td>
      <td>Terrier</td>
      <td>Energetic</td>
      <td>7</td>
      <td>14</td>
      <td>Small</td>
      <td>Moderate</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>7</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>8.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>155</th>
      <td>Wirehaired Dachshund</td>
      <td>Germany</td>
      <td>Hound</td>
      <td>Wiry coat</td>
      <td>7</td>
      <td>13</td>
      <td>Small</td>
      <td>Moderate</td>
      <td>1.5</td>
      <td>With Training</td>
      <td>7</td>
      <td>Moderate</td>
      <td>High</td>
      <td>8.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>156</th>
      <td>Wirehaired Pointing Griffon</td>
      <td>Netherlands</td>
      <td>Sporting</td>
      <td>Shaggy beard</td>
      <td>7</td>
      <td>13</td>
      <td>Medium</td>
      <td>High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>7</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>20.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>157</th>
      <td>Xoloitzcuintli</td>
      <td>Mexico</td>
      <td>Non-Sporting</td>
      <td>Hairless variety</td>
      <td>7</td>
      <td>15</td>
      <td>Small-Large</td>
      <td>Low</td>
      <td>2.0</td>
      <td>With Training</td>
      <td>8</td>
      <td>Low</td>
      <td>Moderate</td>
      <td>25.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>158</th>
      <td>Yorkshire Terrier</td>
      <td>England</td>
      <td>Toy</td>
      <td>Long silky coat</td>
      <td>8</td>
      <td>13</td>
      <td>Toy</td>
      <td>High</td>
      <td>1.0</td>
      <td>Yes</td>
      <td>7</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>2.5</td>
      <td>6</td>
    </tr>
  </tbody>
</table>
<p>159 rows × 15 columns</p>
</div>
</div>
</div>
<div class="cell markdown">
<ul>
<li><p>Friendly rating</p></li>
<li><p>Training difficulty</p></li>
<li><p>Intelligence</p></li>
<li><p>Lifespan</p></li>
<li><p>Size</p></li>
</ul>
</div>
<div class="cell code" data-execution_count="3">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>grouped_df <span class="op">=</span> df.groupby(<span class="st">&#39;Size&#39;</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>grouped_df.get_group(<span class="st">&#39;Medium&#39;</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>grouped_sizecounts <span class="op">=</span> df.groupby(<span class="st">&#39;Size&#39;</span>).count().select_dtypes(<span class="st">&#39;int&#39;</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>grouped_sizecounts</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">#df.plot(x=&#39;Size&#39;, y=&#39;Life Span&#39;, kind=&#39;bar&#39;)</span></span></code></pre></div>
<div class="output execute_result" data-execution_count="3">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Origin</th>
      <th>Type</th>
      <th>Unique Feature</th>
      <th>Friendly Rating (1-10)</th>
      <th>Life Span</th>
      <th>Grooming Needs</th>
      <th>Exercise Requirements (hrs/day)</th>
      <th>Good with Children</th>
      <th>Intelligence Rating (1-10)</th>
      <th>Shedding Level</th>
      <th>Health Issues Risk</th>
      <th>Average Weight (kg)</th>
      <th>Training Difficulty (1-10)</th>
    </tr>
    <tr>
      <th>Size</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Giant</th>
      <td>7</td>
      <td>7</td>
      <td>7</td>
      <td>7</td>
      <td>7</td>
      <td>7</td>
      <td>7</td>
      <td>7</td>
      <td>7</td>
      <td>7</td>
      <td>7</td>
      <td>7</td>
      <td>7</td>
      <td>7</td>
    </tr>
    <tr>
      <th>Large</th>
      <td>42</td>
      <td>42</td>
      <td>42</td>
      <td>42</td>
      <td>42</td>
      <td>42</td>
      <td>42</td>
      <td>42</td>
      <td>42</td>
      <td>42</td>
      <td>42</td>
      <td>42</td>
      <td>42</td>
      <td>42</td>
    </tr>
    <tr>
      <th>Medium</th>
      <td>56</td>
      <td>56</td>
      <td>56</td>
      <td>56</td>
      <td>56</td>
      <td>56</td>
      <td>56</td>
      <td>56</td>
      <td>56</td>
      <td>56</td>
      <td>56</td>
      <td>56</td>
      <td>56</td>
      <td>56</td>
    </tr>
    <tr>
      <th>Small</th>
      <td>44</td>
      <td>44</td>
      <td>44</td>
      <td>44</td>
      <td>44</td>
      <td>44</td>
      <td>44</td>
      <td>44</td>
      <td>44</td>
      <td>44</td>
      <td>44</td>
      <td>44</td>
      <td>44</td>
      <td>44</td>
    </tr>
    <tr>
      <th>Small-Large</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Small-Medium</th>
      <td>6</td>
      <td>6</td>
      <td>6</td>
      <td>6</td>
      <td>6</td>
      <td>6</td>
      <td>6</td>
      <td>6</td>
      <td>6</td>
      <td>6</td>
      <td>6</td>
      <td>6</td>
      <td>6</td>
      <td>6</td>
    </tr>
    <tr>
      <th>Toy</th>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell code" data-execution_count="4">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>sizes <span class="op">=</span> [<span class="st">&#39;Giant&#39;</span>, <span class="st">&#39;Large&#39;</span>, <span class="st">&#39;Medium&#39;</span>, <span class="st">&#39;Small&#39;</span>, <span class="st">&#39;Small-Large&#39;</span>, <span class="st">&#39;Small-Medium&#39;</span>, <span class="st">&#39;Toy&#39;</span>]</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>counts <span class="op">=</span> [<span class="dv">7</span>, <span class="dv">42</span>, <span class="dv">56</span>, <span class="dv">44</span>, <span class="dv">1</span>, <span class="dv">6</span>, <span class="dv">3</span>]</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>plt.bar(sizes, counts)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_1b729b2b838b4d78ad1ff18fd8e0de37/f897715ca45439c2ee039c40cc7d87e8e478947e.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="5">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>sns.countplot(x<span class="op">=</span><span class="st">&#39;Training Difficulty (1-10)&#39;</span>, hue<span class="op">=</span><span class="st">&#39;Intelligence Rating (1-10)&#39;</span>, data<span class="op">=</span>df)</span></code></pre></div>
<div class="output execute_result" data-execution_count="5">
<pre><code>&lt;Axes: xlabel=&#39;Training Difficulty (1-10)&#39;, ylabel=&#39;count&#39;&gt;</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_1b729b2b838b4d78ad1ff18fd8e0de37/73ab4876cb246e5174808d7a8ef8af44c18975c7.png" /></p>
</div>
</div>
<div class="cell markdown">
<ul>
<li>Most dogs have a 6 or 7 training difficulty level</li>
<li>The dogs with the highest training difficulty level have lower
intelligence</li>
<li>Dogs with lower training difficulty level have higher
intelligence</li>
</ul>
</div>
<div class="cell code" data-execution_count="6">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>sns.countplot(x<span class="op">=</span><span class="st">&#39;Friendly Rating (1-10)&#39;</span>, hue<span class="op">=</span><span class="st">&#39;Intelligence Rating (1-10)&#39;</span>, data<span class="op">=</span>df)</span></code></pre></div>
<div class="output execute_result" data-execution_count="6">
<pre><code>&lt;Axes: xlabel=&#39;Friendly Rating (1-10)&#39;, ylabel=&#39;count&#39;&gt;</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_1b729b2b838b4d78ad1ff18fd8e0de37/d8ae8c7704e48f7cac46b28d90c5df7e0e426d45.png" /></p>
</div>
</div>
<div class="cell markdown">
<ul>
<li>According to count, almost all dogs are very friendly</li>
<li>Up to a point, higher intelligence can also correlate with a higher
friendliness rating with the exception of the dogs with the highest
friendliness rating which are moderately intelligent</li>
</ul>
</div>
<div class="cell markdown">
<ul>
<li>Feature Extraction
<ul>
<li>We need to vectorize the data in order to produce vectors that can
be projected into a visual space
<ul>
<li>For the text based data, we will use tfidf to vectorize text</li>
<li>for the ranking based data, we will encode all rankings based values
into numerical classes and then normalize to a range between 0 and
1</li>
</ul></li>
<li>Then we will scale all features using the standard scaler</li>
<li>After the data is vectorized then we can perform dimensionality
reduction using pca and tsne</li>
</ul></li>
</ul>
<ol>
<li>The first high level step is vectorize.</li>
</ol>
<ul>
<li>As part of the process of vectorization, we need to vectorize the
text using tfidf.</li>
<li>The next step to vectorize the data is to encode rankings based
values into numerical classes.</li>
<li>The last step to vectorize the data is to normalize all ranking
based values.</li>
<li>This will complete the vectorization process.</li>
</ul>
<ol>
<li>The second high level step is scaling and dimensionality
reduction.</li>
</ol>
<ul>
<li>The first part of this process will be to scale all features using
the standard scaler.</li>
<li>The next part of this process will be to use pca (principle
component analysis)</li>
<li>The last step to perform the dimensionality reduction is to use tsne
(T-distributed Stochastic Neighbor Embedding)</li>
<li>This will complete the dimensionality reduction portion</li>
</ul>
</div>
<div class="cell code" data-execution_count="7">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>tfidf_converter <span class="op">=</span> TfidfVectorizer(lowercase<span class="op">=</span><span class="va">True</span>, max_features<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>extracted_name <span class="op">=</span> tfidf_converter.fit_transform(df[<span class="st">&#39;Name&#39;</span>]).toarray()</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co">#df = df.assign(Name=extracted_name)</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>extracted_origin <span class="op">=</span> tfidf_converter.fit_transform(df[<span class="st">&#39;Origin&#39;</span>]).toarray()</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co">#df = df.assign(Origin=extracted_origin)</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>extracted_type <span class="op">=</span> tfidf_converter.fit_transform(df[<span class="st">&#39;Type&#39;</span>]).toarray()</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co">#df = df.assign(Type=extracted_type)</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>extracted_feature <span class="op">=</span> tfidf_converter.fit_transform(df[<span class="st">&#39;Unique Feature&#39;</span>]).toarray()</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co">#df = df.assign(Unique_Feature=extracted_feature)</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="co">#df = df.drop(&#39;Unique Feature&#39;, axis=1)</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>df</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="co">#print(extracted_origin)</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="co">#print(extracted_type)</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="co">#print(extracted_feature)</span></span></code></pre></div>
<div class="output execute_result" data-execution_count="7">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Origin</th>
      <th>Type</th>
      <th>Unique Feature</th>
      <th>Friendly Rating (1-10)</th>
      <th>Life Span</th>
      <th>Size</th>
      <th>Grooming Needs</th>
      <th>Exercise Requirements (hrs/day)</th>
      <th>Good with Children</th>
      <th>Intelligence Rating (1-10)</th>
      <th>Shedding Level</th>
      <th>Health Issues Risk</th>
      <th>Average Weight (kg)</th>
      <th>Training Difficulty (1-10)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Affenpinscher</td>
      <td>Germany</td>
      <td>Toy</td>
      <td>Monkey-like face</td>
      <td>7</td>
      <td>14</td>
      <td>Small</td>
      <td>High</td>
      <td>1.5</td>
      <td>Yes</td>
      <td>8</td>
      <td>Moderate</td>
      <td>Low</td>
      <td>4.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Afghan Hound</td>
      <td>Afghanistan</td>
      <td>Hound</td>
      <td>Long silky coat</td>
      <td>5</td>
      <td>13</td>
      <td>Large</td>
      <td>Very High</td>
      <td>2.0</td>
      <td>No</td>
      <td>4</td>
      <td>High</td>
      <td>Moderate</td>
      <td>25.0</td>
      <td>8</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Airedale Terrier</td>
      <td>England</td>
      <td>Terrier</td>
      <td>Largest of terriers</td>
      <td>8</td>
      <td>12</td>
      <td>Medium</td>
      <td>High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>7</td>
      <td>Moderate</td>
      <td>Low</td>
      <td>21.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Akita</td>
      <td>Japan</td>
      <td>Working</td>
      <td>Strong loyalty</td>
      <td>6</td>
      <td>11</td>
      <td>Large</td>
      <td>Moderate</td>
      <td>2.0</td>
      <td>With Training</td>
      <td>7</td>
      <td>High</td>
      <td>High</td>
      <td>45.0</td>
      <td>9</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Alaskan Malamute</td>
      <td>Alaska USA</td>
      <td>Working</td>
      <td>Strong pulling ability</td>
      <td>7</td>
      <td>11</td>
      <td>Large</td>
      <td>High</td>
      <td>3.0</td>
      <td>Yes</td>
      <td>6</td>
      <td>Very High</td>
      <td>Moderate</td>
      <td>36.0</td>
      <td>8</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>154</th>
      <td>Wire Fox Terrier</td>
      <td>England</td>
      <td>Terrier</td>
      <td>Energetic</td>
      <td>7</td>
      <td>14</td>
      <td>Small</td>
      <td>Moderate</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>7</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>8.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>155</th>
      <td>Wirehaired Dachshund</td>
      <td>Germany</td>
      <td>Hound</td>
      <td>Wiry coat</td>
      <td>7</td>
      <td>13</td>
      <td>Small</td>
      <td>Moderate</td>
      <td>1.5</td>
      <td>With Training</td>
      <td>7</td>
      <td>Moderate</td>
      <td>High</td>
      <td>8.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>156</th>
      <td>Wirehaired Pointing Griffon</td>
      <td>Netherlands</td>
      <td>Sporting</td>
      <td>Shaggy beard</td>
      <td>7</td>
      <td>13</td>
      <td>Medium</td>
      <td>High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>7</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>20.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>157</th>
      <td>Xoloitzcuintli</td>
      <td>Mexico</td>
      <td>Non-Sporting</td>
      <td>Hairless variety</td>
      <td>7</td>
      <td>15</td>
      <td>Small-Large</td>
      <td>Low</td>
      <td>2.0</td>
      <td>With Training</td>
      <td>8</td>
      <td>Low</td>
      <td>Moderate</td>
      <td>25.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>158</th>
      <td>Yorkshire Terrier</td>
      <td>England</td>
      <td>Toy</td>
      <td>Long silky coat</td>
      <td>8</td>
      <td>13</td>
      <td>Toy</td>
      <td>High</td>
      <td>1.0</td>
      <td>Yes</td>
      <td>7</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>2.5</td>
      <td>6</td>
    </tr>
  </tbody>
</table>
<p>159 rows × 15 columns</p>
</div>
</div>
</div>
<div class="cell code" data-execution_count="8">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.get_dummies(df, prefix<span class="op">=</span>[<span class="st">&#39;Size&#39;</span>], columns<span class="op">=</span>[<span class="st">&#39;Size&#39;</span>], drop_first<span class="op">=</span><span class="va">False</span>, dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.get_dummies(df, prefix<span class="op">=</span>[<span class="st">&#39;Grooming Needs&#39;</span>], columns<span class="op">=</span>[<span class="st">&#39;Grooming Needs&#39;</span>], drop_first<span class="op">=</span><span class="va">False</span>, dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.get_dummies(df, prefix<span class="op">=</span>[<span class="st">&#39;Good with Children&#39;</span>], columns<span class="op">=</span>[<span class="st">&#39;Good with Children&#39;</span>], drop_first<span class="op">=</span><span class="va">False</span>, dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.get_dummies(df, prefix<span class="op">=</span>[<span class="st">&#39;Health Issues Risk&#39;</span>], columns<span class="op">=</span>[<span class="st">&#39;Health Issues Risk&#39;</span>], drop_first<span class="op">=</span><span class="va">False</span>, dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.get_dummies(df, prefix<span class="op">=</span>[<span class="st">&#39;Shedding Level&#39;</span>], columns<span class="op">=</span>[<span class="st">&#39;Shedding Level&#39;</span>], drop_first<span class="op">=</span><span class="va">False</span>, dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.drop(<span class="st">&#39;Name&#39;</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.drop(<span class="st">&#39;Origin&#39;</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.drop(<span class="st">&#39;Type&#39;</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.drop(<span class="st">&#39;Unique Feature&#39;</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>df</span></code></pre></div>
<div class="output execute_result" data-execution_count="8">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Friendly Rating (1-10)</th>
      <th>Life Span</th>
      <th>Exercise Requirements (hrs/day)</th>
      <th>Intelligence Rating (1-10)</th>
      <th>Average Weight (kg)</th>
      <th>Training Difficulty (1-10)</th>
      <th>Size_Giant</th>
      <th>Size_Large</th>
      <th>Size_Medium</th>
      <th>Size_Small</th>
      <th>...</th>
      <th>Good with Children_No</th>
      <th>Good with Children_With Training</th>
      <th>Good with Children_Yes</th>
      <th>Health Issues Risk_High</th>
      <th>Health Issues Risk_Low</th>
      <th>Health Issues Risk_Moderate</th>
      <th>Shedding Level_High</th>
      <th>Shedding Level_Low</th>
      <th>Shedding Level_Moderate</th>
      <th>Shedding Level_Very High</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7</td>
      <td>14</td>
      <td>1.5</td>
      <td>8</td>
      <td>4.0</td>
      <td>6</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5</td>
      <td>13</td>
      <td>2.0</td>
      <td>4</td>
      <td>25.0</td>
      <td>8</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8</td>
      <td>12</td>
      <td>2.0</td>
      <td>7</td>
      <td>21.0</td>
      <td>6</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6</td>
      <td>11</td>
      <td>2.0</td>
      <td>7</td>
      <td>45.0</td>
      <td>9</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7</td>
      <td>11</td>
      <td>3.0</td>
      <td>6</td>
      <td>36.0</td>
      <td>8</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>154</th>
      <td>7</td>
      <td>14</td>
      <td>2.0</td>
      <td>7</td>
      <td>8.0</td>
      <td>7</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>155</th>
      <td>7</td>
      <td>13</td>
      <td>1.5</td>
      <td>7</td>
      <td>8.0</td>
      <td>7</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>156</th>
      <td>7</td>
      <td>13</td>
      <td>2.0</td>
      <td>7</td>
      <td>20.0</td>
      <td>6</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>157</th>
      <td>7</td>
      <td>15</td>
      <td>2.0</td>
      <td>8</td>
      <td>25.0</td>
      <td>6</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>158</th>
      <td>8</td>
      <td>13</td>
      <td>1.0</td>
      <td>7</td>
      <td>2.5</td>
      <td>6</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>159 rows × 27 columns</p>
</div>
</div>
</div>
<div class="cell code" data-execution_count="9">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>num_rows <span class="op">=</span> df.shape[<span class="dv">0</span>]</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>rows <span class="op">=</span> []</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_rows):</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    row <span class="op">=</span> df.iloc[i].to_list()</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(extracted_name[i])):</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>        row.append(extracted_name[i][j])</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>        row.append(extracted_origin[i][j])</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>        row.append(extracted_type[i][j])</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>        row.append(extracted_feature[i][j])</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    row <span class="op">=</span> np.array(row)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    row <span class="op">=</span> row.astype(np.float64)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    rows.append(row)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> row <span class="kw">in</span> rows:</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(row)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>[ 7.  14.   1.5  8.   4.   6.   0.   0.   0.   1.   0.   0.   0.   1.
  0.   0.   0.   0.   0.   1.   0.   1.   0.   0.   0.   1.   0.   0.
  0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   1.   0.   0.   0.
  0. ]
[ 5.         13.          2.          4.         25.          8.
  0.          1.          0.          0.          0.          0.
  0.          0.          0.          0.          1.          1.
  0.          0.          0.          0.          1.          1.
  0.          0.          0.          0.          0.          1.
  0.          0.          0.          0.          0.53044295  0.
  0.          0.          0.          0.          0.          0.
  0.84772064]
[ 8. 12.  2.  7. 21.  6.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1.  0.  1.  0.  0.  0.]
[ 6. 11.  2.  7. 45.  9.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  1.  0.]
[ 7. 11.  3.  6. 36.  8.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  1.  0.]
[ 8. 11.  2.  6. 42.  7.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  1.  0.]
[ 9. 14.  2.  9. 12.  5.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 8.  12.   2.5  6.  31.   6.   0.   0.   1.   0.   0.   0.   0.   0.
  1.   0.   0.   0.   0.   1.   0.   1.   0.   0.   0.   1.   0.   0.
  0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 7.  14.   2.5  9.  15.   7.   0.   0.   1.   0.   0.   0.   0.   0.
  0.   1.   0.   0.   0.   1.   0.   1.   0.   0.   0.   1.   0.   1.
  0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 8.  14.   2.5  9.  25.   7.   0.   0.   1.   0.   0.   0.   0.   1.
  0.   0.   0.   0.   0.   1.   0.   0.   1.   1.   0.   0.   0.   0.
  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 7.  13.   1.5  7.   6.5  6.   0.   0.   0.   1.   0.   0.   0.   0.
  0.   1.   0.   0.   0.   1.   0.   1.   0.   0.   1.   0.   0.   0.
  0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   1.   0.   0.
  0. ]
[ 6. 13.  2.  6. 10.  9.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.
  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 8. 11.  1.  5. 24.  7.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.
  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  1.]
[ 9. 13.  2.  7. 10.  7.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 8.         13.          2.          8.         22.          6.
  0.          0.          1.          0.          0.          0.
  0.          0.          0.          0.          1.          0.
  0.          1.          0.          1.          0.          1.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.53044295  0.
  0.          0.          0.          0.          1.          0.
  0.84772064]
[ 9.   8.   1.5  7.  43.   5.   0.   1.   0.   0.   0.   0.   0.   1.
  0.   0.   0.   0.   0.   1.   1.   0.   0.   1.   0.   0.   0.   1.
  0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   1.
  0. ]
[ 9.         13.          1.          8.          4.          5.
  0.          0.          0.          1.          0.          0.
  0.          0.          0.          0.          1.          0.
  0.          1.          0.          1.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.          0.          0.          1.          0.53905178  0.
  0.          0.          0.84227262  0.          0.          0.
  0.        ]
[ 7. 11.  2.  8. 50.  8.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.
  0.  0.  0.  1.  0.  1.  0.]
[ 7. 11.  2.  6. 43.  8.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 8. 13.  3. 10. 17.  6.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 8.  13.   1.5  7.   6.   6.   0.   0.   0.   1.   0.   0.   0.   0.
  0.   1.   0.   0.   0.   1.   0.   1.   0.   0.   0.   1.   0.   0.
  0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   1.   1.   0.   0.
  0. ]
[ 6. 11.  2.  6. 37.  7.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.
  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 9.  12.   1.5  8.   9.   5.   0.   0.   0.   1.   0.   0.   0.   0.
  1.   0.   0.   0.   0.   1.   0.   0.   1.   0.   1.   0.   0.   0.
  0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   1.   1.   0.   0.
  0. ]
[ 7. 11.  2.  8. 34.  7.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.
  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 9. 11.  2.  7. 28.  6.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  1.  0.  0.  0.  0.  1.  0.]
[ 7.         12.          2.          8.         35.          7.
  0.          1.          0.          0.          0.          0.
  0.          1.          0.          0.          0.          0.
  0.          1.          0.          1.          0.          0.
  0.          1.          0.          0.          0.          0.
  0.          0.          1.          0.          0.53044295  0.
  0.          0.          0.          0.          0.          0.
  0.84772064]
[ 8.  13.   2.5  8.  17.   5.   0.   0.   1.   0.   0.   0.   0.   0.
  0.   1.   0.   0.   0.   1.   0.   1.   0.   0.   0.   1.   0.   0.
  0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 7.  13.   1.5  8.   4.   7.   0.   0.   0.   1.   0.   0.   0.   1.
  0.   0.   0.   0.   0.   1.   0.   0.   1.   0.   0.   1.   0.   0.
  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.
  0. ]
[ 7. 12.  2.  7. 27.  7.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.
  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1.  0.  1.  0.  0.  0.]
[ 6.   9.   1.5  6.  52.   7.   0.   1.   0.   0.   0.   0.   0.   0.
  1.   0.   0.   0.   1.   0.   1.   0.   0.   0.   0.   1.   0.   0.
  1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.
  0. ]
[ 8.  14.   1.5  7.   7.   6.   0.   0.   0.   1.   0.   0.   0.   0.
  0.   1.   0.   0.   0.   1.   0.   1.   0.   0.   0.   1.   0.   0.
  0.   0.   0.   0.   0.   0.   1.   0.   0.   1.   0.   1.   1.   0.
  0. ]
[ 6. 13.  2.  8. 21.  8.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.
  1.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 6. 11.  2.  7. 45.  9.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.
  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  1.  0.]
[ 8. 13.  2.  8. 13.  6.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  1.]
[10. 11.  1.  6.  6.  4.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.
  0.  0.  0.  0.  0.  0.  0.]
[ 7.  11.   2.5  7.  30.   7.   0.   1.   0.   0.   0.   0.   0.   0.
  0.   1.   0.   0.   0.   1.   0.   1.   0.   0.   0.   1.   0.   0.
  0.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 6. 16.  1.  7.  2.  7.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.
  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 7. 14.  1.  8.  3.  6.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 6.  10.   1.5  6.  22.   8.   0.   0.   1.   0.   0.   0.   0.   0.
  1.   0.   0.   0.   1.   0.   1.   0.   0.   0.   0.   1.   0.   0.
  0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 5.  10.   1.5  5.  26.   9.   0.   0.   1.   0.   0.   0.   0.   1.
  0.   0.   0.   1.   0.   0.   1.   0.   0.   1.   0.   0.   0.   0.
  0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 7.  11.   1.5  6.  31.   6.   0.   0.   1.   0.   0.   0.   0.   0.
  0.   1.   0.   0.   0.   1.   0.   0.   1.   1.   0.   0.   0.   0.
  1.   0.   0.   0.   0.   1.   0.   1.   0.   0.   0.   0.   0.   0.
  0. ]
[ 9.  13.   1.5  7.  12.   5.   0.   0.   0.   0.   0.   1.   0.   1.
  0.   0.   0.   0.   0.   1.   0.   0.   1.   1.   0.   0.   0.   0.
  1.   0.   0.   0.   0.   1.   0.   1.   0.   0.   0.   0.   0.   0.
  1. ]
[ 9. 13.  2.  8. 24.  5.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  1.  0.  0.]
[ 7. 12.  2.  7. 32.  6.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  1.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 7.  14.   1.5  7.  10.   7.   0.   0.   0.   1.   0.   0.   0.   0.
  1.   0.   0.   0.   1.   0.   1.   0.   0.   0.   0.   1.   0.   0.
  0.   1.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.
  1. ]
[ 8.  12.   2.5  7.  24.   7.   0.   0.   1.   0.   0.   0.   0.   0.
  1.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   1.   0.   0.
  0.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 7.  13.   1.5  7.   8.   7.   0.   0.   0.   1.   0.   0.   0.   0.
  0.   1.   0.   0.   0.   1.   0.   1.   0.   0.   1.   0.   0.   0.
  0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   1.   1.   0.
  0. ]
[ 8.  11.   2.5  9.  35.   7.   0.   1.   0.   0.   0.   0.   0.   0.
  1.   0.   0.   0.   1.   0.   0.   0.   1.   0.   1.   0.   0.   0.
  0.   0.   1.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   1.
  0. ]
[ 7.  9.  1.  6. 20.  7.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.
  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 8.         12.          1.5         7.         14.          5.
  0.          0.          1.          0.          0.          0.
  0.          1.          0.          0.          0.          0.
  0.          1.          0.          0.          1.          0.
  0.          1.          0.          0.          1.          0.
  0.          0.73582045  0.          1.          0.          0.67717669
  0.          0.          0.          0.          0.          0.
  0.        ]
[ 7.  12.   2.5  6.  29.   7.   0.   0.   1.   0.   0.   0.   0.   0.
  1.   0.   0.   0.   0.   1.   0.   1.   0.   0.   0.   1.   0.   0.
  1.   1.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 8. 12.  2.  7. 26.  6.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 9.         13.          2.          7.         20.          6.
  0.          0.          1.          0.          0.          0.
  0.          1.          0.          0.          0.          0.
  0.          1.          0.          0.          1.          0.
  0.          1.          0.          0.          1.          0.
  0.          0.73582045  0.          1.          0.          0.67717669
  0.          0.          0.          0.          0.          0.
  0.        ]
[ 8.         11.          1.          7.          5.          6.
  0.          0.          0.          1.          0.          0.
  0.          1.          0.          0.          0.          0.
  0.          1.          0.          0.          1.          0.
  0.          1.          0.          0.          1.          0.
  0.          0.73582045  0.          0.          0.          0.67717669
  0.          0.          0.          0.          0.          0.
  0.        ]
[ 7.  12.   2.5  8.  27.   7.   0.   0.   1.   0.   0.   0.   0.   0.
  1.   0.   0.   0.   0.   1.   0.   1.   0.   0.   0.   1.   0.   1.
  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 7. 12.  2.  7. 18.  6.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  0.  1.
  0.  0.  0.  0.  0.  0.  0.]
[ 8. 12.  2.  7. 20.  6.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 7.         13.          2.          8.         15.          7.
  0.          0.          1.          0.          0.          0.
  0.          0.          0.          1.          0.          0.
  0.          1.          0.          1.          0.          0.
  0.          1.          0.          0.          0.          0.
  0.72334622  0.          0.          1.          0.          0.
  0.          0.          0.69048552  0.          0.          0.
  0.        ]
[ 9.  11.   2.5  8.  32.   5.   0.   1.   0.   0.   0.   0.   0.   0.
  0.   1.   0.   0.   0.   1.   0.   0.   1.   0.   0.   1.   0.   0.
  1.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 8. 11.  1.  7. 11.  6.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.
  0.  1.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 7. 13.  2.  8. 13.  7.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.
  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.
  1.  0.  0.  0.  0.  1.  0.]
[ 8.  11.   2.5  9.  31.   6.   0.   1.   0.   0.   0.   0.   0.   0.
  0.   1.   0.   0.   1.   0.   0.   0.   1.   1.   0.   0.   0.   0.
  0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.
  0. ]
[ 8.  13.   2.5  8.  26.   6.   0.   1.   0.   0.   0.   0.   0.   0.
  1.   0.   0.   0.   0.   1.   0.   1.   0.   0.   0.   1.   0.   0.
  0.   0.   0.   0.   0.   1.   0.   0.   1.   0.   0.   0.   0.   0.
  0. ]
[ 7.  13.   2.5  8.  27.   7.   0.   1.   0.   0.   0.   0.   0.   0.
  0.   1.   0.   0.   0.   1.   0.   1.   0.   0.   0.   1.   0.   0.
  0.   0.   0.   0.   0.   1.   1.   0.   1.   0.   0.   0.   0.   0.
  0. ]
[ 7. 13.  2.  8. 38.  8.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  1.  0.  0.  0.  0.  1.  0.]
[10. 11.  2.  8. 29.  4.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.
  0.  0.  0.  0.  1.  0.  0.]
[ 8. 11.  2.  7. 26.  6.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.
  0.  0.  0.  0.  1.  0.  0.]
[ 8.  8.  2.  6. 67.  6.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.
  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  1.  0.  0.  0.  0.  1.  0.]
[ 7.  11.   1.5  6.  46.   8.   0.   1.   0.   0.   0.   0.   0.   1.
  0.   0.   0.   0.   0.   1.   0.   0.   1.   1.   0.   0.   0.   0.
  0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   1.
  0. ]
[ 8. 10.  2.  7. 61.  7.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  1.  0.]
[ 7. 11.  2.  7. 33.  6.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.
  0.  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 8. 12.  2.  6. 25.  6.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.
  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 9.  14.   1.5  8.   5.   5.   0.   0.   0.   1.   0.   0.   0.   1.
  0.   0.   0.   0.   0.   1.   0.   1.   0.   0.   1.   0.   0.   0.
  0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 7. 13.  2.  7. 22.  7.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.
  0.  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 8. 12.  2.  7. 14.  6.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 8.  12.   2.5  7.  27.   6.   0.   1.   0.   0.   0.   0.   0.   1.
  0.   0.   0.   0.   0.   1.   0.   0.   1.   0.   0.   1.   0.   0.
  0.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 8.  13.   2.5  7.  29.   6.   0.   1.   0.   0.   0.   0.   0.   1.
  0.   0.   0.   0.   0.   1.   0.   0.   1.   1.   0.   0.   0.   0.
  0.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 7.  13.   1.5  7.  11.   7.   0.   0.   1.   0.   0.   0.   0.   0.
  0.   1.   0.   0.   0.   1.   0.   1.   0.   0.   1.   0.   0.   0.
  0.   0.   0.   0.   0.   0.   1.   0.   0.   1.   0.   1.   0.   0.
  0. ]
[ 8. 11.  2.  7. 24.  6.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.
  0.  0.  0.  0.  0.  0.  0.]
[ 7.  7.  2.  6. 54.  6.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 7.  13.   1.5  7.   4.   7.   0.   0.   0.   1.   0.   0.   0.   0.
  1.   0.   0.   1.   0.   0.   0.   0.   1.   0.   1.   0.   0.   0.
  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 7. 11.  1.  7.  3.  6.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 8.  13.   1.5  8.   6.   6.   0.   0.   0.   1.   0.   0.   0.   1.
  0.   0.   0.   0.   0.   1.   0.   1.   0.   1.   0.   0.   0.   0.
  0.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 8.  13.   1.5  8.  16.   6.   0.   0.   1.   0.   0.   0.   0.   1.
  0.   0.   0.   0.   0.   1.   0.   1.   0.   1.   0.   0.   0.   0.
  0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 7.  13.   1.5  7.  16.   7.   0.   0.   1.   0.   0.   0.   0.   1.
  0.   0.   0.   0.   0.   1.   0.   1.   0.   0.   1.   0.   0.   0.
  0.   0.   0.   0.   0.   0.   1.   0.   0.   1.   0.   1.   0.   0.
  0. ]
[ 6. 11.  2.  6. 40.  8.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.
  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.
  0.  0.  0.  0.  0.  1.  0.]
[ 6. 11.  2.  7. 42.  8.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  1.  0.]
[10. 11.  2.  8. 30.  4.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 7.  13.   1.5  7.   7.   7.   0.   0.   0.   1.   0.   0.   0.   0.
  0.   1.   0.   0.   0.   1.   0.   1.   0.   0.   1.   0.   0.   0.
  1.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   1.   0.   0.
  0. ]
[ 8.  9.  2.  7. 61.  8.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  1.  0.  1.  0.  0.  1.  0.]
[ 6. 13.  1.  7.  6.  8.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.
  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 8.  14.   1.5  8.   6.   6.   0.   0.   0.   1.   0.   0.   0.   1.
  0.   0.   0.   0.   0.   1.   0.   1.   0.   0.   1.   0.   0.   0.
  0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 8.  13.   1.   7.   2.5  6.   0.   0.   0.   1.   0.   0.   0.   0.
  0.   0.   1.   1.   0.   0.   0.   1.   0.   0.   1.   0.   0.   0.
  0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 7.  15.   1.5  8.   7.   7.   0.   0.   0.   0.   0.   1.   0.   0.
  1.   0.   0.   0.   1.   0.   0.   1.   0.   0.   0.   1.   0.   0.
  1.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   1.   0.   0.
  0. ]
[ 6.   9.   1.5  6.  78.   7.   1.   0.   0.   0.   0.   0.   0.   0.
  1.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   1.   0.   0.
  1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.
  0. ]
[ 6.  13.   1.5  7.   4.   8.   0.   0.   0.   1.   0.   0.   0.   0.
  1.   0.   0.   1.   0.   0.   0.   1.   0.   0.   1.   0.   0.   0.
  0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.
  0. ]
[ 8.  12.   1.5  8.   8.   6.   0.   0.   0.   1.   0.   0.   0.   1.
  0.   0.   0.   0.   0.   1.   0.   1.   0.   0.   0.   1.   0.   0.
  0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.
  0. ]
[ 6.  8.  1.  5. 70.  8.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  1.  0.]
[ 9.  9.  2.  7. 61.  7.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  1.  0.]
[ 8.  14.   1.5  7.   5.   6.   0.   0.   0.   1.   0.   0.   0.   0.
  1.   0.   0.   0.   0.   1.   0.   1.   0.   0.   1.   0.   0.   0.
  1.   0.   0.   0.   0.   0.   0.   0.   0.   1.   1.   1.   0.   0.
  0. ]
[ 8. 12.  2.  7. 12.  6.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 7. 12.  2.  7. 23.  7.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 7. 12.  2.  7.  8.  7.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 8. 10.  2.  6. 32.  6.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.
  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 7.  10.   2.5  6.  37.   7.   0.   1.   0.   0.   0.   0.   0.   0.
  0.   0.   1.   0.   0.   1.   0.   0.   1.   1.   0.   0.   0.   0.
  1.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 9. 13.  1.  8.  3.  5.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 6.         12.          1.          5.          5.          7.
  0.          0.          0.          1.          0.          0.
  0.          0.          0.          0.          1.          0.
  1.          0.          1.          0.          0.          0.
  0.          1.          0.          0.          0.          0.
  0.72334622  0.          0.          0.          0.          0.
  0.          0.          0.69048552  0.          0.          0.
  0.        ]
[ 9. 12.  2.  8. 12.  5.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  1.]
[ 7. 12.  2.  6. 15.  7.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 7. 12.  2.  8. 20.  7.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 8.  12.   2.5  7.  25.   6.   0.   0.   1.   0.   0.   0.   0.   0.
  0.   1.   0.   0.   0.   1.   0.   0.   1.   0.   0.   1.   0.   0.
  1.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 8. 12.  1.  7.  3.  7.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.
  1.  0.  0.  0.  0.  0.  0.]
[ 8.  15.   1.5  8.   7.   6.   0.   0.   0.   1.   0.   0.   0.   0.
  0.   0.   1.   0.   0.   1.   0.   1.   0.   0.   1.   0.   0.   0.
  0.   0.   0.   0.   1.   1.   1.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 9. 12.  2.  8. 22.  5.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 9. 15.  1.  8.  4.  5.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.
  0.  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 7. 12.  2.  8. 15.  8.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 8. 11.  2.  8. 18.  6.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 7.  12.   2.5  8.  23.   7.   0.   0.   1.   0.   0.   0.   0.   0.
  0.   1.   0.   0.   0.   1.   0.   1.   0.   0.   0.   1.   0.   0.
  0.   0.   0.   0.   0.   1.   0.   0.   1.   0.   0.   0.   0.   0.
  0. ]
[ 8. 12.  1.  7.  7.  6.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 7. 10.  2.  6. 54.  7.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.
  0.  0.  0.  0.  0.  1.  0.]
[ 7. 15.  2.  7.  5.  7.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  1.  0.  1.  0.  0.  0.]
[ 8. 12.  2.  6. 25.  7.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 6.  11.   2.5  8.  36.   7.   0.   1.   0.   0.   0.   0.   0.   0.
  0.   1.   0.   0.   1.   0.   0.   0.   1.   0.   0.   1.   0.   0.
  0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 7.  9.  2.  8. 40.  8.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  1.  0.  0.  0.  0.  1.  0.]
[ 9.  8.  2.  6. 68.  7.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  1.  0.]
[ 6.  12.   2.5  7.  22.   7.   0.   0.   1.   0.   0.   0.   0.   0.
  0.   1.   0.   1.   0.   0.   0.   0.   1.   0.   0.   1.   0.   0.
  0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 9. 12.  2.  7. 21.  7.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.
  0.  0.  0.  0.  0.  1.  0.]
[ 7. 13.  2.  7.  7.  7.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.
  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 6.  8.  2.  6. 41.  7.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.
  0.  0.  1.  0.  1.  0.  0.]
[ 7.  12.   1.5  6.   9.   7.   0.   0.   0.   1.   0.   0.   0.   0.
  0.   1.   0.   0.   0.   1.   1.   0.   0.   0.   0.   1.   0.   0.
  0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   1.   1.   0.
  0. ]
[ 9. 12.  2.  8. 11.  5.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  1.  0.  0.]
[ 7. 13.  2.  7.  9.  7.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.
  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  0.  1.  0.  0.  0.  0.]
[ 8.         14.          1.          6.          4.          7.
  0.          0.          0.          1.          0.          0.
  0.          0.          0.          0.          1.          0.
  0.          1.          0.          0.          1.          0.
  0.          1.          0.          0.          0.          0.
  0.          0.          0.          0.          0.53044295  0.
  0.          0.          0.          0.          0.          0.
  0.84772064]
[ 8.  12.   2.5  7.  21.   7.   0.   0.   1.   0.   0.   0.   0.   0.
  0.   1.   0.   0.   0.   1.   0.   0.   1.   0.   0.   1.   0.   0.
  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.
  0. ]
[ 7.  13.   1.5  7.   4.   7.   0.   0.   0.   1.   0.   0.   0.   1.
  0.   0.   0.   0.   0.   1.   0.   1.   0.   0.   0.   1.   0.   0.
  0.   0.   0.   0.   0.   0.   1.   0.   0.   1.   0.   1.   0.   0.
  0. ]
[ 7.  13.   1.5  6.   8.   7.   0.   0.   0.   1.   0.   0.   0.   0.
  0.   1.   0.   1.   0.   0.   0.   0.   1.   0.   0.   1.   0.   0.
  0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   1.   1.   0.
  1. ]
[ 6.  12.   2.5  7.  18.   7.   0.   0.   1.   0.   0.   0.   0.   0.
  1.   0.   0.   0.   1.   0.   0.   0.   1.   0.   1.   0.   0.   0.
  0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  0. ]
[ 7. 13.  2.  7.  7.  7.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1.  0.  1.  0.  0.  0.]
[ 8. 12.  2.  7. 12.  6.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.
  0.  1.  0.  1.  0.  0.  0.]
[ 7. 12.  2.  8. 15.  6.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 7. 12.  2.  7. 32.  7.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 7. 12.  2.  7. 16.  7.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.
  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1.  0.  1.  0.  0.  0.]
[ 9. 12.  2.  8. 26.  5.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 7. 15.  2.  7. 14.  6.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  1.  0.  0.  0.  0.  0.  0.]
[ 7.  11.   1.5  6.  18.   6.   0.   0.   1.   0.   0.   0.   0.   1.
  0.   0.   0.   0.   0.   1.   0.   0.   1.   0.   0.   1.   0.   0.
  1.   0.   0.   0.   0.   1.   0.   1.   0.   0.   0.   0.   0.   0.
  0. ]
[ 8. 12.  2.  8. 12.  7.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  1.  0.  0.  0.  0.]
[ 6. 12.  2.  7. 15.  7.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 7. 10.  2.  6. 45.  8.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  1.  0.]
[ 8.  15.   1.5  8.   2.   7.   0.   0.   0.   0.   0.   0.   1.   0.
  0.   1.   0.   0.   0.   1.   0.   1.   0.   0.   1.   0.   0.   0.
  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.
  0. ]
[ 8. 12.  2.  7. 20.  7.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 8. 13.  2.  7. 16.  6.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.
  0.  0.  0.  0.  0.  0.  0.]
[ 7.  14.   1.5  7.   9.   7.   0.   0.   1.   0.   0.   0.   0.   0.
  0.   1.   0.   0.   0.   1.   0.   0.   1.   0.   0.   1.   0.   0.
  0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   1.   0.   0.
  0. ]
[ 8.  13.   1.5  7.   7.   7.   0.   0.   0.   1.   0.   0.   0.   0.
  0.   1.   0.   0.   0.   1.   0.   0.   1.   0.   0.   1.   0.   0.
  0.   0.   0.   0.   0.   0.   1.   0.   0.   1.   0.   1.   1.   0.
  0. ]
[ 7. 13.  2.  8.  8.  6.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.
  0.  1.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 7. 14.  2.  7.  8.  7.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1.  0.  1.  0.  0.  0.]
[ 7.  13.   1.5  7.   8.   7.   0.   0.   0.   1.   0.   0.   0.   0.
  0.   1.   0.   0.   1.   0.   1.   0.   0.   0.   0.   1.   0.   0.
  0.   1.   0.   0.   0.   0.   1.   0.   1.   0.   0.   0.   0.   0.
  0. ]
[ 7. 13.  2.  7. 20.  6.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 7. 15.  2.  8. 25.  6.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.
  0.  0.  0.  0.  0.  0.  0.]
[ 8.         13.          1.          7.          2.5         6.
  0.          0.          0.          0.          0.          0.
  1.          1.          0.          0.          0.          0.
  0.          1.          0.          0.          1.          0.
  0.          1.          0.          0.          1.          0.
  0.          0.          0.          0.          0.53044295  0.
  0.          0.          0.          1.          0.          0.
  0.84772064]
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="10">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>normalizer <span class="op">=</span> Normalizer().fit(rows)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>rows <span class="op">=</span> normalizer.transform(rows)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> row <span class="kw">in</span> rows:</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(row)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>[0.36378979 0.72757958 0.07795496 0.41575976 0.20787988 0.31181982
 0.         0.         0.         0.05196997 0.         0.
 0.         0.05196997 0.         0.         0.         0.
 0.         0.05196997 0.         0.05196997 0.         0.
 0.         0.05196997 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.05196997 0.         0.05196997 0.         0.         0.
 0.        ]
[0.16574839 0.4309458  0.06629935 0.13259871 0.82874193 0.26519742
 0.         0.03314968 0.         0.         0.         0.
 0.         0.         0.         0.         0.03314968 0.03314968
 0.         0.         0.         0.         0.03314968 0.03314968
 0.         0.         0.         0.         0.         0.03314968
 0.         0.         0.         0.         0.01758401 0.
 0.         0.         0.         0.         0.         0.
 0.02810167]
[0.29290081 0.43935122 0.0732252  0.25628821 0.76886463 0.21967561
 0.         0.         0.0366126  0.         0.         0.
 0.         0.0366126  0.         0.         0.         0.
 0.         0.0366126  0.         0.0366126  0.         0.
 0.         0.0366126  0.         0.         0.0366126  0.
 0.         0.         0.         0.         0.         0.
 0.         0.0366126  0.         0.0366126  0.         0.
 0.        ]
[0.12451456 0.2282767  0.04150485 0.14526699 0.93385921 0.18677184
 0.         0.02075243 0.         0.         0.         0.
 0.         0.         0.         0.02075243 0.         0.
 0.02075243 0.         0.02075243 0.         0.         0.02075243
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.02075243
 0.        ]
[0.17604841 0.2766475  0.07544932 0.15089864 0.90539182 0.20119818
 0.         0.02514977 0.         0.         0.         0.
 0.         0.02514977 0.         0.         0.         0.
 0.         0.02514977 0.         0.         0.02514977 0.
 0.         0.         0.02514977 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.02514977
 0.        ]
[0.17694958 0.24330568 0.0442374  0.13271219 0.92898531 0.15483088
 0.         0.0221187  0.         0.         0.         0.
 0.         0.         0.0221187  0.         0.         0.
 0.         0.0221187  0.         0.         0.0221187  0.
 0.         0.0221187  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.0221187
 0.        ]
[0.38801755 0.60358286 0.08622612 0.38801755 0.51735674 0.21556531
 0.         0.         0.         0.         0.         0.04311306
 0.         0.04311306 0.         0.         0.         0.
 0.         0.04311306 0.         0.04311306 0.         0.04311306
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.04311306 0.04311306 0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.22598059 0.33897088 0.07061893 0.16948544 0.87567477 0.16948544
 0.         0.         0.02824757 0.         0.         0.
 0.         0.         0.02824757 0.         0.         0.
 0.         0.02824757 0.         0.02824757 0.         0.
 0.         0.02824757 0.         0.         0.         0.02824757
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.2826697  0.5653394  0.10095347 0.36343247 0.60572079 0.2826697
 0.         0.         0.04038139 0.         0.         0.
 0.         0.         0.         0.04038139 0.         0.
 0.         0.04038139 0.         0.04038139 0.         0.
 0.         0.04038139 0.         0.04038139 0.         0.
 0.         0.         0.         0.         0.04038139 0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.24972579 0.43702014 0.07803931 0.28094152 0.7803931  0.21851007
 0.         0.         0.03121572 0.         0.         0.
 0.         0.03121572 0.         0.         0.         0.
 0.         0.03121572 0.         0.         0.03121572 0.03121572
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.37178334 0.69045477 0.07966786 0.37178334 0.34522738 0.31867143
 0.         0.         0.         0.05311191 0.         0.
 0.         0.         0.         0.05311191 0.         0.
 0.         0.05311191 0.         0.05311191 0.         0.
 0.05311191 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.05311191 0.         0.05311191 0.         0.
 0.        ]
[0.28867513 0.62546279 0.09622504 0.28867513 0.48112522 0.4330127
 0.         0.         0.         0.         0.         0.04811252
 0.         0.         0.04811252 0.         0.         0.04811252
 0.         0.         0.         0.04811252 0.         0.
 0.04811252 0.         0.         0.         0.         0.04811252
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.27537136 0.37863561 0.03442142 0.1721071  0.82611407 0.24094994
 0.         0.         0.03442142 0.         0.         0.
 0.         0.         0.03442142 0.         0.         0.
 0.         0.03442142 0.03442142 0.         0.         0.
 0.         0.03442142 0.         0.         0.         0.03442142
 0.         0.         0.03442142 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.03442142]
[0.42008403 0.60678804 0.09335201 0.32673202 0.46676003 0.32673202
 0.         0.         0.         0.         0.         0.046676
 0.         0.         0.046676   0.         0.         0.
 0.         0.046676   0.         0.         0.046676   0.
 0.         0.046676   0.         0.         0.046676   0.046676
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.27801922 0.45178123 0.0695048  0.27801922 0.76455285 0.20851441
 0.         0.         0.0347524  0.         0.         0.
 0.         0.         0.         0.         0.0347524  0.
 0.         0.0347524  0.         0.0347524  0.         0.0347524
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.01843417 0.
 0.         0.         0.         0.         0.0347524  0.
 0.02946033]
[0.19742112 0.17548544 0.03290352 0.15354976 0.94323425 0.1096784
 0.         0.02193568 0.         0.         0.         0.
 0.         0.02193568 0.         0.         0.         0.
 0.         0.02193568 0.02193568 0.         0.         0.02193568
 0.         0.         0.         0.02193568 0.         0.
 0.         0.         0.         0.         0.02193568 0.
 0.         0.         0.         0.         0.         0.02193568
 0.        ]
[0.47237749 0.68232305 0.05248639 0.4198911  0.20994555 0.26243194
 0.         0.         0.         0.05248639 0.         0.
 0.         0.         0.         0.         0.05248639 0.
 0.         0.05248639 0.         0.05248639 0.         0.
 0.05248639 0.         0.         0.         0.         0.
 0.         0.         0.         0.05248639 0.02829288 0.
 0.         0.         0.04420785 0.         0.         0.
 0.        ]
[0.13205197 0.20751024 0.03772913 0.15091654 0.94322835 0.15091654
 0.         0.01886457 0.         0.         0.         0.
 0.         0.01886457 0.         0.         0.         0.
 0.         0.01886457 0.         0.         0.01886457 0.
 0.         0.01886457 0.         0.         0.         0.
 0.         0.         0.         0.         0.01886457 0.
 0.         0.         0.         0.01886457 0.         0.01886457
 0.        ]
[0.1517086  0.23839923 0.04334532 0.13003595 0.93192428 0.17338126
 0.         0.02167266 0.         0.         0.         0.
 0.         0.         0.         0.02167266 0.         0.
 0.         0.02167266 0.02167266 0.         0.         0.
 0.         0.02167266 0.         0.         0.         0.02167266
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.3086067  0.50148589 0.11572751 0.38575837 0.65578924 0.23145502
 0.         0.         0.03857584 0.         0.         0.
 0.         0.03857584 0.         0.         0.         0.
 0.         0.03857584 0.         0.03857584 0.         0.
 0.         0.03857584 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.41917001 0.68115127 0.07859438 0.36677376 0.31437751 0.31437751
 0.         0.         0.         0.05239625 0.         0.
 0.         0.         0.         0.05239625 0.         0.
 0.         0.05239625 0.         0.05239625 0.         0.
 0.         0.05239625 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.05239625 0.05239625 0.05239625 0.         0.
 0.        ]
[0.14902521 0.27321289 0.04967507 0.14902521 0.9189888  0.17386275
 0.         0.02483754 0.         0.         0.         0.
 0.         0.02483754 0.         0.         0.         0.02483754
 0.         0.         0.         0.02483754 0.         0.
 0.         0.02483754 0.         0.         0.         0.02483754
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.44707563 0.59610084 0.07451261 0.39740056 0.44707563 0.24837535
 0.         0.         0.         0.04967507 0.         0.
 0.         0.         0.04967507 0.         0.         0.
 0.         0.04967507 0.         0.         0.04967507 0.
 0.04967507 0.         0.         0.         0.         0.
 0.         0.         0.         0.04967507 0.         0.
 0.         0.         0.04967507 0.04967507 0.         0.
 0.        ]
[0.18395592 0.28907358 0.05255883 0.21023533 0.89350016 0.18395592
 0.         0.02627942 0.         0.         0.         0.
 0.         0.         0.         0.         0.02627942 0.
 0.         0.02627942 0.         0.         0.02627942 0.02627942
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.27360806 0.33440985 0.06080179 0.21280627 0.85122506 0.18240537
 0.         0.0304009  0.         0.         0.         0.
 0.         0.         0.0304009  0.         0.         0.
 0.         0.0304009  0.         0.         0.0304009  0.
 0.         0.0304009  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.0304009  0.         0.         0.         0.         0.0304009
 0.        ]
[0.1782608  0.30558994 0.05093166 0.20372663 0.891304   0.1782608
 0.         0.02546583 0.         0.         0.         0.
 0.         0.02546583 0.         0.         0.         0.
 0.         0.02546583 0.         0.02546583 0.         0.
 0.         0.02546583 0.         0.         0.         0.
 0.         0.         0.02546583 0.         0.01350817 0.
 0.         0.         0.         0.         0.         0.
 0.02158791]
[0.32019217 0.52031228 0.10006005 0.32019217 0.68040837 0.20012011
 0.         0.         0.04002402 0.         0.         0.
 0.         0.         0.         0.04002402 0.         0.
 0.         0.04002402 0.         0.04002402 0.         0.
 0.         0.04002402 0.         0.         0.         0.
 0.         0.         0.04002402 0.04002402 0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.37139068 0.68972554 0.07958372 0.42444649 0.21222324 0.37139068
 0.         0.         0.         0.05305581 0.         0.
 0.         0.05305581 0.         0.         0.         0.
 0.         0.05305581 0.         0.         0.05305581 0.
 0.         0.05305581 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.05305581 0.         0.         0.
 0.        ]
[0.21790048 0.37354368 0.06225728 0.21790048 0.84047329 0.21790048
 0.         0.         0.03112864 0.         0.         0.
 0.         0.         0.03112864 0.         0.         0.
 0.03112864 0.         0.         0.         0.03112864 0.
 0.03112864 0.         0.         0.         0.03112864 0.
 0.         0.         0.         0.         0.         0.
 0.         0.03112864 0.         0.03112864 0.         0.
 0.        ]
[0.1111254  0.1666881  0.02778135 0.1111254  0.96308682 0.1296463
 0.         0.0185209  0.         0.         0.         0.
 0.         0.         0.0185209  0.         0.         0.
 0.0185209  0.         0.0185209  0.         0.         0.
 0.         0.0185209  0.         0.         0.0185209  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.0185209
 0.        ]
[0.39740056 0.69545098 0.07451261 0.34772549 0.34772549 0.29805042
 0.         0.         0.         0.04967507 0.         0.
 0.         0.         0.         0.04967507 0.         0.
 0.         0.04967507 0.         0.04967507 0.         0.
 0.         0.04967507 0.         0.         0.         0.
 0.         0.         0.         0.         0.04967507 0.
 0.         0.04967507 0.         0.04967507 0.04967507 0.
 0.        ]
[0.21428571 0.46428571 0.07142857 0.28571429 0.75       0.28571429
 0.         0.         0.03571429 0.         0.         0.
 0.         0.         0.03571429 0.         0.         0.
 0.03571429 0.         0.         0.03571429 0.         0.
 0.         0.03571429 0.         0.03571429 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.12451456 0.2282767  0.04150485 0.14526699 0.93385921 0.18677184
 0.         0.02075243 0.         0.         0.         0.
 0.         0.         0.02075243 0.         0.         0.
 0.02075243 0.         0.         0.         0.02075243 0.
 0.02075243 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.02075243
 0.        ]
[0.35355339 0.57452426 0.08838835 0.35355339 0.57452426 0.26516504
 0.         0.         0.         0.04419417 0.         0.
 0.         0.         0.         0.04419417 0.         0.
 0.         0.04419417 0.         0.         0.04419417 0.04419417
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.04419417]
[0.56165596 0.61782155 0.0561656  0.33699357 0.33699357 0.22466238
 0.         0.         0.         0.0561656  0.         0.
 0.         0.         0.         0.0561656  0.         0.
 0.         0.0561656  0.0561656  0.         0.         0.
 0.         0.0561656  0.         0.         0.         0.
 0.         0.         0.         0.         0.0561656  0.0561656
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.20367003 0.32005291 0.0727393  0.20367003 0.87287156 0.20367003
 0.         0.02909572 0.         0.         0.         0.
 0.         0.         0.         0.02909572 0.         0.
 0.         0.02909572 0.         0.02909572 0.         0.
 0.         0.02909572 0.         0.         0.         0.
 0.         0.         0.         0.02909572 0.02909572 0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.3  0.8  0.05 0.35 0.1  0.35 0.   0.   0.   0.05 0.   0.   0.   0.
 0.05 0.   0.   0.05 0.   0.   0.   0.   0.05 0.   0.05 0.   0.   0.
 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
 0.  ]
[0.36893239 0.73786479 0.05270463 0.42163702 0.15811388 0.31622777
 0.         0.         0.         0.05270463 0.         0.
 0.         0.05270463 0.         0.         0.         0.
 0.         0.05270463 0.         0.05270463 0.         0.
 0.05270463 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.22233662 0.37056104 0.05558416 0.22233662 0.81523428 0.29644883
 0.         0.         0.0370561  0.         0.         0.
 0.         0.         0.0370561  0.         0.         0.
 0.0370561  0.         0.0370561  0.         0.         0.
 0.         0.0370561  0.         0.         0.         0.
 0.         0.         0.         0.0370561  0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.16527232 0.33054465 0.0495817  0.16527232 0.85941609 0.29749018
 0.         0.         0.03305446 0.         0.         0.
 0.         0.03305446 0.         0.         0.         0.03305446
 0.         0.         0.03305446 0.         0.         0.03305446
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.03305446 0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.20096614 0.31580393 0.04306417 0.17225669 0.8899929  0.17225669
 0.         0.         0.02870945 0.         0.         0.
 0.         0.         0.         0.02870945 0.         0.
 0.         0.02870945 0.         0.         0.02870945 0.02870945
 0.         0.         0.         0.         0.02870945 0.
 0.         0.         0.         0.02870945 0.         0.02870945
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.41111323 0.59383022 0.06851887 0.31975473 0.54815097 0.22839624
 0.         0.         0.         0.         0.         0.04567925
 0.         0.04567925 0.         0.         0.         0.
 0.         0.04567925 0.         0.         0.04567925 0.04567925
 0.         0.         0.         0.         0.04567925 0.
 0.         0.         0.         0.04567925 0.         0.04567925
 0.         0.         0.         0.         0.         0.
 0.04567925]
[0.29591818 0.42743737 0.06575959 0.26303838 0.78911514 0.16439899
 0.         0.         0.0328798  0.         0.         0.
 0.         0.0328798  0.         0.         0.         0.
 0.         0.0328798  0.         0.         0.0328798  0.0328798
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.0328798  0.
 0.        ]
[0.19310804 0.33104236 0.05517373 0.19310804 0.88277961 0.16552118
 0.         0.02758686 0.         0.         0.         0.
 0.         0.         0.         0.02758686 0.         0.
 0.         0.02758686 0.         0.02758686 0.         0.
 0.02758686 0.         0.         0.         0.02758686 0.
 0.         0.         0.         0.02758686 0.02758686 0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.32879797 0.65759595 0.07045671 0.32879797 0.46971139 0.32879797
 0.         0.         0.         0.04697114 0.         0.
 0.         0.         0.04697114 0.         0.         0.
 0.04697114 0.         0.04697114 0.         0.         0.
 0.         0.04697114 0.         0.         0.         0.04697114
 0.         0.         0.         0.         0.         0.
 0.04697114 0.         0.         0.         0.         0.
 0.04697114]
[0.26737317 0.40105975 0.08355412 0.23395152 0.8021195  0.23395152
 0.         0.         0.03342165 0.         0.         0.
 0.         0.         0.03342165 0.         0.         0.
 0.         0.03342165 0.03342165 0.         0.         0.
 0.         0.03342165 0.         0.         0.         0.
 0.         0.         0.         0.03342165 0.03342165 0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.35434522 0.6580697  0.07593112 0.35434522 0.40496597 0.35434522
 0.         0.         0.         0.05062075 0.         0.
 0.         0.         0.         0.05062075 0.         0.
 0.         0.05062075 0.         0.05062075 0.         0.
 0.05062075 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.05062075 0.         0.05062075 0.05062075 0.
 0.        ]
[0.20292219 0.27901802 0.06341319 0.22828747 0.8877846  0.17755692
 0.         0.02536527 0.         0.         0.         0.
 0.         0.         0.02536527 0.         0.         0.
 0.02536527 0.         0.         0.         0.02536527 0.
 0.02536527 0.         0.         0.         0.         0.
 0.02536527 0.         0.         0.         0.         0.
 0.02536527 0.         0.         0.         0.         0.02536527
 0.        ]
[0.28022427 0.36028835 0.04003204 0.24019223 0.80064077 0.28022427
 0.         0.         0.04003204 0.         0.         0.
 0.         0.         0.04003204 0.         0.         0.
 0.         0.04003204 0.04003204 0.         0.         0.
 0.         0.04003204 0.         0.         0.04003204 0.
 0.         0.04003204 0.         0.04003204 0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.36205026 0.54307539 0.06788442 0.31679398 0.63358795 0.22628141
 0.         0.         0.04525628 0.         0.         0.
 0.         0.04525628 0.         0.         0.         0.
 0.         0.04525628 0.         0.         0.04525628 0.
 0.         0.04525628 0.         0.         0.04525628 0.
 0.         0.0333005  0.         0.04525628 0.         0.0306465
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.20793863 0.35646622 0.0742638  0.17823311 0.86146003 0.20793863
 0.         0.         0.02970552 0.         0.         0.
 0.         0.         0.02970552 0.         0.         0.
 0.         0.02970552 0.         0.02970552 0.         0.
 0.         0.02970552 0.         0.         0.02970552 0.02970552
 0.         0.02970552 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.25529026 0.38293539 0.06382256 0.22337898 0.82969334 0.19146769
 0.         0.         0.03191128 0.         0.         0.
 0.         0.03191128 0.         0.         0.         0.
 0.         0.03191128 0.         0.         0.03191128 0.
 0.         0.03191128 0.         0.         0.03191128 0.
 0.         0.03191128 0.         0.03191128 0.03191128 0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.32929278 0.47564513 0.07317617 0.25611661 0.73176173 0.21952852
 0.         0.         0.03658809 0.         0.         0.
 0.         0.03658809 0.         0.         0.         0.
 0.         0.03658809 0.         0.         0.03658809 0.
 0.         0.03658809 0.         0.         0.03658809 0.
 0.         0.02692226 0.         0.03658809 0.         0.0247766
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.45958799 0.63193349 0.0574485  0.40213949 0.28724249 0.34469099
 0.         0.         0.         0.0574485  0.         0.
 0.         0.0574485  0.         0.         0.         0.
 0.         0.0574485  0.         0.         0.0574485  0.
 0.         0.0574485  0.         0.         0.0574485  0.
 0.         0.04227178 0.         0.         0.         0.03890278
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.21630814 0.37081395 0.07725291 0.2472093  0.83433138 0.21630814
 0.         0.         0.03090116 0.         0.         0.
 0.         0.         0.03090116 0.         0.         0.
 0.         0.03090116 0.         0.03090116 0.         0.
 0.         0.03090116 0.         0.03090116 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.28226724 0.4838867  0.08064778 0.28226724 0.72583005 0.24194335
 0.         0.         0.04032389 0.         0.         0.
 0.         0.04032389 0.         0.         0.         0.
 0.         0.04032389 0.         0.04032389 0.         0.
 0.         0.04032389 0.         0.         0.04032389 0.
 0.04032389 0.         0.         0.04032389 0.         0.04032389
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.30172571 0.45258857 0.07543143 0.26401    0.75431429 0.22629429
 0.         0.         0.03771571 0.         0.         0.
 0.         0.03771571 0.         0.         0.         0.
 0.         0.03771571 0.         0.03771571 0.         0.03771571
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.03771571 0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.29397237 0.54594868 0.08399211 0.33596842 0.62994079 0.29397237
 0.         0.         0.04199605 0.         0.         0.
 0.         0.         0.         0.04199605 0.         0.
 0.         0.04199605 0.         0.04199605 0.         0.
 0.         0.04199605 0.         0.         0.         0.
 0.03037769 0.         0.         0.04199605 0.         0.
 0.         0.         0.02899767 0.         0.         0.
 0.        ]
[0.24685344 0.30170975 0.0685704  0.21942528 0.8777011  0.1371408
 0.         0.02742816 0.         0.         0.         0.
 0.         0.         0.         0.02742816 0.         0.
 0.         0.02742816 0.         0.         0.02742816 0.
 0.         0.02742816 0.         0.         0.02742816 0.
 0.         0.         0.         0.02742816 0.02742816 0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.40050094 0.55068879 0.05006262 0.35043832 0.55068879 0.3003757
 0.         0.         0.         0.05006262 0.         0.
 0.         0.         0.05006262 0.         0.         0.
 0.         0.05006262 0.05006262 0.         0.         0.
 0.05006262 0.         0.         0.         0.         0.
 0.         0.         0.05006262 0.05006262 0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.30935922 0.57452426 0.08838835 0.35355339 0.57452426 0.30935922
 0.         0.         0.04419417 0.         0.         0.
 0.         0.         0.04419417 0.         0.         0.
 0.04419417 0.         0.         0.04419417 0.         0.
 0.         0.04419417 0.         0.         0.         0.
 0.04419417 0.         0.         0.         0.         0.
 0.04419417 0.         0.         0.         0.         0.04419417
 0.        ]
[0.22402285 0.30803142 0.07000714 0.25202571 0.86808855 0.16801714
 0.         0.02800286 0.         0.         0.         0.
 0.         0.         0.         0.02800286 0.         0.
 0.02800286 0.         0.         0.         0.02800286 0.02800286
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.02800286 0.         0.         0.         0.         0.
 0.        ]
[0.2502139  0.40659758 0.07819184 0.2502139  0.81319517 0.18766042
 0.         0.03127674 0.         0.         0.         0.
 0.         0.         0.03127674 0.         0.         0.
 0.         0.03127674 0.         0.03127674 0.         0.
 0.         0.03127674 0.         0.         0.         0.
 0.         0.         0.         0.03127674 0.         0.
 0.03127674 0.         0.         0.         0.         0.
 0.        ]
[0.21357251 0.39663467 0.0762759  0.24408287 0.82377969 0.21357251
 0.         0.03051036 0.         0.         0.         0.
 0.         0.         0.         0.03051036 0.         0.
 0.         0.03051036 0.         0.03051036 0.         0.
 0.         0.03051036 0.         0.         0.         0.
 0.         0.         0.         0.03051036 0.03051036 0.
 0.03051036 0.         0.         0.         0.         0.
 0.        ]
[0.16494577 0.30632786 0.04712736 0.18850945 0.8954199  0.18850945
 0.         0.02356368 0.         0.         0.         0.
 0.         0.02356368 0.         0.         0.         0.
 0.02356368 0.         0.         0.         0.02356368 0.
 0.02356368 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.02356368 0.         0.         0.         0.         0.02356368
 0.        ]
[0.2943724  0.32380965 0.05887448 0.23549792 0.85367997 0.11774896
 0.         0.02943724 0.         0.         0.         0.
 0.         0.02943724 0.         0.         0.         0.
 0.         0.02943724 0.         0.         0.02943724 0.02943724
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.02943724 0.02943724 0.
 0.         0.         0.         0.         0.02943724 0.
 0.        ]
[0.25846827 0.35539387 0.06461707 0.22615973 0.84002187 0.1938512
 0.         0.03230853 0.         0.         0.         0.
 0.         0.03230853 0.         0.         0.         0.
 0.         0.03230853 0.         0.         0.03230853 0.
 0.         0.03230853 0.         0.         0.         0.
 0.         0.         0.         0.03230853 0.03230853 0.
 0.         0.         0.         0.         0.03230853 0.
 0.        ]
[0.11669199 0.11669199 0.029173   0.08751899 0.97729544 0.08751899
 0.0145865  0.         0.         0.         0.         0.
 0.         0.         0.0145865  0.         0.         0.
 0.         0.0145865  0.0145865  0.         0.         0.
 0.         0.0145865  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.0145865  0.         0.         0.         0.         0.0145865
 0.        ]
[0.14302851 0.22475909 0.03064897 0.12259587 0.93990164 0.16346115
 0.         0.02043264 0.         0.         0.         0.
 0.         0.02043264 0.         0.         0.         0.
 0.         0.02043264 0.         0.         0.02043264 0.02043264
 0.         0.         0.         0.         0.         0.
 0.         0.         0.02043264 0.         0.         0.
 0.         0.         0.         0.         0.         0.02043264
 0.        ]
[0.12658608 0.1582326  0.03164652 0.11076282 0.96521887 0.11076282
 0.         0.01582326 0.         0.         0.         0.
 0.         0.         0.01582326 0.         0.         0.
 0.         0.01582326 0.         0.         0.01582326 0.
 0.         0.01582326 0.         0.01582326 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.01582326
 0.        ]
[0.19023425 0.29893953 0.05435264 0.19023425 0.8968186  0.16305793
 0.         0.02717632 0.         0.         0.         0.
 0.         0.         0.02717632 0.         0.         0.
 0.         0.02717632 0.         0.02717632 0.         0.
 0.02717632 0.         0.         0.         0.         0.02717632
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.26432744 0.39649116 0.06608186 0.19824558 0.82602325 0.19824558
 0.         0.         0.03304093 0.         0.         0.
 0.         0.         0.03304093 0.         0.         0.
 0.         0.03304093 0.         0.03304093 0.         0.
 0.         0.03304093 0.         0.         0.03304093 0.03304093
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.45042247 0.70065717 0.07507041 0.40037553 0.25023471 0.25023471
 0.         0.         0.         0.05004694 0.         0.
 0.         0.05004694 0.         0.         0.         0.
 0.         0.05004694 0.         0.05004694 0.         0.
 0.05004694 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.05004694 0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.24595493 0.45677344 0.07027284 0.24595493 0.77300121 0.24595493
 0.         0.         0.03513642 0.         0.         0.
 0.         0.         0.03513642 0.         0.         0.
 0.         0.03513642 0.         0.03513642 0.         0.
 0.03513642 0.         0.         0.         0.         0.03513642
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.35848857 0.53773286 0.08962214 0.3136775  0.627355   0.26886643
 0.         0.         0.04481107 0.         0.         0.
 0.         0.         0.         0.04481107 0.         0.
 0.         0.04481107 0.         0.04481107 0.         0.
 0.         0.04481107 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.24863792 0.37295688 0.07769935 0.21755818 0.83915299 0.18647844
 0.         0.03107974 0.         0.         0.         0.
 0.         0.03107974 0.         0.         0.         0.
 0.         0.03107974 0.         0.         0.03107974 0.
 0.         0.03107974 0.         0.         0.         0.
 0.         0.         0.         0.03107974 0.03107974 0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.23365758 0.37969356 0.07301799 0.20445038 0.84700871 0.17524318
 0.         0.0292072  0.         0.         0.         0.
 0.         0.0292072  0.         0.         0.         0.
 0.         0.0292072  0.         0.         0.0292072  0.0292072
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.0292072  0.0292072  0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.33099609 0.61470703 0.07092773 0.33099609 0.52013672 0.33099609
 0.         0.         0.04728516 0.         0.         0.
 0.         0.         0.         0.04728516 0.         0.
 0.         0.04728516 0.         0.04728516 0.         0.
 0.04728516 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.04728516 0.
 0.         0.04728516 0.         0.04728516 0.         0.
 0.        ]
[0.2731155  0.37553381 0.06827887 0.23897606 0.81934649 0.20483662
 0.         0.03413944 0.         0.         0.         0.
 0.         0.03413944 0.         0.         0.         0.
 0.         0.03413944 0.         0.03413944 0.         0.
 0.03413944 0.         0.         0.         0.         0.
 0.         0.         0.         0.03413944 0.03413944 0.03413944
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.1258049  0.1258049  0.03594426 0.10783277 0.97049496 0.10783277
 0.01797213 0.         0.         0.         0.         0.
 0.         0.         0.         0.01797213 0.         0.
 0.         0.01797213 0.01797213 0.         0.         0.
 0.         0.01797213 0.         0.         0.         0.01797213
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.3800477  0.70580288 0.08143879 0.3800477  0.21717012 0.3800477
 0.         0.         0.         0.05429253 0.         0.
 0.         0.         0.05429253 0.         0.         0.05429253
 0.         0.         0.         0.         0.05429253 0.
 0.05429253 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.42600643 0.66943868 0.06085806 0.42600643 0.18257419 0.36514837
 0.         0.         0.         0.06085806 0.         0.
 0.         0.         0.         0.06085806 0.         0.
 0.         0.06085806 0.         0.06085806 0.         0.
 0.         0.06085806 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.4113396  0.66842685 0.07712617 0.4113396  0.3085047  0.3085047
 0.         0.         0.         0.05141745 0.         0.
 0.         0.05141745 0.         0.         0.         0.
 0.         0.05141745 0.         0.05141745 0.         0.05141745
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.05141745 0.05141745 0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.32734967 0.53194321 0.06137806 0.32734967 0.65469934 0.24551225
 0.         0.         0.04091871 0.         0.         0.
 0.         0.04091871 0.         0.         0.         0.
 0.         0.04091871 0.         0.04091871 0.         0.04091871
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.04091871 0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.29009704 0.53875164 0.06216365 0.29009704 0.66307894 0.29009704
 0.         0.         0.04144243 0.         0.         0.
 0.         0.04144243 0.         0.         0.         0.
 0.         0.04144243 0.         0.04144243 0.         0.
 0.04144243 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.04144243 0.
 0.         0.04144243 0.         0.04144243 0.         0.
 0.        ]
[0.13882344 0.25450965 0.04627448 0.13882344 0.92548963 0.18509793
 0.         0.02313724 0.         0.         0.         0.
 0.         0.         0.         0.         0.02313724 0.
 0.02313724 0.         0.         0.02313724 0.         0.
 0.02313724 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.02313724 0.
 0.         0.         0.         0.         0.         0.02313724
 0.        ]
[0.13271219 0.24330568 0.0442374  0.15483088 0.92898531 0.17694958
 0.         0.0221187  0.         0.         0.         0.
 0.         0.         0.         0.0221187  0.         0.
 0.0221187  0.         0.         0.         0.0221187  0.
 0.         0.0221187  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.0221187
 0.        ]
[0.28724249 0.31596674 0.0574485  0.229794   0.86172748 0.114897
 0.         0.02872425 0.         0.         0.         0.
 0.         0.         0.         0.02872425 0.         0.
 0.         0.02872425 0.         0.         0.02872425 0.02872425
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.02872425 0.02872425 0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.36135801 0.67109345 0.07743386 0.36135801 0.36135801 0.36135801
 0.         0.         0.         0.05162257 0.         0.
 0.         0.         0.         0.05162257 0.         0.
 0.         0.05162257 0.         0.05162257 0.         0.
 0.05162257 0.         0.         0.         0.05162257 0.
 0.         0.         0.         0.         0.         0.
 0.         0.05162257 0.         0.05162257 0.         0.
 0.        ]
[0.12663365 0.14246286 0.03165841 0.11080444 0.96558158 0.12663365
 0.01582921 0.         0.         0.         0.         0.
 0.         0.01582921 0.         0.         0.         0.
 0.         0.01582921 0.01582921 0.         0.         0.01582921
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.01582921 0.         0.01582921 0.         0.         0.01582921
 0.        ]
[0.315353   0.68326483 0.05255883 0.36791183 0.315353   0.42047066
 0.         0.         0.         0.05255883 0.         0.
 0.         0.         0.         0.         0.05255883 0.05255883
 0.         0.         0.         0.05255883 0.         0.
 0.05255883 0.         0.         0.         0.         0.
 0.         0.         0.         0.05255883 0.05255883 0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.39740056 0.69545098 0.07451261 0.39740056 0.29805042 0.29805042
 0.         0.         0.         0.04967507 0.         0.
 0.         0.04967507 0.         0.         0.         0.
 0.         0.04967507 0.         0.04967507 0.         0.
 0.04967507 0.         0.         0.         0.         0.
 0.         0.         0.04967507 0.04967507 0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.4395538  0.71427493 0.05494423 0.38460958 0.13736056 0.32966535
 0.         0.         0.         0.05494423 0.         0.
 0.         0.         0.         0.         0.05494423 0.05494423
 0.         0.         0.         0.05494423 0.         0.
 0.05494423 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.05494423 0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.33136675 0.7100716  0.07100716 0.37870485 0.33136675 0.33136675
 0.         0.         0.         0.         0.         0.04733811
 0.         0.         0.04733811 0.         0.         0.
 0.04733811 0.         0.         0.04733811 0.         0.
 0.         0.04733811 0.         0.         0.04733811 0.
 0.         0.         0.         0.         0.         0.
 0.         0.04733811 0.         0.04733811 0.         0.
 0.        ]
[0.07562141 0.11343211 0.01890535 0.07562141 0.9830783  0.08822498
 0.01260357 0.         0.         0.         0.         0.
 0.         0.         0.01260357 0.         0.         0.
 0.         0.01260357 0.01260357 0.         0.         0.
 0.         0.01260357 0.         0.         0.01260357 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.01260357
 0.        ]
[0.32432432 0.7027027  0.08108108 0.37837838 0.21621622 0.43243243
 0.         0.         0.         0.05405405 0.         0.
 0.         0.         0.05405405 0.         0.         0.05405405
 0.         0.         0.         0.05405405 0.         0.
 0.05405405 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.05405405 0.         0.         0.         0.         0.
 0.        ]
[0.41025641 0.61538462 0.07692308 0.41025641 0.41025641 0.30769231
 0.         0.         0.         0.05128205 0.         0.
 0.         0.05128205 0.         0.         0.         0.
 0.         0.05128205 0.         0.05128205 0.         0.
 0.         0.05128205 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.05128205 0.         0.         0.         0.         0.
 0.        ]
[0.08404977 0.11206636 0.0140083  0.07004148 0.98058068 0.11206636
 0.         0.0140083  0.         0.         0.         0.
 0.         0.         0.         0.0140083  0.         0.
 0.         0.0140083  0.0140083  0.         0.         0.
 0.         0.0140083  0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.0140083
 0.        ]
[0.14246286 0.14246286 0.03165841 0.11080444 0.96558158 0.11080444
 0.01582921 0.         0.         0.         0.         0.
 0.         0.01582921 0.         0.         0.         0.
 0.         0.01582921 0.         0.         0.01582921 0.
 0.         0.01582921 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.01582921
 0.        ]
[0.40971802 0.71700653 0.07682213 0.35850326 0.25607376 0.30728851
 0.         0.         0.         0.05121475 0.         0.
 0.         0.         0.05121475 0.         0.         0.
 0.         0.05121475 0.         0.05121475 0.         0.
 0.05121475 0.         0.         0.         0.05121475 0.
 0.         0.         0.         0.         0.         0.
 0.         0.05121475 0.05121475 0.05121475 0.         0.
 0.        ]
[0.37838702 0.56758052 0.09459675 0.33108864 0.56758052 0.28379026
 0.         0.         0.04729838 0.         0.         0.
 0.         0.         0.         0.04729838 0.         0.
 0.         0.04729838 0.         0.04729838 0.         0.
 0.         0.04729838 0.         0.         0.         0.
 0.04729838 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.24282731 0.41627539 0.06937923 0.24282731 0.79786116 0.24282731
 0.         0.         0.03468962 0.         0.         0.
 0.         0.         0.         0.03468962 0.         0.
 0.         0.03468962 0.         0.         0.03468962 0.
 0.         0.03468962 0.         0.         0.         0.03468962
 0.         0.         0.         0.         0.03468962 0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.36639675 0.62810871 0.10468478 0.36639675 0.41873914 0.36639675
 0.         0.         0.         0.05234239 0.         0.
 0.         0.05234239 0.         0.         0.         0.
 0.         0.05234239 0.05234239 0.         0.         0.
 0.         0.05234239 0.         0.         0.         0.
 0.         0.         0.         0.05234239 0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.22430886 0.28038608 0.05607722 0.16823165 0.89723545 0.16823165
 0.         0.02803861 0.         0.         0.         0.
 0.         0.         0.         0.         0.02803861 0.
 0.         0.02803861 0.         0.         0.02803861 0.02803861
 0.         0.         0.         0.         0.02803861 0.
 0.02803861 0.02803861 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.17411804 0.24874006 0.06218501 0.14924403 0.92033821 0.17411804
 0.         0.02487401 0.         0.         0.         0.
 0.         0.         0.         0.         0.02487401 0.
 0.         0.02487401 0.         0.         0.02487401 0.02487401
 0.         0.         0.         0.         0.02487401 0.02487401
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.4776704  0.68996836 0.05307449 0.42459591 0.15922347 0.26537245
 0.         0.         0.         0.05307449 0.         0.
 0.         0.         0.         0.05307449 0.         0.
 0.         0.05307449 0.         0.05307449 0.         0.
 0.05307449 0.         0.         0.         0.         0.
 0.         0.         0.05307449 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.35478744 0.70957488 0.05913124 0.2956562  0.2956562  0.41391868
 0.         0.         0.         0.05913124 0.         0.
 0.         0.         0.         0.         0.05913124 0.
 0.05913124 0.         0.05913124 0.         0.         0.
 0.         0.05913124 0.         0.         0.         0.
 0.04277236 0.         0.         0.         0.         0.
 0.         0.         0.04082926 0.         0.         0.
 0.        ]
[0.41602515 0.5547002  0.09245003 0.36980013 0.5547002  0.23112508
 0.         0.         0.         0.04622502 0.         0.
 0.         0.         0.         0.04622502 0.         0.
 0.         0.04622502 0.         0.         0.04622502 0.
 0.         0.04622502 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.04622502]
[0.30875676 0.52929731 0.08821622 0.26464865 0.66162164 0.30875676
 0.         0.         0.         0.04410811 0.         0.
 0.         0.04410811 0.         0.         0.         0.
 0.         0.04410811 0.         0.         0.04410811 0.04410811
 0.         0.         0.         0.         0.         0.04410811
 0.         0.         0.04410811 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.26141979 0.44814821 0.07469137 0.29876547 0.74691369 0.26141979
 0.         0.         0.03734568 0.         0.         0.
 0.         0.         0.         0.03734568 0.         0.
 0.         0.03734568 0.         0.03734568 0.         0.
 0.         0.03734568 0.         0.         0.         0.03734568
 0.03734568 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.26215421 0.39323132 0.08192319 0.22938494 0.81923192 0.19661566
 0.         0.         0.03276928 0.         0.         0.
 0.         0.         0.         0.03276928 0.         0.
 0.         0.03276928 0.         0.         0.03276928 0.
 0.         0.03276928 0.         0.         0.03276928 0.
 0.         0.         0.         0.03276928 0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.44513191 0.66769786 0.05564149 0.38949042 0.16692447 0.38949042
 0.         0.         0.         0.05564149 0.         0.
 0.         0.05564149 0.         0.         0.         0.
 0.         0.05564149 0.         0.         0.05564149 0.05564149
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.05564149 0.
 0.05564149 0.         0.         0.         0.         0.
 0.        ]
[0.37785906 0.70848573 0.07084857 0.37785906 0.33062668 0.28339429
 0.         0.         0.         0.04723238 0.         0.
 0.         0.         0.         0.         0.04723238 0.
 0.         0.04723238 0.         0.04723238 0.         0.
 0.04723238 0.         0.         0.         0.         0.
 0.         0.         0.04723238 0.04723238 0.04723238 0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.31622777 0.42163702 0.07027284 0.28109135 0.77300121 0.17568209
 0.         0.03513642 0.         0.         0.         0.
 0.         0.         0.         0.         0.03513642 0.
 0.         0.03513642 0.         0.         0.03513642 0.
 0.         0.03513642 0.         0.         0.         0.
 0.         0.         0.03513642 0.03513642 0.03513642 0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.44020439 0.73367398 0.0489116  0.39129279 0.1956464  0.24455799
 0.         0.         0.         0.         0.         0.
 0.0489116  0.         0.         0.         0.0489116  0.
 0.         0.0489116  0.         0.0489116  0.         0.
 0.0489116  0.         0.         0.         0.         0.
 0.         0.         0.0489116  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.29686613 0.50891336 0.08481889 0.33927557 0.6361417  0.33927557
 0.         0.         0.04240945 0.         0.         0.
 0.         0.         0.         0.04240945 0.         0.
 0.         0.04240945 0.         0.04240945 0.         0.
 0.         0.04240945 0.         0.         0.         0.04240945
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.32102894 0.44141479 0.08025724 0.32102894 0.72231512 0.24077171
 0.         0.         0.04012862 0.         0.         0.
 0.         0.04012862 0.         0.         0.         0.
 0.         0.04012862 0.         0.         0.04012862 0.
 0.         0.04012862 0.         0.04012862 0.         0.
 0.         0.         0.         0.04012862 0.04012862 0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.24034556 0.41202096 0.0858377  0.27468064 0.78970684 0.24034556
 0.         0.         0.03433508 0.         0.         0.
 0.         0.         0.         0.03433508 0.         0.
 0.         0.03433508 0.         0.03433508 0.         0.
 0.         0.03433508 0.         0.         0.         0.
 0.         0.         0.         0.03433508 0.         0.
 0.03433508 0.         0.         0.         0.         0.
 0.        ]
[0.42884501 0.64326752 0.05360563 0.37523939 0.37523939 0.32163376
 0.         0.         0.         0.05360563 0.         0.
 0.         0.         0.         0.05360563 0.         0.
 0.         0.05360563 0.05360563 0.         0.         0.
 0.         0.05360563 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.12448502 0.17783575 0.03556715 0.10670145 0.96031304 0.12448502
 0.01778357 0.         0.         0.         0.         0.
 0.         0.01778357 0.         0.         0.         0.
 0.         0.01778357 0.01778357 0.         0.         0.01778357
 0.         0.         0.         0.01778357 0.         0.
 0.         0.         0.01778357 0.         0.         0.
 0.         0.         0.         0.         0.         0.01778357
 0.        ]
[0.34655164 0.74261066 0.09901475 0.34655164 0.24753689 0.34655164
 0.         0.         0.         0.         0.         0.04950738
 0.         0.         0.04950738 0.         0.         0.
 0.         0.04950738 0.         0.         0.04950738 0.
 0.         0.04950738 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.04950738 0.         0.04950738 0.         0.
 0.        ]
[0.26247149 0.39370723 0.06561787 0.19685361 0.82022339 0.22966255
 0.         0.         0.03280894 0.         0.         0.
 0.         0.         0.         0.03280894 0.         0.
 0.         0.03280894 0.         0.03280894 0.         0.
 0.         0.03280894 0.         0.         0.         0.03280894
 0.         0.         0.         0.         0.03280894 0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.15103004 0.27688842 0.06292919 0.20137339 0.90618027 0.17620172
 0.         0.02517167 0.         0.         0.         0.
 0.         0.         0.         0.02517167 0.         0.
 0.02517167 0.         0.         0.         0.02517167 0.
 0.         0.02517167 0.         0.         0.         0.02517167
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.16191735 0.20817945 0.0462621  0.1850484  0.925242   0.1850484
 0.         0.02313105 0.         0.         0.         0.
 0.         0.         0.         0.02313105 0.         0.
 0.02313105 0.         0.02313105 0.         0.         0.02313105
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.02313105 0.         0.         0.         0.         0.02313105
 0.        ]
[0.12904635 0.11470787 0.02867697 0.0860309  0.97501687 0.10036938
 0.01433848 0.         0.         0.         0.         0.
 0.         0.01433848 0.         0.         0.         0.
 0.         0.01433848 0.         0.         0.01433848 0.01433848
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.01433848
 0.        ]
[0.21563073 0.43126145 0.08984614 0.25156918 0.79064599 0.25156918
 0.         0.         0.03593845 0.         0.         0.
 0.         0.         0.         0.03593845 0.         0.03593845
 0.         0.         0.         0.         0.03593845 0.
 0.         0.03593845 0.         0.         0.         0.03593845
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.32328954 0.43105272 0.07184212 0.25144742 0.75434227 0.25144742
 0.         0.         0.03592106 0.         0.         0.
 0.         0.03592106 0.         0.         0.         0.
 0.         0.03592106 0.         0.         0.03592106 0.03592106
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.03592106 0.
 0.         0.         0.         0.         0.         0.03592106
 0.        ]
[0.36099744 0.67042381 0.10314212 0.36099744 0.36099744 0.36099744
 0.         0.         0.         0.05157106 0.         0.
 0.         0.         0.         0.05157106 0.         0.05157106
 0.         0.         0.         0.         0.05157106 0.
 0.         0.05157106 0.         0.         0.         0.
 0.05157106 0.         0.         0.05157106 0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.13845335 0.18460446 0.04615112 0.13845335 0.94609787 0.1615289
 0.         0.02307556 0.         0.         0.         0.
 0.         0.         0.         0.02307556 0.         0.
 0.         0.02307556 0.         0.         0.02307556 0.
 0.         0.02307556 0.         0.         0.         0.02307556
 0.         0.         0.         0.         0.         0.
 0.         0.         0.02307556 0.         0.02307556 0.
 0.        ]
[0.36428206 0.62448354 0.07806044 0.31224177 0.46836265 0.36428206
 0.         0.         0.         0.05204029 0.         0.
 0.         0.         0.         0.05204029 0.         0.
 0.         0.05204029 0.05204029 0.         0.         0.
 0.         0.05204029 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.05204029 0.         0.05204029 0.05204029 0.
 0.        ]
[0.42664092 0.56885456 0.09480909 0.37923637 0.52145001 0.23702273
 0.         0.         0.04740455 0.         0.         0.
 0.         0.04740455 0.         0.         0.         0.
 0.         0.04740455 0.         0.         0.04740455 0.04740455
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.04740455 0.
 0.        ]
[0.34655164 0.6435959  0.09901475 0.34655164 0.44556639 0.34655164
 0.         0.         0.         0.04950738 0.         0.
 0.         0.         0.         0.04950738 0.         0.04950738
 0.         0.         0.         0.         0.04950738 0.
 0.         0.04950738 0.         0.         0.         0.
 0.         0.         0.         0.04950738 0.         0.
 0.         0.         0.04950738 0.         0.         0.
 0.        ]
[0.41702883 0.72980045 0.0521286  0.31277162 0.20851441 0.36490022
 0.         0.         0.         0.0521286  0.         0.
 0.         0.         0.         0.         0.0521286  0.
 0.         0.0521286  0.         0.         0.0521286  0.
 0.         0.0521286  0.         0.         0.         0.
 0.         0.         0.         0.         0.02765125 0.
 0.         0.         0.         0.         0.         0.
 0.04419049]
[0.29033379 0.43550069 0.09072931 0.25404207 0.7621262  0.25404207
 0.         0.         0.03629172 0.         0.         0.
 0.         0.         0.         0.03629172 0.         0.
 0.         0.03629172 0.         0.         0.03629172 0.
 0.         0.03629172 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.03629172
 0.        ]
[0.37837838 0.7027027  0.08108108 0.37837838 0.21621622 0.37837838
 0.         0.         0.         0.05405405 0.         0.
 0.         0.05405405 0.         0.         0.         0.
 0.         0.05405405 0.         0.05405405 0.         0.
 0.         0.05405405 0.         0.         0.         0.
 0.         0.         0.         0.         0.05405405 0.
 0.         0.05405405 0.         0.05405405 0.         0.
 0.        ]
[0.35992215 0.66842685 0.07712617 0.3085047  0.4113396  0.35992215
 0.         0.         0.         0.05141745 0.         0.
 0.         0.         0.         0.05141745 0.         0.05141745
 0.         0.         0.         0.         0.05141745 0.
 0.         0.05141745 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.05141745 0.         0.05141745 0.05141745 0.
 0.05141745]
[0.24209101 0.48418203 0.10087126 0.28243952 0.72627304 0.28243952
 0.         0.         0.0403485  0.         0.         0.
 0.         0.         0.0403485  0.         0.         0.
 0.0403485  0.         0.         0.         0.0403485  0.
 0.0403485  0.         0.         0.         0.         0.0403485
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.36051834 0.66953406 0.10300524 0.36051834 0.36051834 0.36051834
 0.         0.         0.         0.05150262 0.         0.
 0.         0.         0.05150262 0.         0.         0.
 0.         0.05150262 0.         0.         0.05150262 0.
 0.         0.05150262 0.         0.         0.05150262 0.
 0.         0.         0.         0.         0.         0.
 0.         0.05150262 0.         0.05150262 0.         0.
 0.        ]
[0.37754334 0.56631501 0.09438584 0.33035042 0.56631501 0.28315751
 0.         0.         0.04719292 0.         0.         0.
 0.         0.04719292 0.         0.         0.         0.
 0.         0.04719292 0.         0.         0.04719292 0.
 0.         0.04719292 0.         0.         0.         0.
 0.         0.         0.         0.         0.04719292 0.
 0.         0.04719292 0.         0.04719292 0.         0.
 0.        ]
[0.30406057 0.52124669 0.08687445 0.34749779 0.65155836 0.26062335
 0.         0.         0.04343722 0.         0.         0.
 0.         0.         0.         0.         0.04343722 0.
 0.         0.04343722 0.         0.         0.04343722 0.
 0.         0.04343722 0.         0.04343722 0.         0.
 0.         0.         0.         0.04343722 0.04343722 0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.19223226 0.32954102 0.0549235  0.19223226 0.87877606 0.19223226
 0.         0.02746175 0.         0.         0.         0.
 0.         0.02746175 0.         0.         0.         0.
 0.         0.02746175 0.         0.         0.02746175 0.
 0.         0.02746175 0.         0.         0.         0.
 0.         0.         0.         0.02746175 0.02746175 0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.29606845 0.50754592 0.08459099 0.29606845 0.6767279  0.29606845
 0.         0.         0.04229549 0.         0.         0.
 0.         0.         0.04229549 0.         0.         0.
 0.         0.04229549 0.04229549 0.         0.         0.
 0.         0.04229549 0.         0.         0.04229549 0.
 0.         0.         0.         0.         0.         0.
 0.         0.04229549 0.         0.04229549 0.         0.
 0.        ]
[0.28446279 0.37928372 0.06321395 0.25285582 0.8217814  0.15803489
 0.         0.03160698 0.         0.         0.         0.
 0.         0.         0.         0.         0.03160698 0.
 0.         0.03160698 0.         0.         0.03160698 0.
 0.         0.03160698 0.         0.         0.         0.
 0.         0.         0.03160698 0.03160698 0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.29449221 0.63105474 0.08414063 0.29449221 0.58898443 0.2524219
 0.         0.         0.04207032 0.         0.         0.
 0.         0.04207032 0.         0.         0.         0.
 0.         0.04207032 0.         0.         0.04207032 0.
 0.         0.04207032 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.04207032 0.         0.         0.         0.         0.
 0.        ]
[0.29160339 0.4582339  0.06248644 0.24994576 0.74983729 0.24994576
 0.         0.         0.04165763 0.         0.         0.
 0.         0.04165763 0.         0.         0.         0.
 0.         0.04165763 0.         0.         0.04165763 0.
 0.         0.04165763 0.         0.         0.04165763 0.
 0.         0.         0.         0.04165763 0.         0.04165763
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.36706517 0.55059776 0.09176629 0.36706517 0.55059776 0.32118203
 0.         0.         0.04588315 0.         0.         0.
 0.         0.         0.         0.04588315 0.         0.
 0.         0.04588315 0.         0.04588315 0.         0.
 0.         0.04588315 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.04588315 0.         0.         0.
 0.        ]
[0.26490647 0.52981294 0.08830216 0.30905755 0.66226618 0.30905755
 0.         0.         0.04415108 0.         0.         0.
 0.         0.         0.         0.04415108 0.         0.
 0.04415108 0.         0.         0.         0.04415108 0.
 0.         0.04415108 0.         0.         0.         0.04415108
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.14643839 0.2091977  0.04183954 0.12551862 0.94138963 0.16735816
 0.         0.02091977 0.         0.         0.         0.
 0.         0.02091977 0.         0.         0.         0.
 0.02091977 0.         0.         0.         0.02091977 0.
 0.         0.02091977 0.         0.         0.         0.
 0.02091977 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.02091977
 0.        ]
[0.39305989 0.73698729 0.07369873 0.39305989 0.09826497 0.3439274
 0.         0.         0.         0.         0.         0.
 0.04913249 0.         0.         0.04913249 0.         0.
 0.         0.04913249 0.         0.04913249 0.         0.
 0.04913249 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.04913249 0.         0.
 0.        ]
[0.29897404 0.44846106 0.07474351 0.26160228 0.74743509 0.26160228
 0.         0.         0.03737175 0.         0.         0.
 0.         0.         0.         0.03737175 0.         0.
 0.         0.03737175 0.         0.         0.03737175 0.
 0.         0.03737175 0.         0.         0.         0.03737175
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.33075929 0.53748385 0.08268982 0.28941438 0.66151858 0.24806947
 0.         0.         0.04134491 0.         0.         0.
 0.         0.04134491 0.         0.         0.         0.
 0.         0.04134491 0.         0.         0.04134491 0.
 0.         0.04134491 0.         0.         0.         0.
 0.         0.         0.         0.04134491 0.         0.04134491
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.33630146 0.67260292 0.0720646  0.33630146 0.43238759 0.33630146
 0.         0.         0.04804307 0.         0.         0.
 0.         0.         0.         0.04804307 0.         0.
 0.         0.04804307 0.         0.         0.04804307 0.
 0.         0.04804307 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.04804307 0.         0.04804307 0.         0.
 0.        ]
[0.40444811 0.65722818 0.07583402 0.3538921  0.3538921  0.3538921
 0.         0.         0.         0.05055601 0.         0.
 0.         0.         0.         0.05055601 0.         0.
 0.         0.05055601 0.         0.         0.05055601 0.
 0.         0.05055601 0.         0.         0.         0.
 0.         0.         0.         0.         0.05055601 0.
 0.         0.05055601 0.         0.05055601 0.05055601 0.
 0.        ]
[0.35310329 0.65576325 0.10088665 0.40354662 0.40354662 0.30265996
 0.         0.         0.05044333 0.         0.         0.
 0.         0.         0.05044333 0.         0.         0.
 0.         0.05044333 0.         0.05044333 0.         0.
 0.05044333 0.         0.         0.         0.05044333 0.05044333
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.34197238 0.68394476 0.09770639 0.34197238 0.39082557 0.34197238
 0.         0.         0.         0.0488532  0.         0.
 0.         0.         0.         0.0488532  0.         0.
 0.         0.0488532  0.         0.         0.0488532  0.
 0.         0.0488532  0.         0.         0.0488532  0.
 0.         0.         0.         0.         0.         0.
 0.         0.0488532  0.         0.0488532  0.         0.
 0.        ]
[0.35434522 0.6580697  0.07593112 0.35434522 0.40496597 0.35434522
 0.         0.         0.         0.05062075 0.         0.
 0.         0.         0.         0.05062075 0.         0.
 0.05062075 0.         0.05062075 0.         0.         0.
 0.         0.05062075 0.         0.         0.         0.05062075
 0.         0.         0.         0.         0.05062075 0.
 0.05062075 0.         0.         0.         0.         0.
 0.        ]
[0.26215206 0.48685383 0.07490059 0.26215206 0.74900589 0.22470177
 0.         0.         0.03745029 0.         0.         0.
 0.         0.03745029 0.         0.         0.         0.
 0.         0.03745029 0.         0.         0.03745029 0.
 0.         0.03745029 0.         0.         0.         0.
 0.         0.         0.         0.03745029 0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.22036999 0.47222141 0.06296286 0.25185142 0.78703569 0.18888857
 0.         0.         0.         0.         0.03148143 0.
 0.         0.         0.03148143 0.         0.         0.
 0.03148143 0.         0.         0.         0.03148143 0.
 0.03148143 0.         0.         0.         0.         0.
 0.         0.         0.         0.03148143 0.         0.
 0.         0.         0.         0.         0.         0.
 0.        ]
[0.43823283 0.71212835 0.0547791  0.38345372 0.13694776 0.32867462
 0.         0.         0.         0.         0.         0.
 0.0547791  0.0547791  0.         0.         0.         0.
 0.         0.0547791  0.         0.         0.0547791  0.
 0.         0.0547791  0.         0.         0.0547791  0.
 0.         0.         0.         0.         0.02905719 0.
 0.         0.         0.         0.0547791  0.         0.
 0.04643738]
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="11">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler().fit(rows)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>rows <span class="op">=</span> scaler.transform(rows)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> row <span class="kw">in</span> rows:</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(row)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>[ 0.77189025  1.42037847  0.52116729  1.51760333 -1.69856973  0.7942398
 -0.21315135 -0.58520895 -0.72623981  1.62254756 -0.07955573 -0.19783992
 -0.13847468  2.09643125 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  1.15688447 -0.38664604  1.68217556 -0.85993719 -0.45378342
 -0.50225489  1.39940306 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
  3.88361979 -0.38708024  4.19141327 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-1.23584229 -0.23772758 -0.07603596 -1.51797776  0.71078151  0.20774376
 -0.21315135  2.27151766 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369 -0.65668302  2.28288645  2.29583294
 -0.37459955 -1.58208151 -0.38664604 -0.7495916   0.81949636  2.01544852
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491  1.9770728
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  0.41368092 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
  2.43421407]
[ 0.05322179 -0.1907435   0.27882683 -0.19198499  0.47841837 -0.36490715
 -0.21315135 -0.58520895  1.23423547 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  1.28227901 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.34750724 -0.38664604  0.96357701 -0.85993719 -0.45378342
 -0.50225489  0.66510091 -0.07955573 -0.21787083  1.89929457 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278  1.84858437 -0.27377333  1.6711374  -0.26395713 -0.41534171
 -0.265011  ]
[-1.65386847 -1.37059544 -1.34644295 -1.38216957  1.11870537 -0.7788268
 -0.21315135  1.20316473 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  0.3915856  -0.31989356 -0.29128286
  1.34314804 -1.58208151  1.13212255 -0.7495916  -0.85993719  1.09201007
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713  1.97069827
 -0.265011  ]
[-1.13142124 -1.10021516  0.39278485 -1.32179642  1.00823326 -0.59734771
 -0.21315135  1.58211306 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  0.67459108 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955 -0.25661659 -0.38664604 -0.7495916   0.41420409 -0.45378342
 -0.50225489 -1.08550575 12.56980509 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713  2.4762894
 -0.265011  ]
[-1.1222852  -1.28658733 -1.20643447 -1.51676124  1.09979144 -1.1806346
 -0.21315135  1.32090531 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  0.79910047 -0.65668302 -0.31989356 -0.29128286
 -0.37459955 -0.41636291 -0.38664604 -0.7495916   0.26064335 -0.45378342
 -0.50225489 -0.02791524 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713  2.12778722
 -0.265011  ]
[ 1.01750993  0.72726889  0.94496082  1.22019759 -0.49759691 -0.41661352
 -0.21315135 -0.58520895 -0.72623981 -0.61684322 -0.07955573  4.63832538
 -0.13847468  1.626893   -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.69010007 -0.38664604  1.26774508 -0.85993719  2.7575947
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  1.77585374  1.87014524 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.62521166 -0.7518436   0.14528823 -1.12253968  0.89291165 -0.99628463
 -0.21315135 -0.58520895  0.78631781 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  1.16619909 -0.65668302 -0.31989356 -0.29128286
 -0.37459955 -0.09335365 -0.38664604  0.5721625  -0.85993719 -0.45378342
 -0.50225489  0.26513277 -0.07955573 -0.21787083 -0.44978491  1.62038669
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.0505006   0.51349787  1.69955229  0.95663734 -0.15468653  0.42753993
 -0.21315135 -0.58520895  1.43604057 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.38310443 -0.31989356 -0.29128286
 -0.37459955  0.54613297 -0.38664604  1.13992514 -0.85993719 -0.45378342
 -0.50225489  0.84530279 -0.07955573  5.46616297 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  1.71429973 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.38448408 -0.20377361  0.52548945  0.07230672  0.52315641 -0.37956928
 -0.21315135 -0.58520895  0.9452518  -0.61684322 -0.07955573 -0.19783992
 -0.13847468  0.99617013 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.06307639 -0.38664604 -0.7495916   0.72151816  1.87139346
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.85292837  1.21286037  0.60893205  1.04616137 -1.1655715   0.88043103
 -0.21315135 -0.58520895 -0.72623981  1.67175365 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  2.02616193 -0.31989356 -0.29128286
 -0.37459955  1.21706772 -0.38664604  1.73560873 -0.85993719 -0.45378342
  2.35870873 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278  2.85607656 -0.27377333  2.61576241 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.01038213  0.84957205  1.4572801   0.15521368 -0.6381989   2.31881042
 -0.21315135 -0.58520895 -0.72623981 -0.61684322 -0.07955573  5.19913501
 -0.13847468 -0.65869356  2.35604144 -0.65668302 -0.31989356  3.46358529
 -0.37459955 -1.58208151 -0.38664604  1.50167874 -0.85993719 -0.45378342
  2.08940843 -1.08550575 -0.07955573 -0.21787083 -0.44978491  3.06579695
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.12449082 -0.53012799 -1.70938005 -1.09443463  0.70058368 -0.09728238
 -0.21315135 -0.58520895  1.11690544 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  1.53599132 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.2320257   2.13248925 -0.7495916  -0.85993719 -0.45378342
 -0.50225489  0.56033104 -0.07955573 -0.21787083 -0.44978491  2.06960711
 -0.25005089 -0.21161747  2.8472056  -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
  3.04123996]
[ 1.34259802  0.745185    1.31007289  0.5631962  -0.69394527  0.98183086
 -0.21315135 -0.58520895 -0.72623981 -0.61684322 -0.07955573  5.03799483
 -0.13847468 -0.65869356  2.26999884 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.87787726 -0.38664604 -0.7495916   1.50476894 -0.45378342
 -0.50225489  1.14627561 -0.07955573 -0.21787083  2.54496653  2.96127314
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.09764694 -0.12126293  0.08820313  0.0409787   0.46168586 -0.50531167
 -0.21315135 -0.58520895  1.1346284  -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369 -0.65668302  2.40872602 -0.29128286
 -0.37459955  0.24946944 -0.38664604  0.876535   -0.85993719  2.13483128
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  0.46218329 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247  2.94747798 -0.41534171
  2.56471657]
[-0.91474589 -1.66568489 -1.78715334 -1.29337548  1.15508666 -1.74863949
 -0.21315135  1.30513348 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  0.50419987 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955 -0.42600846  1.21871907 -0.7495916  -0.85993719  1.18014748
 -0.50225489 -1.08550575 -0.07955573  2.8697683  -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  0.66194903 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713  2.10674451
 -0.265011  ]
[ 1.87274623  1.16740615 -0.78377713  1.56189272 -1.69055357  0.17295487
 -0.21315135 -0.58520895 -0.72623981  1.64480006 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369 -0.65668302  3.80112762 -0.29128286
 -0.37459955  1.18410118 -0.38664604  1.70633968 -0.85993719 -0.45378342
  2.32501418 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  2.29656681  1.02463534 -0.25225666
 -0.33368278 -0.38708024  3.52450267 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-1.57745466 -1.48667457 -1.5399012  -1.32160454  1.15506376 -1.22987595
 -0.21315135  1.04047537 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  0.34138854 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955 -0.5878649  -0.38664604 -0.7495916   0.09578212 -0.45378342
 -0.50225489 -0.1835093  -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  0.48673817 -0.25225666
 -0.33368278 -0.38708024 -0.27377333  0.65501956 -0.26395713  1.75363887
 -0.265011  ]
[-1.37817681 -1.31401307 -1.2521424  -1.54545144  1.11119656 -0.94727635
 -0.21315135  1.28246708 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  0.43806927 -0.31989356 -0.29128286
 -0.37459955 -0.4398705   1.19946974 -0.7495916  -0.85993719 -0.45378342
 -0.50225489 -0.04924235 -0.07955573 -0.21787083 -0.44978491  1.14198373
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.21244721  0.15657324  2.4565368   1.19597845  0.03961182 -0.21672557
 -0.21315135 -0.58520895  1.33935983 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  1.38635759 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.4509754  -0.38664604  1.05544032 -0.85993719 -0.45378342
 -0.50225489  0.75897171 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 1.33333182  1.16085624  0.55392967  0.99245706 -1.2852892   0.82641478
 -0.21315135 -0.58520895 -0.72623981  1.64091607 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.99001208 -0.31989356 -0.29128286
 -0.37459955  1.17935073 -0.38664604  1.70212203 -0.85993719 -0.45378342
 -0.50225489  1.41978543 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278  2.81237682  4.22803879  2.57478952 -0.26395713 -0.41534171
 -0.265011  ]
[-1.4053809  -1.11941377 -0.9278219  -1.34188018  1.06099843 -0.94121942
 -0.21315135  1.55520547 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  0.65803818 -0.52573369 -0.65668302 -0.31989356  1.64712453
 -0.37459955 -1.58208151 -0.38664604  0.41260076 -0.85993719 -0.45378342
 -0.50225489  0.10208411 -0.07955573 -0.21787083 -0.44978491  1.37226604
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 1.61623739e+00  6.85446340e-01  3.44790054e-01  1.32078657e+00
 -7.70333617e-01 -3.87287732e-03 -2.13151349e-01 -5.85208952e-01
 -7.26239813e-01  1.52366011e+00 -7.95557284e-02 -1.97839916e-01
 -1.38474680e-01 -6.58693556e-01  2.44963268e+00 -6.56683023e-01
 -3.19893556e-01 -2.91282858e-01 -3.74599550e-01  1.03593668e+00
 -3.86646039e-01 -7.49591600e-01  1.65670810e+00 -4.53783421e-01
  2.17357773e+00 -1.08550575e+00 -7.95557284e-02 -2.17870826e-01
 -4.49784907e-01 -4.34958720e-01 -2.50050886e-01 -2.11617475e-01
 -2.84965557e-01  2.14039066e+00 -5.89509081e-01 -2.52256660e-01
 -3.33682777e-01 -3.87080244e-01  3.99423869e+00  2.41899529e+00
 -2.63957127e-01 -4.15341711e-01 -2.65011003e-01]
[-1.05125538 -1.03075658 -0.78006523 -0.68568721  0.96208585 -0.81425031
 -0.21315135  1.67946193 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369 -0.65668302  1.74346108 -0.29128286
 -0.37459955 -0.19708113 -0.38664604 -0.7495916   0.47143426  1.50370094
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.14236707 -0.7773386  -0.35771714 -0.65812596  0.79803077 -0.83375572
 -0.21315135  2.03463695 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  1.29517568 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.02013256 -0.38664604 -0.7495916   0.68023717 -0.45378342
 -0.50225489  0.36809239 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
  2.13331446 -0.38708024 -0.27377333 -0.42502247 -0.26395713  3.0800447
 -0.265011  ]
[-1.10899213 -0.93843439 -0.86343757 -0.75546268  0.95356331 -0.88589318
 -0.21315135  1.60934969 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  0.69134641 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955 -0.23995954 -0.38664604  0.44199973 -0.85993719 -0.45378342
 -0.50225489  0.13212555 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747  2.03229315 -0.61919074  0.18114894 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
  1.80855378]
[ 0.32990008  0.26180791  1.65377619  0.49308686  0.13515017 -0.61090956
 -0.21315135 -0.58520895  1.41690496 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.36505286 -0.31989356 -0.29128286
 -0.37459955  0.52729884 -0.38664604  1.12320343 -0.85993719 -0.45378342
 -0.50225489  0.82821565 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747  3.35701342  1.60424942 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.84894761  1.20878419  0.60462086  1.61072795 -1.68171464  1.54362355
 -0.21315135 -0.58520895 -0.72623981  1.66933654 -0.07955573 -0.19783992
 -0.13847468  2.15399579 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  1.21411139 -0.38664604 -0.7495916   1.82798367 -0.45378342
 -0.50225489  1.4513218  -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024  4.28470719 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.70712729 -0.55859057 -0.28314152 -0.60351425  0.75630686 -0.38723771
 -0.21315135 -0.58520895  0.94058876 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  1.33876513 -0.65668302 -0.31989356 -0.29128286
  2.20202184 -1.58208151 -0.38664604 -0.7495916   0.71710631 -0.45378342
  1.17454257 -1.08550575 -0.07955573 -0.21787083  1.54744139 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278  1.51371885 -0.27377333  1.35716739 -0.26395713 -0.41534171
 -0.265011  ]
[-1.789607   -1.71485973 -2.04960024 -1.74817878  1.23212765 -1.49744918
 -0.21315135  1.01085936 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  0.58360474 -0.65668302 -0.31989356 -0.29128286
  1.15843716 -1.58208151  0.96880805 -0.7495916  -0.85993719 -0.45378342
 -0.50225489 -0.19994148 -0.07955573 -0.21787083  0.73852364 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713  1.71412533
 -0.265011  ]
[ 1.11263434  1.24078791  0.34479005  0.78825322 -1.15587721  0.62102482
 -0.21315135 -0.58520895 -0.72623981  1.52366011 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.85255686 -0.31989356 -0.29128286
 -0.37459955  1.03593668 -0.38664604  1.57479311 -0.85993719 -0.45378342
 -0.50225489  1.28967397 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  2.24451608 -0.25225666
 -0.33368278  2.64621409 -0.27377333  2.41899529  4.32646693 -0.41534171
 -0.265011  ]
[-0.7437736  -0.0513661   0.18677203  0.12347239  0.40521126  0.46583989
 -0.21315135 -0.58520895  1.18613385 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  1.61342957 -0.65668302 -0.31989356 -0.29128286
  2.581591   -1.58208151 -0.38664604  0.92154323 -0.85993719 -0.45378342
 -0.50225489  0.62214856 -0.07955573  4.80922772 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-1.65386847 -1.37059544 -1.34644295 -1.38216957  1.11870537 -0.7788268
 -0.21315135  1.20316473 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  0.71726552 -0.65668302 -0.31989356 -0.29128286
  1.34314804 -1.58208151 -0.38664604 -0.7495916   0.19142514 -0.45378342
  0.61561008 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713  1.97069827
 -0.265011  ]
[ 0.66811421  0.56483884  1.05574772  0.85073026 -0.27574949  0.20733649
 -0.21315135 -0.58520895 -0.72623981  1.28748778 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.57570001 -0.31989356 -0.29128286
 -0.37459955  0.74707778 -0.38664604 -0.7495916   1.37903418  2.83812391
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
  3.97993391]
[ 2.77784624  0.80685949 -0.59526392  0.67320349 -1.19752407 -0.302175
 -0.21315135 -0.58520895 -0.72623981  1.80333745 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  2.18041318 -0.31989356 -0.29128286
 -0.37459955  1.37800593  3.72383912 -0.7495916  -0.85993719 -0.45378342
 -0.50225489  1.60001404 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  2.61480872  5.63961848
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.8513948  -0.85759018  0.25393026 -0.75606944  0.88203337 -0.56625258
 -0.21315135  1.92216128 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  0.81303082 -0.31989356 -0.29128286
 -0.37459955 -0.04865396 -0.38664604  0.61184873 -0.85993719 -0.45378342
 -0.50225489  0.30568627 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  0.99715332  1.07043823 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.12519297  1.82518987 -0.91117332  0.81263673 -2.1172143   1.27453517
 -0.21315135 -0.58520895 -0.72623981  1.53766137 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  2.46909487 -0.65668302 -0.31989356  3.61089058
 -0.37459955 -1.58208151 -0.38664604 -0.7495916   1.67316975 -0.45378342
  2.19108064 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.82402568  1.47787011 -0.77259509  1.58060953 -1.89169438  0.84969045
 -0.21315135 -0.58520895 -0.72623981  1.65420402 -0.07955573 -0.19783992
 -0.13847468  2.13537823 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  1.19560303 -0.38664604  1.71655149 -0.85993719 -0.45378342
  2.33677003 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.66215395 -0.57526279 -0.62505543 -0.55595734  0.65836299  0.60087728
 -0.21315135 -0.58520895  1.25798346 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  1.69379987 -0.65668302 -0.31989356 -0.29128286
  2.69265775 -1.58208151  2.3253089  -0.7495916  -0.85993719 -0.45378342
 -0.50225489  0.68630667 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  1.43937374 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-1.24066857 -0.79894405 -0.93260608 -1.16770568  0.82981732  0.61397721
 -0.21315135 -0.58520895  1.04370986 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  1.09364873 -0.52573369 -0.65668302 -0.31989356  2.28840224
 -0.37459955 -1.58208151  2.03244853 -0.7495916  -0.85993719  2.00835641
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  1.21707213 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.8788067  -0.88134083 -1.26654742 -1.09283094  0.94847539 -0.96142311
 -0.21315135 -0.58520895  0.8110496  -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  0.79351913 -0.31989356 -0.29128286
 -0.37459955 -0.0690115  -0.38664604 -0.7495916   0.59454487  1.6847076
 -0.50225489 -1.08550575 -0.07955573 -0.21787083  1.39222506 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  0.97569499 -0.58950908  2.75941773
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 1.25165256  0.67275413  0.0376864   0.48839734 -0.37809513 -0.25520422
 -0.21315135 -0.58520895 -0.72623981 -0.61684322 -0.07955573  4.92618477
 -0.13847468  1.76293623 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.8253454  -0.38664604 -0.7495916   1.45427118  2.94874312
 -0.50225489 -1.08550575 -0.07955573 -0.21787083  2.48101429 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  1.91841215 -0.58950908  4.53958109
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
  4.12257839]
[ 0.08381168 -0.25733883 -0.10369186 -0.1196209   0.55700361 -1.06027069
 -0.21315135 -0.58520895  1.03435703 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  1.08438895 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.15077781 -0.38664604 -0.7495916   0.80582367  1.99534589
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247  2.77443241 -0.41534171
 -0.265011  ]
[-0.95847166 -0.796162   -0.6460848  -0.86929751  0.9204831  -1.04615387
 -0.21315135  1.79213322 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  0.73681389 -0.31989356 -0.29128286
 -0.37459955 -0.12817497 -0.38664604  0.54124669 -0.85993719 -0.45378342
  0.98375867 -1.08550575 -0.07955573 -0.21787083  1.32019951 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  0.91333239  0.98435611 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.41714521  1.02918808  0.13697627  0.58534393 -0.68249204  1.00781996
 -0.21315135 -0.58520895 -0.72623981  1.40714748 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  2.2876765  -0.65668302 -0.31989356 -0.29128286
  3.51335831 -1.58208151  3.05094184 -0.7495916  -0.85993719 -0.45378342
 -0.50225489  1.16038736 -0.07955573 -0.21787083 -0.44978491  2.98274781
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
  3.47797049 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
  4.24666738]
[-0.205576   -0.40478287  0.80805397 -0.43144174  0.60746907 -0.18532037
 -0.21315135 -0.58520895  1.06337111 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  1.47610831 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.17933477  2.05932072 -0.7495916  -0.85993719 -0.45378342
 -0.50225489  0.51252755 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  1.23747001  1.31723782 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.67614178  1.03183624  0.41747112  0.85921898 -0.93374667  1.32919681
 -0.21315135 -0.58520895 -0.72623981  1.56440938 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.90032587 -0.31989356 -0.29128286
 -0.37459955  1.08577653 -0.38664604  1.61904299 -0.85993719 -0.45378342
  2.2245182  -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278  2.70395965 -0.27377333  2.47313755  4.41385594 -0.41534171
 -0.265011  ]
[-0.85897633 -1.08696459 -0.2239159  -0.49216229  0.93990571 -0.8947478
 -0.21315135  1.60068425 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  0.99355926 -0.65668302 -0.31989356 -0.29128286
  1.7249688  -1.58208151 -0.38664604 -0.7495916   0.42512185 -0.45378342
  0.86408899 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
  2.48883021 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
  1.7246797  -0.38708024 -0.27377333 -0.42502247 -0.26395713  2.50106699
 -0.265011  ]
[-0.07529227 -0.63268448 -1.42190625 -0.36453925  0.6017306   0.39677711
 -0.21315135 -0.58520895  1.41733424 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  1.87204815 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.52772135  2.543103   -0.7495916  -0.85993719 -0.45378342
 -0.50225489  0.82859897 -0.07955573 -0.21787083  2.11868706 -0.43495872
 -0.25005089  5.58971603 -0.28496556  1.60469478 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.75425497  0.38904777  0.00517892  0.45665705 -0.0465437  -0.2818081
 -0.21315135 -0.58520895  1.69707401 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  1.74051325 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.80305393 -0.38664604 -0.7495916   1.43284286 -0.45378342
 -0.50225489  1.07839264 -0.07955573 -0.21787083  2.45387668 -0.43495872
 -0.25005089  4.61419959 -0.28496556  1.89491532 -0.58950908  2.96261795
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.80811999 -0.65404917  0.33204171 -1.02876173  0.83774917 -0.51255488
 -0.21315135 -0.58520895  0.86438562 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  1.25352501 -0.65668302 -0.31989356 -0.29128286
 -0.37459955 -0.01651577 -0.38664604  0.64038234 -0.85993719 -0.45378342
 -0.50225489  0.33484343 -0.07955573 -0.21787083  1.45613331  1.72646947
 -0.25005089  4.093225   -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.32807185 -0.50609338 -0.20294036 -0.54478296  0.7144736  -0.71975437
 -0.21315135 -0.58520895  0.98249647 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  1.0330443  -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.09973429 -0.38664604 -0.7495916   0.75675662 -0.45378342
 -0.50225489  0.44031053 -0.07955573 -0.21787083  1.59765602 -0.43495872
 -0.25005089  4.41287827 -0.28496556  1.15356532  1.23106967 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.42216152  0.01213007  0.2763147  -0.19382462  0.33443485 -0.36675747
 -0.21315135 -0.58520895  1.2329228  -0.61684322 -0.07955573 -0.19783992
 -0.13847468  1.2809794  -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.34621525 -0.38664604 -0.7495916   0.99369353 -0.45378342
 -0.50225489  0.66392876 -0.07955573 -0.21787083  1.8977217  -0.43495872
 -0.25005089  3.68988314 -0.28496556  1.41337416 -0.58950908  2.34685456
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 1.743087    0.88574157 -0.52953123  1.37158951 -1.39059083  1.20774944
 -0.21315135 -0.58520895 -0.72623981  1.85861787 -0.07955573 -0.19783992
 -0.13847468  2.38686881 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  1.4456186  -0.38664604 -0.7495916   2.05052664 -0.45378342
 -0.50225489  1.66135519 -0.07955573 -0.21787083  3.23613429 -0.43495872
 -0.25005089  5.91429329 -0.28496556 -0.61919074 -0.58950908  3.82871755
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.7232704  -0.57384909  0.48519608 -0.28931394  0.73247224 -0.40726895
 -0.21315135 -0.58520895  0.92840812 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  1.32513998 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.04649808 -0.38664604  0.69632864 -0.85993719 -0.45378342
 -0.50225489  0.39201233 -0.07955573  4.13173844 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.05458071  0.05819835  0.65914097  0.08651894  0.31141605 -0.08478552
 -0.21315135 -0.58520895  1.43296196 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  1.47902857 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.54310286 -0.38664604  1.13723489 -0.85993719 -0.45378342
 -0.50225489  0.84255375 -0.07955573 -0.21787083  2.1374125  -0.43495872
  4.10402565 -0.21161747 -0.28496556  1.62090801 -0.58950908  3.97779438
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.14268817 -0.1167501   0.39186823 -0.10920481  0.42195352 -0.28164614
 -0.21315135 -0.58520895  1.29330327 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  1.34075921 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.40564445 -0.38664604  1.01519363 -0.85993719  2.35556057
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  1.56221981 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.06408518  0.40510876  0.83049546  0.6622135  -0.06069708  0.56972412
 -0.21315135 -0.58520895  1.52250025 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.46466618 -0.31989356 -0.29128286
 -0.37459955  0.63123051 -0.38664604  1.21547825 -0.85993719 -0.45378342
 -0.50225489  0.92250697 -0.07955573 -0.21787083 -0.44978491 -0.43495872
  3.03005831 -0.21161747 -0.28496556  1.71380095 -0.58950908 -0.25225666
 -0.33368278 -0.38708024  2.21766528 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.41360389 -0.96012365  0.04032655 -0.58716795  0.90077515 -1.40317067
 -0.21315135  1.77845669 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  0.72879729 -0.31989356 -0.29128286
 -0.37459955 -0.1365391  -0.38664604 -0.7495916   0.52963203 -0.45378342
 -0.50225489  0.22595306 -0.07955573 -0.21787083  1.31001703 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  0.904516    0.97530188 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 1.14406581  0.43160474 -0.90796496  0.81733568 -0.36824671  0.65027621
 -0.21315135 -0.58520895 -0.72623981  1.54035956 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  2.47284544 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  1.05636154  3.277192   -0.7495916  -0.85993719 -0.45378342
  2.19445363 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747  4.27047372  2.16191995 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.22007618  0.56483884  1.05574772  0.85073026 -0.27574949  0.76328613
 -0.21315135 -0.58520895  1.64020186 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  2.12134579 -0.65668302 -0.31989356 -0.29128286
  3.28349963 -1.58208151 -0.38664604  1.31833225 -0.85993719 -0.45378342
 -0.50225489  1.02760864 -0.07955573 -0.21787083 -0.44978491 -0.43495872
  4.52192935 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
  3.25262298 -0.38708024 -0.27377333 -0.42502247 -0.26395713  4.66594667
 -0.265011  ]
[-0.64505906 -0.92478717  0.11394157 -0.23768042  0.86347215 -1.01475542
 -0.21315135  1.82798212 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  0.757827   -0.31989356 -0.29128286
  1.94329028 -1.58208151 -0.38664604 -0.7495916   0.55874741  1.63207543
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
  1.93871642 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.37953572 -0.37382783  0.53330482 -0.25710364  0.65044988 -0.76764871
 -0.21315135  2.11011405 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  1.34763562 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.06629195 -0.38664604  0.71390246 -0.85993719 -0.45378342
 -0.50225489  0.40997019 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  1.11831466 -0.58950908 -0.25225666
  2.20438803 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.75100399 -0.42951795  0.43513667 -0.32283027  0.69152479 -0.44168227
 -0.21315135  2.04407019 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  0.88448863 -0.31989356 -0.29128286
 -0.37459955  0.02590163 -0.38664604  0.67804226 -0.85993719 -0.45378342
 -0.50225489  0.37332634 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  1.07574033  1.15114524 -0.25225666
  2.14219734 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-1.24397916 -0.93430963 -1.05835991 -0.91859591  0.96953567 -0.75696818
 -0.21315135  1.4454291  -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  0.59050638 -0.52573369 -0.65668302 -0.31989356 -0.29128286
  1.57584496 -1.58208151 -0.38664604 -0.7495916   0.33384931 -0.45378342
  0.76704312 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
  1.57848254 -0.38708024 -0.27377333 -0.42502247 -0.26395713  2.29392629
 -0.265011  ]
[ 0.06814073 -0.83659098 -0.45646755 -0.41486379  0.80755744 -1.64711422
 -0.21315135  1.95159247 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  0.90188598 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955 -0.03065479 -0.38664604 -0.7495916   0.63141637  1.73891891
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  1.01612575  1.08992247 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247  2.45630913 -0.41534171
 -0.265011  ]
[-0.29585338 -0.66004334 -0.16223208 -0.5149723   0.75455506 -0.68977056
 -0.21315135  2.19903075 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  1.05410409 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.12067056 -0.38664604 -0.7495916   0.77688222 -0.45378342
 -0.50225489  0.45930483 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  1.17563367  1.25373335 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247  2.72164247 -0.41534171
 -0.265011  ]
[-1.73317322 -1.99432505 -1.97829577 -2.00124736  1.2872664  -2.02739827
  4.32457477 -0.58520895 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  0.3479476  -0.65668302 -0.31989356 -0.29128286
 -0.37459955 -0.81333131  0.68086847 -0.7495916  -0.85993719 -0.45378342
 -0.50225489 -0.3880622  -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
  0.84999465 -0.38708024 -0.27377333 -0.42502247 -0.26395713  1.2617619
 -0.265011  ]
[-1.4661751  -1.39025796 -1.90267092 -1.62521158  1.14215396 -1.07206835
 -0.21315135  1.17560695 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  0.42451825 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955 -0.50522274 -0.38664604 -0.7495916   0.17522427  1.06819031
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747  1.57429941 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713  1.93393081
 -0.265011  ]
[-1.63286751 -1.7621238  -1.85155881 -1.75206577  1.24040139 -1.7349978
 -0.21315135  0.77838588 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  0.42202534 -0.65668302 -0.31989356 -0.29128286
 -0.37459955 -0.74815046 -0.38664604 -0.7495916  -0.05829699 -0.45378342
 -0.50225489 -0.32892731 -0.07955573  2.00939165 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713  1.40396028
 -0.265011  ]
[-0.987606   -0.97560846 -0.68815502 -0.90010551  0.97496356 -1.07714083
 -0.21315135  1.75675413 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  1.10203477 -0.65668302 -0.31989356 -0.29128286
 -0.37459955 -0.14981169 -0.38664604  0.52203672 -0.85993719 -0.45378342
  0.96164414 -1.08550575 -0.07955573 -0.21787083 -0.44978491  1.54244043
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.23645342 -0.43032012 -0.08717982 -0.81422137  0.70023125 -0.63449056
 -0.21315135 -0.58520895  1.04298511 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  1.45330473 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.15926995 -0.38664604  0.79645217 -0.85993719 -0.45378342
 -0.50225489  0.49432387 -0.07955573 -0.21787083  1.67013468  1.96916015
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 1.65016745  1.26988919  0.37337063  1.35267922 -1.53420528  0.01951726
 -0.21315135 -0.58520895 -0.72623981  1.53968406 -0.07955573 -0.19783992
 -0.13847468  1.99448421 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  1.05553534 -0.38664604  1.59219362 -0.85993719 -0.45378342
  2.19360919 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  2.26573179 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.4227129  -0.09335777  0.12755514 -0.3027612   0.494471   -0.03432106
 -0.21315135 -0.58520895  1.1551911  -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  1.5788173  -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.26970818 -0.38664604  0.8945038  -0.85993719 -0.45378342
  1.39042839 -1.08550575 -0.07955573 -0.21787083 -0.44978491  2.12163175
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.7181468   0.35918442  1.11896424  0.42324739 -0.07073163  0.25389883
 -0.21315135 -0.58520895  1.67323455 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.6068614  -0.31989356 -0.29128286
 -0.37459955  0.77959005 -0.38664604  1.34719799 -0.85993719 -0.45378342
 -0.50225489  1.05710519 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.39551287 -0.56187064  0.50807077 -0.60718382  0.75118322 -0.78251769
 -0.21315135  2.09313752 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  0.9889611  -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.05590965 -0.38664604 -0.7495916   0.71462892 -0.45378342
 -0.50225489  0.40055091 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  1.10737096  1.18362915 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.54738277 -0.52421435  0.26820991 -0.74770385  0.78166858 -0.92385394
 -0.21315135  1.9317681  -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  0.8896905  -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955 -0.04277874 -0.38664604 -0.7495916   0.61976188  1.72178357
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  1.00334623  1.0767982  -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.43942959  0.78945011  0.1611104   0.60890847 -0.48680878  1.03547162
 -0.21315135 -0.58520895  1.80571302 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.73183498 -0.31989356 -0.29128286
 -0.37459955  0.90998137 -0.38664604  1.46296479 -0.85993719 -0.45378342
  2.04484092 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  2.10816847 -0.25225666
 -0.33368278  2.50027946 -0.27377333  2.28216694 -0.26395713 -0.41534171
 -0.265011  ]
[-0.1473606  -0.54746629  0.02538958 -0.37757701  0.67432105 -0.5515772
 -0.21315135  2.35681181 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  1.15116722 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.21716442 -0.38664604  0.84785327 -0.85993719 -0.45378342
  1.33672429 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  1.2773452   1.3581887   3.3290336
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-1.64078707 -1.94338625 -1.63135371 -1.78347687  1.26087607 -1.77185694
  5.37781313 -0.58520895 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  0.25114423 -0.31989356 -0.29128286
 -0.37459955 -0.63489894  0.92864614 -0.7495916  -0.85993719 -0.45378342
 -0.50225489 -0.22618062 -0.07955573 -0.21787083 -0.44978491  0.87272645
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.93671205  1.29865233  0.69967028  1.13475814 -1.66251754  1.65252639
 -0.21315135 -0.58520895 -0.72623981  1.72262683 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  2.72620264 -0.65668302 -0.31989356  3.94589443
 -0.37459955 -1.58208151 -0.38664604 -0.7495916   1.89063845 -0.45378342
  2.42230505 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 1.40263906  1.09538589 -0.35483391  1.62745109 -1.79677239  1.46509721
 -0.21315135 -0.58520895 -0.72623981  2.00553625 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  2.41744402 -0.31989356 -0.29128286
 -0.37459955  1.62531232 -0.38664604  2.09806516 -0.85993719 -0.45378342
 -0.50225489  1.82438113 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 1.25394751  1.08972999  0.47870269  1.47021771 -1.30807956  0.75253654
 -0.21315135 -0.58520895 -0.72623981  1.5987394  -0.07955573 -0.19783992
 -0.13847468  2.06714006 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  1.12776507 -0.38664604  1.65632215 -0.85993719  3.37616666
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  2.23718446  2.34392103 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.40246238  0.32682181 -0.32819038  0.56981762  0.03538231 -0.0398898
 -0.21315135 -0.58520895  1.4648123  -0.61684322 -0.07955573 -0.19783992
 -0.13847468  1.51056207 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.57445141 -0.38664604  1.16506743 -0.85993719  2.59414317
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  1.65395166 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.02479728  0.36487914 -0.28793888  0.17045693  0.06790064  0.52097359
 -0.21315135 -0.58520895  1.49285591 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  1.53832671 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.60205321 -0.38664604  1.18957344 -0.85993719 -0.45378342
  1.73011269 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  1.77483383 -0.25225666
 -0.33368278  2.14350702 -0.27377333  1.94765697 -0.26395713 -0.41534171
 -0.265011  ]
[-1.50880582 -1.22396003 -1.10205939 -1.45124652  1.08622591 -0.79988417
 -0.21315135  1.40867988 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369 -0.65668302  1.49675    -0.29128286
  1.54054703 -1.58208151 -0.38664604  0.33304097 -0.85993719 -0.45378342
  0.74407216 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  0.73049957 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713  2.24489565
 -0.265011  ]
[-1.57076141 -1.28658733 -1.20643447 -1.27964141  1.09979144 -0.90238792
 -0.21315135  1.32090531 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  0.46060013 -0.31989356 -0.29128286
  1.45623884 -1.58208151 -0.38664604 -0.7495916   0.26064335 -0.45378342
 -0.50225489 -0.02791524 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713  2.12778722
 -0.265011  ]
[-0.00414189 -0.88043076 -0.52953123 -0.47601181  0.83878705 -1.68299109
 -0.21315135  1.89014933 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  0.79426677 -0.31989356 -0.29128286
 -0.37459955 -0.06823145 -0.38664604 -0.7495916   0.59529472  1.68581009
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  0.97651722  1.04924544 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.74723703  1.10463563  0.4944677   0.93439842 -1.10297409  1.41741562
 -0.21315135 -0.58520895 -0.72623981  1.6075782  -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.95093121 -0.31989356 -0.29128286
 -0.37459955  1.13857567 -0.38664604  1.66592025 -0.85993719 -0.45378342
  2.27848332 -1.08550575 -0.07955573 -0.21787083  2.86234052 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278  2.76513392 -0.27377333  2.53049456 -0.26395713 -0.41534171
 -0.265011  ]
[-1.63238527 -1.8502726  -1.85094949 -1.75161957  1.24180893 -1.53534748
  4.71116954 -0.58520895 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  0.18047257 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955 -0.74783709  0.77181612 -0.7495916  -0.85993719  0.72529236
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
  0.95083888 -0.38708024  1.08624976 -0.42502247 -0.26395713  1.40464392
 -0.265011  ]
[ 0.2808408   1.17267049 -0.78006523  1.00465755 -1.28150367  2.1610353
 -0.21315135 -0.58520895 -0.72623981  1.64792172 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369 -0.65668302  3.80681571  3.8105908
 -0.37459955 -1.58208151 -0.38664604  1.70972951 -0.85993719 -0.45378342
  2.32891656 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  2.30059132  2.40903839 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 1.11263434  1.24078791  0.34479005  1.32078657 -1.348649    0.62102482
 -0.21315135 -0.58520895 -0.72623981  1.52366011 -0.07955573 -0.19783992
 -0.13847468  1.97476992 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  1.03593668 -0.38664604  1.57479311 -0.85993719 -0.45378342
  2.17357773 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747  4.23520891  2.14039066 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 1.53998154  1.34600893 -0.65784381  1.18366298 -1.97223085  1.01873133
 -0.21315135 -0.58520895 -0.72623981  1.7507085  -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369 -0.65668302  3.99410718  3.9967551
 -0.37459955 -1.58208151 -0.38664604  1.82134626 -0.85993719 -0.45378342
  2.4574098  -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  2.54512802 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.44318729  1.3225134   0.16518     1.12036236 -1.21935984  1.04013437
 -0.21315135 -0.58520895 -0.72623981 -0.61684322 -0.07955573  5.1122657
 -0.13847468 -0.65869356  2.3096566  -0.65668302 -0.31989356 -0.29128286
  3.54373345 -1.58208151 -0.38664604  1.46544246 -0.85993719 -0.45378342
 -0.50225489  1.17793367 -0.07955573 -0.21787083  2.5874474  -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278  2.50351279 -0.27377333  2.2851985  -0.26395713 -0.41534171
 -0.265011  ]
[-2.14954449 -2.01254694 -2.50438378 -2.12879347  1.30970769 -2.01851723
  3.70770308 -0.58520895 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  0.22917682 -0.65668302 -0.31989356 -0.29128286
 -0.37459955 -0.91783744  0.53574744 -0.7495916  -0.85993719 -0.45378342
 -0.50225489 -0.48287471 -0.07955573 -0.21787083  0.35886517 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713  1.03377156
 -0.265011  ]
[ 0.3717916   1.28132316  0.68134201  1.11686242 -1.66621929  2.3115108
 -0.21315135 -0.58520895 -0.72623981  1.71235093 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  2.71191881 -0.65668302 -0.31989356  3.92728302
 -0.37459955 -1.58208151 -0.38664604  1.77969355 -0.85993719 -0.45378342
  2.40945919 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
  4.05274078 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 1.24296622  0.79323765  0.46829648  1.45860558 -0.9132163   0.74231691
 -0.21315135 -0.58520895 -0.72623981  1.59290507 -0.07955573 -0.19783992
 -0.13847468  2.05996207 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  1.12062919 -0.38664604  1.64998662 -0.85993719 -0.45378342
 -0.50225489  1.36651069 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
  3.82779598 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-2.06409821 -2.02018113 -2.75529648 -2.18861219  1.30001525 -1.71859964
 -0.21315135  0.62197837 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  0.05091887 -0.31989356 -0.29128286
 -0.37459955 -0.8438043   0.63855256 -0.7495916  -0.85993719 -0.45378342
 -0.50225489 -0.41570862 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713  1.1952821
 -0.265011  ]
[-1.47190967 -1.8502726  -1.85094949 -1.75161957  1.24180893 -1.73447421
  4.71116954 -0.58520895 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  0.18047257 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955 -0.74783709 -0.38664604 -0.7495916  -0.05799575 -0.45378342
 -0.50225489 -0.32864301 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713  1.40464392
 -0.265011  ]
[ 1.237508    1.36127784  0.46312412  0.90379455 -1.51154593  0.73723728
 -0.21315135 -0.58520895 -0.72623981  1.59000514 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  2.54185435 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  1.11708232 -0.38664604  1.64683756 -0.85993719 -0.45378342
  2.25651533 -1.08550575 -0.07955573 -0.21787083  2.83617453 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278  2.74023124  4.126526    2.5071458  -0.26395713 -0.41534171
 -0.265011  ]
[ 0.9198761   0.52602515  1.37385062  0.60990061 -0.30269574  0.44163624
 -0.21315135 -0.58520895  1.80642096 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.73250282 -0.31989356 -0.29128286
 -0.37459955  0.91067816 -0.38664604  1.46358343 -0.85993719 -0.45378342
 -0.50225489  1.17603401 -0.07955573 -0.21787083 -0.44978491 -0.43495872
  4.85711371 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.45442052 -0.3197314   0.08176907 -0.33629033  0.5909439  -0.07366559
 -0.21315135 -0.58520895  1.1312664  -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.09559568 -0.31989356 -0.29128286
 -0.37459955  0.2461604  -0.38664604 -0.7495916   0.89751293 -0.45378342
 -0.50225489  0.57315465 -0.07955573 -0.21787083 -0.44978491  2.08912156
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  1.38957708 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.79831942  0.86436203  1.89073558  0.98841532 -0.88029776  1.48080138
 -0.21315135 -0.58520895 -0.72623981  1.63859526 -0.07955573 -0.19783992
 -0.13847468  2.11617476 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  1.17651219  3.44403757 -0.7495916  -0.85993719 -0.45378342
 -0.50225489  1.41721017 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  2.28856746 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.6421595  -1.07931748 -0.5997923  -1.13598077  0.97658119 -1.01205698
 -0.21315135  1.83106305 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369 -0.65668302  1.88158573 -0.29128286
 -0.37459955 -0.10436673 -0.38664604 -0.7495916   0.56055864  1.63473844
 -0.50225489 -1.08550575 -0.07955573 -0.21787083  1.34918363 -0.43495872
  2.77749031  3.85166086 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-1.1509912  -1.25621054 -0.28684425 -1.33953431  1.06623506 -0.93800788
 -0.21315135  1.5583484  -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369 -0.65668302  1.63311385 -0.29128286
 -0.37459955 -0.2711503  -0.38664604 -0.7495916   0.40023314  1.3990156
 -0.50225489 -1.08550575 -0.07955573 -0.21787083  1.14614148  1.37491972
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 1.92640546  1.21014148 -0.75364433  1.61232985 -1.88738847  0.20994556
 -0.21315135 -0.58520895 -0.72623981  1.67014139 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  2.02427194 -0.31989356 -0.29128286
 -0.37459955  1.21509579 -0.38664604  1.73385797 -0.85993719 -0.45378342
  2.35669326 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747  4.54453848 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.68062491  1.31973683 -0.44331189  0.23005301 -1.35794015  2.07861323
 -0.21315135 -0.58520895 -0.72623981  1.93112732 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369 -0.65668302  4.32285477 -0.29128286
  4.51989038 -1.58208151  3.94088009 -0.7495916  -0.85993719 -0.45378342
 -0.50225489  1.74181429 -0.07955573 -0.21787083 -0.44978491 -0.43495872
  4.36840516 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024  3.23421956 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 1.30144934  0.45402745  1.2638581   1.02490074 -0.35267984 -0.22087615
 -0.21315135 -0.58520895 -0.72623981  1.37499698 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.67828409 -0.31989356 -0.29128286
 -0.37459955  0.85410899 -0.38664604 -0.7495916   1.481921   -0.45378342
 -0.50225489  1.124712   -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
  4.17500068]
[ 0.21396855  0.31203189  1.04692825 -0.10235822  0.06224535  0.75570745
 -0.21315135 -0.58520895 -0.72623981  1.28377925 -0.07955573 -0.19783992
 -0.13847468  1.67964425 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.74254193 -0.38664604 -0.7495916   1.37467396  2.83171318
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491  2.77442847
 -0.25005089 -0.21161747  3.72864426 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.26593101 -0.14157056  0.35394945  0.26338549  0.39323435  0.16022232
 -0.21315135 -0.58520895  1.27348948 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.22976184 -0.31989356 -0.29128286
 -0.37459955  0.38614281 -0.38664604  0.99787927 -0.85993719 -0.45378342
 -0.50225489  0.70015277 -0.07955573 -0.21787083 -0.44978491  2.282382
  3.78244598 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.25848546 -0.44854177  0.72448963 -0.48039705  0.67387644 -0.65499447
 -0.21315135 -0.58520895  1.02843904 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  0.99859348 -0.31989356 -0.29128286
 -0.37459955  0.14495305 -0.38664604 -0.7495916   0.80022446 -0.45378342
 -0.50225489  0.48133496 -0.07955573 -0.21787083  1.6527053  -0.43495872
 -0.25005089 -0.21161747 -0.28496556  1.20122918 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 1.59653203  1.08565515 -0.62211784  1.23598721 -1.85750356  1.77131296
 -0.21315135 -0.58520895 -0.72623981  1.78075362 -0.07955573 -0.19783992
 -0.13847468  2.29107234 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  1.35038398 -0.38664604 -0.7495916   1.95897962  3.69080416
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  2.58490774 -0.25225666
  4.18155923 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.9145237   1.31364881  0.15705442  1.11129514 -1.2222318   0.43665508
 -0.21315135 -0.58520895 -0.72623981  1.41840447 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369 -0.65668302  3.3886041  -0.29128286
 -0.37459955  0.90720005 -0.38664604  1.46049542 -0.85993719 -0.45378342
  2.04199817 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747  4.01293696  2.0046929   2.10515767 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.28970915 -0.28976126  0.12755514  0.07391295  0.494471   -0.91833257
 -0.21315135  2.44272827 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369 -0.65668302  2.43887742 -0.29128286
 -0.37459955  0.26970818 -0.38664604 -0.7495916   0.92014892 -0.45378342
 -0.50225489  0.59451823 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747  2.91226681  1.33273015  1.41506774 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 1.54657713  1.4544446  -0.96694022  1.25530924 -1.74604366 -0.05189409
 -0.21315135 -0.58520895 -0.72623981 -0.61684322 -0.07955573 -0.19783992
  6.90829531 -0.65869356 -0.52573369 -0.65668302  3.52044946 -0.29128286
 -0.37459955  0.99569956 -0.38664604  1.53906894 -0.85993719 -0.45378342
  2.13245204 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747  4.16573698 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.09342193  0.19809087  0.87285796  0.69766727 -0.03663349  1.13962503
 -0.21315135 -0.58520895  1.54463603 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.48554797 -0.31989356 -0.29128286
 -0.37459955  0.65301755 -0.38664604  1.23482169 -0.85993719 -0.45378342
 -0.50225489  0.94227312 -0.07955573 -0.21787083 -0.44978491  2.65083065
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.33838319 -0.17920863  0.63913026  0.5020573   0.2977758  -0.09952447
 -0.21315135 -0.58520895  1.42250571 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  1.46867635 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.53281135 -0.38664604 -0.7495916   1.17306441 -0.45378342
 -0.50225489  0.83321684 -0.07955573  5.43058361 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  1.61006001  1.69987898 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.47958035 -0.34351254  0.92505906  0.00518803  0.55929982 -0.10488525
 -0.21315135 -0.58520895  1.11228227 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.07768701 -0.31989356 -0.29128286
 -0.37459955  0.22747537 -0.38664604  0.85700776 -0.85993719 -0.45378342
 -0.50225489  0.55620278 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  1.28821369 -0.58950908 -0.25225666
  2.45256901 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 1.43141643  0.94909588 -0.7264302   1.08321139 -1.04910527  0.91769626
 -0.21315135 -0.58520895 -0.72623981  1.69302815 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  2.05110132 -0.31989356 -0.29128286
 -0.37459955  1.24308825  3.53648752 -0.7495916  -0.85993719 -0.45378342
 -0.50225489  1.47761087 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-1.65416791 -1.65254728 -1.65067576 -1.79560504  1.22136356 -1.56237655
  5.3191557  -0.58520895 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  0.28408105 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955 -0.64483628  0.9148468  -0.7495916  -0.85993719  0.87086812
 -0.50225489 -1.08550575 -0.07955573  2.2853231  -0.44978491 -0.43495872
 -0.25005089 -0.21161747  1.33324778 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713  1.62935026
 -0.265011  ]
[ 0.59713086  1.5043983   1.60021769  0.77566915 -1.54467459  1.23115582
 -0.21315135 -0.58520895 -0.72623981 -0.61684322 -0.07955573  5.35560147
 -0.13847468 -0.65869356  2.43958845 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  1.02709879 -0.38664604 -0.7495916   1.64821242 -0.45378342
 -0.50225489  1.28165585 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278  2.63597431 -0.27377333  2.40939447 -0.26395713 -0.41534171
 -0.265011  ]
[-0.25526898 -0.44588157 -0.11095341 -0.8291437   0.67772401 -0.23927437
 -0.21315135 -0.58520895  1.03056264 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.00059678 -0.31989356 -0.29128286
 -0.37459955  0.14704319 -0.38664604  0.78559675 -0.85993719 -0.45378342
 -0.50225489  0.48323122 -0.07955573 -0.21787083 -0.44978491  1.95227982
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  1.28228193 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-1.385056   -1.09886851 -0.24871483 -0.78069016  1.01129296 -0.91179582
 -0.21315135  1.58400045 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  0.61481531 -0.31989356 -0.29128286
  1.70894388 -1.58208151 -0.38664604 -0.7495916   0.41531366 -0.45378342
 -0.50225489  0.11806075 -0.07955573 -0.21787083 -0.44978491  1.39657861
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-1.27468111 -1.48293384 -1.10269377 -0.95569954  1.08526497 -0.80050718
 -0.21315135  1.4081464  -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  0.51173714 -0.31989356 -0.29128286
  1.54003462 -1.58208151  1.30620235 -0.7495916  -0.85993719  1.26918743
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
  1.54337501 -0.38708024 -0.27377333 -0.42502247 -0.26395713  2.24418388
 -0.265011  ]
[-1.60792545 -2.0054158  -2.00371116 -2.01720023  1.27842404 -1.86574418
  4.24741934 -0.58520895 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  0.10144372 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955 -0.82640245 -0.38664604 -0.7495916  -0.13351896  0.61425235
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713  1.23324593
 -0.265011  ]
[-0.73013796 -0.23596319  1.13044105 -0.24257456  0.56294433  0.03630455
 -0.21315135 -0.58520895  1.19813728 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.15867834 -0.31989356  2.51347877
 -0.37459955 -1.58208151 -0.38664604 -0.7495916   0.96078176 -0.45378342
 -0.50225489  0.63286702 -0.07955573 -0.21787083 -0.44978491  2.17998935
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.36130105 -0.23712991  0.20796125 -0.24387983  0.42206211  0.03477289
 -0.21315135 -0.58520895  1.19720591 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  1.24561781 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.31106106 -0.38664604 -0.7495916   0.95990056  2.22188154
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  1.45983255 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713  3.71473362
 -0.265011  ]
[ 0.74358153  1.1008925   1.81169362  0.93053292 -1.10437337  1.41287967
 -0.21315135 -0.58520895 -0.72623981  1.60535859 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.94832924 -0.31989356  3.73350174
 -0.37459955 -1.58208151 -0.38664604 -0.7495916   1.75276313 -0.45378342
 -0.50225489  1.38032956 -0.07955573 -0.21787083 -0.44978491 -0.43495872
  5.31846797 -0.21161747 -0.28496556  2.24571804 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-1.51255785 -1.61471193 -1.10838035 -1.45521409  1.16619937 -1.0963755
 -0.21315135  1.40336425 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  0.50893405 -0.31989356 -0.29128286
 -0.37459955 -0.36593365 -0.38664604 -0.7495916   0.30911992 -0.45378342
 -0.50225489  0.01783636 -0.07955573 -0.21787083 -0.44978491  1.24406132
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024  1.70884607 -0.42502247  1.86843232 -0.41534171
 -0.265011  ]
[ 0.77688089  0.84409827  0.52657218  0.40785587 -0.68772603  1.45419931
 -0.21315135 -0.58520895 -0.72623981  1.62557786 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.97203161 -0.31989356 -0.29128286
 -0.37459955  1.16059079  3.42192853 -0.7495916  -0.85993719 -0.45378342
 -0.50225489  1.40276559 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278  2.79064112 -0.27377333  2.55441012  4.54503501 -0.41534171
 -0.265011  ]
[ 1.40907142  0.53314666  1.38473031  1.12606039 -0.48171233 -0.14668546
 -0.21315135 -0.58520895  1.81210595 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  1.85440086 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.91627359 -0.38664604 -0.7495916   1.54167851  3.07725608
 -0.50225489 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247  4.11665008 -0.41534171
 -0.265011  ]
[ 0.59713086  0.95093145  1.60021769  0.77566915 -0.77619044  1.23115582
 -0.21315135 -0.58520895 -0.72623981  1.5164342  -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.84408618 -0.31989356  3.57244459
 -0.37459955 -1.58208151 -0.38664604 -0.7495916   1.64821242 -0.45378342
 -0.50225489  1.28165585 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  2.13107488 -0.58950908 -0.25225666
 -0.33368278 -0.38708024  3.97983076 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 1.3116246   1.43279255 -0.8021091   0.41353606 -1.69610733  1.46197559
 -0.21315135 -0.58520895 -0.72623981  1.62938309 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369 -0.65668302  3.7730358  -0.29128286
 -0.37459955  1.16524491 -0.38664604 -0.7495916   1.78100936 -0.45378342
 -0.50225489  1.40698801 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  0.98802948 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
  3.97958036]
[ 0.02719751 -0.21226695  1.17569266 -0.21606437  0.45226888  0.06741276
 -0.21315135 -0.58520895  1.21705363 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.17652308 -0.31989356 -0.29128286
 -0.37459955  0.33059609 -0.38664604 -0.7495916   0.97867917 -0.45378342
 -0.50225489  0.64975838 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713  3.7573512
 -0.265011  ]
[ 0.91978853  1.28132316  0.68134201  1.11686242 -1.66621929  1.63152678
 -0.21315135 -0.58520895 -0.72623981  1.71235093 -0.07955573 -0.19783992
 -0.13847468  2.20691643 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  1.26672166 -0.38664604  1.77969355 -0.85993719 -0.45378342
 -0.50225489  1.49905212 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  2.49434262 -0.25225666
 -0.33368278  2.91360672 -0.27377333  2.66970271 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.73268031  1.08972999  0.47870269  0.36779322 -0.90901282  1.39935285
 -0.21315135 -0.58520895 -0.72623981  1.5987394  -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.94056979 -0.31989356  3.72151327
 -0.37459955 -1.58208151 -0.38664604 -0.7495916   1.74498078 -0.45378342
 -0.50225489  1.37298467 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278  2.75260851 -0.27377333  2.51875074  4.48747851 -0.41534171
  4.673745  ]
[-0.46188506  0.05984913  1.69534008  0.08836575  0.31313512  0.42464425
 -0.21315135 -0.58520895  1.43427975 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  1.89100324 -0.65668302 -0.31989356 -0.29128286
  2.96518056 -1.58208151 -0.38664604 -0.7495916   1.18420423 -0.45378342
  1.6711862  -1.08550575 -0.07955573 -0.21787083 -0.44978491  2.50087255
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.7387245   1.09591905  1.80468003  0.92539686 -1.10623257  1.4068528
 -0.21315135 -0.58520895 -0.72623981  1.60240941 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  2.55909667 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  1.1322538  -0.38664604 -0.7495916   1.74929571 -0.45378342
 -0.50225489  1.37705704 -0.07955573 -0.21787083  2.85464428 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278  2.75780926 -0.27377333  2.52362696 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.91132299  0.51895128  1.36304371  0.60198671 -0.30760674  0.43367637
 -0.21315135 -0.58520895  1.800774   -0.61684322 -0.07955573 -0.19783992
 -0.13847468  1.84318163 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.90512016 -0.38664604 -0.7495916   1.53095696 -0.45378342
 -0.50225489  1.17099155 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  2.10290618 -0.25225666
 -0.33368278  2.49464715 -0.27377333  2.27688608 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.1663588   0.26703102  0.97817939  0.78581224  0.02319327  0.15020328
 -0.21315135 -0.58520895  1.59966989 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369 -0.65668302  3.09062348 -0.29128286
 -0.37459955  0.70718438 -0.38664604 -0.7495916   1.34068549 -0.45378342
 -0.50225489  0.99141562 -0.07955573  5.89629897 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  1.79386185  1.88863914 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.96735024 -0.80455406 -0.65890555 -0.87868614  0.90494668 -0.71013632
 -0.21315135  1.78135157 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  0.79715785 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955 -0.13476869 -0.38664604 -0.7495916   0.53133389 -0.45378342
 -0.50225489  0.22755926 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  0.90638214  0.97721836 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.08533518  0.19044726  0.86118064  0.23447253  0.12086753  0.59609227
 -0.21315135 -0.58520895  1.53853425 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  2.00762135 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.6470119   2.7087542  -0.7495916  -0.85993719 -0.45378342
 -0.50225489  0.93682453 -0.07955573 -0.21787083  2.26391126 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278  2.19559716 -0.27377333  1.9964967  -0.26395713 -0.41534171
 -0.265011  ]
[-0.03232235 -0.52650523 -0.23412401 -0.22878138  0.68377011 -1.14032922
 -0.21315135  2.138573   -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369 -0.65668302  2.16175981 -0.29128286
 -0.37459955  0.08369653 -0.38664604 -0.7495916   0.74133987 -0.45378342
 -0.50225489  0.42576038 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747  2.59110589  1.13666036 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.06935534  0.88082961  0.83810562  0.2175747  -0.21963458  0.04703149
 -0.21315135 -0.58520895  1.5264768  -0.61684322 -0.07955573 -0.19783992
 -0.13847468  1.57161313 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.63514441 -0.38664604 -0.7495916   1.27143501 -0.45378342
 -0.50225489  0.92605784 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
  3.0802744  -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.04006863 -0.08519417 -0.27139992 -0.25997812  0.40457985  0.01588247
 -0.21315135 -0.58520895  1.50437877 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  1.54973494 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.61339453 -0.38664604 -0.7495916   1.25052731 -0.45378342
 -0.50225489  0.9063254  -0.07955573 -0.21787083  2.22298551 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  1.69500054 -0.58950908  4.1177057
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.80509591  0.4310959   1.22882505  0.9955811  -0.36859997  0.9120136
 -0.21315135 -0.58520895  1.73064039 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.66101521 -0.31989356 -0.29128286
 -0.37459955  0.83609149 -0.38664604  1.39736229 -0.85993719 -0.45378342
 -0.50225489  1.10836574 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024  3.66844199 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.23058323  0.31491415  1.05133153  0.37371998  0.0647466   0.75949125
 -0.21315135 -0.58520895  1.63789427 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.57352314 -0.31989356 -0.29128286
  3.27993249 -1.58208151 -0.38664604 -0.7495916   1.37685088 -0.45378342
 -0.50225489  1.02554807 -0.07955573 -0.21787083 -0.44978491  2.77755501
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-1.43160596 -1.47724211 -1.32929451 -1.5938787   1.14792835 -1.02304521
 -0.21315135  1.21758576 -0.72623981 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  0.45034261 -0.52573369 -0.65668302 -0.31989356 -0.29128286
  1.35699956 -1.58208151 -0.38664604 -0.7495916   0.19990308 -0.45378342
 -0.50225489 -0.08524118 -0.07955573 -0.21787083 -0.44978491 -0.43495872
  2.00881535 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713  1.98993874
 -0.265011  ]
[ 1.06862887  1.47296515  0.30308914  1.27425314 -2.12394734  1.19814371
 -0.21315135 -0.58520895 -0.72623981 -0.61684322 -0.07955573 -0.19783992
  6.94011891 -0.65869356 -0.52573369  1.8251493  -0.31989356 -0.29128286
 -0.37459955  1.00734096 -0.38664604  1.54940466 -0.85993719 -0.45378342
  2.14435053 -1.08550575 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333  2.38793106 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.11479182 -0.13982185  0.356621   -0.13501635  0.39525774  0.16251802
 -0.21315135 -0.58520895  1.27488545 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.23107873 -0.31989356 -0.29128286
 -0.37459955  0.38751679 -0.38664604 -0.7495916   1.03339583 -0.45378342
 -0.50225489  0.70139931 -0.07955573 -0.21787083 -0.44978491  2.28427892
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.43702894  0.35779253  0.76376985  0.16313864  0.06184544 -0.00772077
 -0.21315135 -0.58520895  1.48763395 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  1.53315669 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.59691352 -0.38664604 -0.7495916   1.23468446 -0.45378342
 -0.50225489  0.8913731  -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  1.67762835 -0.58950908  4.08490123
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.49321513  1.11307318  0.21936046  0.66578381 -0.82733282  1.1022116
 -0.21315135 -0.58520895  1.84629642 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.77011934 -0.31989356 -0.29128286
 -0.37459955  0.9499254  -0.38664604 -0.7495916   1.57402728 -0.45378342
 -0.50225489  1.2116408  -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278  2.5465595  -0.27377333  2.32555911 -0.26395713 -0.41534171
 -0.265011  ]
[ 1.18408201  1.02713235  0.41249603  0.85436131 -1.13194673  1.3234966
 -0.21315135 -0.58520895 -0.72623981  1.56162006 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.89705604 -0.31989356 -0.29128286
 -0.37459955  1.08236494 -0.38664604 -0.7495916   1.7013386  -0.45378342
 -0.50225489  1.33179571 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  2.29477503 -0.25225666
 -0.33368278  2.70000691 -0.27377333  2.46943146  4.40787408 -0.41534171
 -0.265011  ]
[ 0.66355113  1.01894379  1.69612908  1.38667436 -0.93925469  0.67901151
 -0.21315135 -0.58520895  1.97482192 -0.61684322 -0.07955573 -0.19783992
 -0.13847468 -0.65869356  2.49564865 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  1.07642603 -0.38664604  1.61074123 -0.85993719 -0.45378342
  2.21496122 -1.08550575 -0.07955573 -0.21787083  2.78667961  3.2353906
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.55070657  1.17647109  1.53318064  0.72657794 -0.98862066  1.17355006
 -0.21315135 -0.58520895 -0.72623981  1.48824551 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.81104153 -0.31989356 -0.29128286
 -0.37459955  0.99262162 -0.38664604 -0.7495916   1.61507025 -0.45378342
 -0.50225489  1.25037667 -0.07955573 -0.21787083  2.68465619 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074 -0.58950908 -0.25225666
 -0.33368278  2.59602829 -0.27377333  2.37194107 -0.26395713 -0.41534171
 -0.265011  ]
[ 0.67614178  1.03183624  0.41747112  0.85921898 -0.93374667  1.32919681
 -0.21315135 -0.58520895 -0.72623981  1.56440938 -0.07955573 -0.19783992
 -0.13847468 -0.65869356 -0.52573369  1.90032587 -0.31989356 -0.29128286
  3.81544847 -1.58208151  3.31803873 -0.7495916  -0.85993719 -0.45378342
 -0.50225489  1.33489084 -0.07955573 -0.21787083 -0.44978491  3.24829994
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  2.2984681  -0.25225666
  3.77413186 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-0.2585073   0.0747838   0.36466934 -0.12912254  0.40135345 -0.30167957
 -0.21315135 -0.58520895  1.27909097 -0.61684322 -0.07955573 -0.19783992
 -0.13847468  1.32668829 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  0.39165606 -0.38664604 -0.7495916   1.03737482 -0.45378342
 -0.50225489  0.70515463 -0.07955573 -0.21787083 -0.44978491 -0.43495872
 -0.25005089 -0.21161747 -0.28496556  1.46127207 -0.58950908 -0.25225666
 -0.33368278 -0.38708024 -0.27377333 -0.42502247 -0.26395713 -0.41534171
 -0.265011  ]
[-6.82091534e-01 -7.00760423e-03 -2.46989686e-01 -2.39548849e-01
  5.48933980e-01 -7.52199048e-01 -2.13151349e-01 -5.85208952e-01
 -7.26239813e-01 -6.16843218e-01  1.25698051e+01 -1.97839916e-01
 -1.38474680e-01 -6.58693556e-01  1.35989587e+00 -6.56683023e-01
 -3.19893556e-01 -2.91282858e-01  2.23122321e+00 -1.58208151e+00
 -3.86646039e-01 -7.49591600e-01  7.34979259e-01 -4.53783421e-01
  1.19354605e+00 -1.08550575e+00 -7.95557284e-02 -2.17870826e-01
 -4.49784907e-01 -4.34958720e-01 -2.50050886e-01 -2.11617475e-01
 -2.84965557e-01  1.12968575e+00 -5.89509081e-01 -2.52256660e-01
 -3.33682777e-01 -3.87080244e-01 -2.73773333e-01 -4.25022472e-01
 -2.63957127e-01 -4.15341711e-01 -2.65011003e-01]
[ 1.52658956  1.33401007 -0.66630424  1.17127184 -1.9738328   1.00626821
 -0.21315135 -0.58520895 -0.72623981 -0.61684322 -0.07955573 -0.19783992
  7.75363583  2.24535405 -0.52573369 -0.65668302 -0.31989356 -0.29128286
 -0.37459955  1.30493384 -0.38664604 -0.7495916   1.91528936 -0.45378342
 -0.50225489  1.53371987 -0.07955573 -0.21787083  3.06486479 -0.43495872
 -0.25005089 -0.21161747 -0.28496556 -0.61919074  1.06824007 -0.25225666
 -0.33368278 -0.38708024 -0.27377333  2.71121354 -0.26395713 -0.41534171
  4.19539834]
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="12">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">16</span>).fit(rows)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>rows <span class="op">=</span> pca.transform(rows)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> row <span class="kw">in</span> rows:</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(row)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>[ 3.63290396 -0.26905319 -0.75963486 -0.83054452 -0.66701483 -2.00306229
  1.62837113  3.97138436 -0.63032535  0.81072819 -1.35519939  0.5305951
  0.9832535  -1.53172945  0.76200218 -2.71737872]
[-2.50543646 -1.0531194  -1.25797042 -0.70260662  2.87314023 -0.6575616
 -2.72333697 -2.09114705  1.07891416  0.19957176 -0.39701868 -0.30761252
 -1.6248677  -0.68144129  0.1744389  -0.55167589]
[ 0.57512783  1.35532371  1.41477612  1.45380674 -1.21449146  1.79260813
  0.24625868  0.70861441 -0.37936415  0.11142895  0.41135976  0.12214296
 -0.80809659  0.10402521 -0.03952505 -0.20742666]
[-4.32755548 -1.46683985 -0.02110513  0.80116523  0.59231517 -0.59990371
  0.46388446  0.53440046  0.0528506   0.04872767  0.27035028 -0.88934939
 -0.4905834   0.78973786  0.15576816  0.55738104]
[-3.80544372  0.27834796 -0.59898218  1.24946601  1.09367334  0.22683522
 -1.17847891  2.3972869  -2.72689888  4.11945948 -1.0307113  -0.186891
  2.58925427 -3.5781414  -2.63967676  8.17944977]
[-3.80512433 -0.55561667  0.20428031  0.74697848  0.5652898   0.41550072
  0.24551818  0.1208196  -0.73418729  0.77711176 -0.01322868  0.01759296
  0.44423267 -0.717342   -0.02248741 -0.1156379 ]
[ 1.48125903  1.97113906 -2.44726527 -1.1464928   0.05447869  1.08508601
 -1.98374718  2.24494609  0.99140275 -1.45440836  0.78070858 -1.53387163
 -0.82945951 -0.21947102  3.40149417  0.76782379]
[-1.72138888 -0.44221561  1.20444775 -0.45187996 -1.63517265  0.91181127
 -0.62029235 -0.34810374  1.01412418 -0.21813734 -0.61464242 -0.06228459
  0.22096034 -0.5349996  -0.1461798  -0.39521942]
[ 1.30009935  0.88697266  0.71216688  0.11395367 -3.58426535 -1.467071
 -1.89701926 -0.46219999  0.25014303 -0.72612312  2.60371909  2.15399299
 -0.27514916 -1.31509253 -0.27425489  0.04572785]
[-1.01108758  1.57506208 -0.41865586 -0.27737711  0.18121941  0.18541094
 -1.46442848  1.00939911  0.61323931 -0.20826078 -0.57047357  0.7331951
  0.29470991  0.97101938 -0.0079619   0.1776599 ]
[ 4.21900238 -1.79911129 -0.36556207  3.25507284 -1.04648792  1.42596773
  0.08699577  0.23717154 -0.69416887 -0.13150748 -0.66213905 -0.62801708
 -0.13777818  0.702631   -0.32372459  0.19988571]
[ 1.87860923 -3.93505854  0.66598645 -3.17233991  0.61134342  3.49498293
 -3.15652224 -0.12176354  1.02744177 -1.48085031 -1.58188824 -0.5312678
 -1.31361801 -1.7743066   1.58292903  0.85654401]
[-1.42968493 -0.7699148   0.95783193 -0.82747796 -0.04437012  0.21952718
  1.38652504 -1.7431388   4.06941226 -0.17293552 -0.0159219  -0.15598428
  1.18157644 -0.42075936 -0.2469527   1.02938142]
[ 2.00432123  0.391836    3.00897406 -2.4194508   1.70793549  3.04272547
 -1.20319854 -0.10868272  1.81176478  0.22452183 -0.20123446 -0.91087221
  0.60788806 -2.43162535  2.51586719  0.0530231 ]
[-0.31542712  0.55624178 -1.50950887  0.86383296  0.21501074 -0.59090506
 -1.78307641 -0.71264245  1.95662984 -0.39856953  0.61549051  0.16295366
 -1.75545608  1.50313836  0.58196731  0.64592333]
[-4.3549411   0.22031782 -1.34902547  1.05815152 -0.09444963 -0.44697974
  0.3190758   0.87320074  0.20673803 -0.72425274  1.75722642  0.58280537
 -0.415118   -0.6623826  -0.04493216  0.48781959]
[ 3.65542878e+00 -1.35901032e+00 -4.43652005e+00 -9.21701066e-01
 -1.03153315e+00 -3.12294702e-01  1.50067504e+00 -1.05561721e+00
 -1.73651212e+00 -1.75228044e-01  3.49461988e-01  3.45630620e-01
 -2.62618965e-03 -5.22634132e-01  1.77878465e+00 -8.86836216e-01]
[-3.71440030e+00  6.27003008e-02 -3.78293930e-01  1.50459956e+00
  5.31361110e-01  1.35866325e-01  1.70574642e-01  3.69477882e-01
 -7.78578302e-01  5.14295383e-01  4.20365166e-01  5.14882045e-04
 -1.89510457e-01 -5.52643733e-01 -2.56539661e-01 -3.78204875e-01]
[-3.35947632 -0.67782348  0.49408447  0.8688287  -0.30825067 -0.42126922
  0.55169583 -1.06563999  0.78741918 -0.23518728 -0.60215006 -1.22619233
  0.18370453 -0.67004432 -0.11592159 -0.43910892]
[ 1.04883042  1.34075534  0.51432831 -0.61288842 -2.12677134 -0.15354134
 -1.04024617  1.09838794  0.22439038  0.37464006 -0.29428567  0.40437696
  0.247302   -0.01449657 -0.08404072 -0.01646517]
[ 4.67240476 -0.94728091  1.18374219  3.24863913 -0.99915176 -0.68834913
  1.3060682   0.45761004 -1.56024706  0.32330723 -1.05930961  0.15738847
  0.76950254 -0.64980675  2.10856114 -1.25229742]
[-3.14380529 -0.93703317 -0.19089444 -0.02163574 -0.01706284  0.13090815
 -0.82851239 -0.56801847 -0.15091715 -0.14106645 -1.09748095 -0.5754304
 -0.77179581 -0.99043146 -0.39927311 -0.92307266]
[ 3.14230534 -0.88373043 -0.84907542 -0.3442325   1.13571122  1.56019751
  0.90567597 -0.02692798 -2.29739746 -0.42431907 -0.59807426  1.04073852
  3.04351406 -0.37141378  1.45512172 -0.85172078]
[-2.89605295  0.13309272 -1.44872568  0.47905977  0.93023381 -0.04729705
 -0.77843075 -0.74225408 -0.08840612  0.44148017  0.0747809  -0.43333149
 -0.21254878 -0.08266229  0.65314385 -0.43125002]
[-2.7651427  -0.76767519  0.46405471  0.12681803  0.92950923 -0.25833073
  0.13358689  1.65454957 -0.82539863  1.5293267   0.19858774 -0.32876298
  0.83726456 -1.24520496 -0.46378015 -0.59286055]
[-2.31593426  0.20816476 -1.32233728  0.68821447 -0.1205255  -0.04914912
  0.20802619 -0.56052941  0.9951959   0.92275696  0.10340133 -0.85904856
  0.34284165 -0.68232706  0.23630701 -0.3573448 ]
[ 0.90513103  0.84037339 -0.23588065 -0.40415468 -3.00256307 -0.56187717
 -0.24030195 -1.41431694  0.67240607  0.55822977 -0.65856163 -0.5290646
  1.73768189  0.45396524  0.69694769  0.96146886]
[ 3.51686354  1.18953401 -0.15082226 -0.54863755  1.33895163 -1.62610914
  0.9687283   1.4689734  -1.21701436  0.69971458 -1.28919147  1.83033171
  2.16165092 -1.22294947  1.14536868 -1.51515659]
[-1.11646438 -1.35950205  1.93130536  0.23670774  0.69145193  2.59994794
 -0.21081999 -0.07970469 -0.86867214 -0.14536665  1.25752625  0.21451832
 -0.14992586  1.13885051 -0.54506479  0.02890934]
[-4.76034396 -1.47674613  0.71635247  0.43420875  0.56406908  0.50386866
  1.50748531  0.07556744 -0.36614997  0.13112188  0.71920868 -0.61552411
 -0.37728376 -0.11467782 -0.06422282  0.08203046]
[ 4.28138637 -0.2430172   0.59692878  4.86817328 -0.25973416 -1.08485833
 -0.51553971 -0.16828751 -0.2798507  -1.31421573  0.88235935 -1.21361329
 -0.97178191  0.31845997 -0.45762573  0.22451293]
[-0.89850685 -1.41733739  1.90254225 -1.57201245 -2.06876504 -0.05880357
 -0.90780736  0.2652157   0.01291954 -0.68782743  3.22067692  2.16414012
 -0.11230539 -0.45356319 -0.09294589  0.20088035]
[-4.13618834e+00 -1.90030327e+00  1.95253427e-02  2.19522909e-01
  8.33680282e-01  7.92789690e-01  4.68357982e-02  3.24368376e-01
 -9.56672626e-01  6.33378719e-01  4.58248171e-01 -1.73989519e-01
  8.10105725e-02  1.94289651e-01 -3.62714567e-01  3.85809745e-03]
[ 1.36778706  0.91061851 -0.55390263  0.51807286  2.58545835 -1.32106204
 -1.5137611  -0.16536484  2.3138031   0.56470864 -1.36562041  0.34879193
  0.42877102  1.21623967  0.74271248  0.19439778]
[ 2.79133997  1.72771393 -0.01978475  0.20235463  0.31757309 -2.83074127
  3.85576001 -0.84459716  1.13110606 -1.86468319  0.24659057 -2.1308455
 -0.77538842 -0.14249093 -0.70615722  1.16344577]
[-1.75872878  0.23990732 -0.61669959  0.85324459 -1.15553712 -0.7402944
 -0.52396256 -0.91328483 -0.82957193  0.0434727   0.14885883 -1.67286865
  0.03697384 -0.83850139  0.39469087 -0.75795797]
[ 2.17060346 -3.27682478 -0.89351499 -1.85542248  2.79769702  1.30270831
 -0.83972967 -0.69592504 -1.22414105 -1.07590453 -1.43641636  1.93675674
  0.11731992 -0.2916182  -1.66474381  0.22834854]
[ 3.11751198 -0.62165342 -2.75301816 -0.16927872 -0.71654894  0.9840727
  0.72880631  1.78039587  0.1089083   0.00621287 -0.92015618  0.25096107
 -0.06755308  0.24104172 -0.96590188 -0.16295969]
[-1.61595434 -1.4138434   2.01027881 -1.88025795 -0.37058065 -0.49312606
  1.29744398 -0.28261732  0.28696516 -1.42401513  1.7206614  -0.40311683
  0.51303214  0.72804132 -0.03291777  0.9579771 ]
[-2.21180644  0.02325816 -0.69959888 -1.11994319  0.53980571 -0.4263375
 -0.36305957  0.0414431   0.33312045 -2.38431929 -0.69803995  0.52241839
 -0.89564597  1.04333017 -0.25145812  1.19530183]
[-2.22394292  2.23995792 -0.00420824 -0.22793185  0.34629144  0.76525213
  0.29196915 -0.84234451 -0.11199761 -0.63949839 -1.05807051 -0.43558252
 -0.64640281  1.52464545  0.37457427  0.30118337]
[ 1.18054396  4.65046976 -0.78887449 -2.39958968  4.37869136  2.24182967
 -0.25639144  0.7240268   1.94866911 -0.30528792 -0.31669114 -1.28858043
 -1.39523699  0.88334569  3.87353275  1.29591069]
[-1.08791351  1.84539147 -0.5423528   0.82824189  0.68641564 -0.0759606
 -1.6962579   0.81868694  0.81233386 -0.81050102 -0.54312727  0.49996037
  0.11374387  1.69220819 -0.25324481  0.51878657]
[-2.05428267e+00 -9.40505347e-02 -1.30956262e+00  8.27208236e-01
 -8.89258482e-01  9.21885927e-01 -3.69587201e-02 -1.05006971e+00
 -1.00388235e+00 -5.57109076e-04 -3.80729766e-02 -1.75878551e+00
 -4.33292888e-01 -3.04113830e-01 -8.22453353e-03 -7.88228811e-01]
[ 1.03249736 -3.75730794  2.94492119 -2.93854325  2.58474814 -2.11149043
  1.54024252  1.39719511  4.08685436 -0.19178214  1.31049627 -1.30330282
  0.31025914 -0.51058502 -1.00351338 -0.58431144]
[-0.65279983  0.35299244  0.77290863 -0.87651842 -1.12800373 -0.34567202
  0.50465592 -0.53563184  0.39187447 -1.66204608  1.20245134 -0.3511073
  0.72765529 -0.49999435 -0.12044442  0.72203437]
[ 4.19233558 -1.68267681 -0.16423532  4.60471018 -0.29055125  0.86720179
 -0.60936085 -0.08018765 -0.51835051 -1.08630845 -0.61397939 -0.94793972
 -0.45291881  1.62278094 -0.77747973  0.84814369]
[-3.31585044 -2.41670633  0.50918064 -0.89142188  0.7628907  -0.26330437
 -0.06320665  1.64898005 -1.69068537  1.82058171  0.4744114  -0.55517473
 -0.43524553  0.82910058 -0.03510181  0.20154607]
[-0.84371659  1.82824355  2.05403711 -2.14058814 -0.3473553   1.76955422
  3.83822686 -1.60607035 -0.28363292 -1.58844258  0.31729227 -0.55356597
 -0.69137295 -0.2950186  -1.94904055  0.35847404]
[ 0.71866692  5.27213599  1.19462687 -2.58553493  0.53851823  1.41550853
  2.21962689 -0.85995732 -1.50500437 -0.10145741 -0.51786776 -0.04645079
 -0.89052573  0.44491028 -1.75565384 -0.23082677]
[-1.37719848  0.80491787  2.06580862 -1.39691601 -1.24776299  2.23587516
  0.80248854 -0.99106775  0.33836547 -0.17728791 -0.88511168 -0.43552624
 -1.02406011 -0.68258805 -1.62907442 -0.81206171]
[-1.03768616  3.34734362  0.52510966 -1.20346792  0.06981986  0.97734721
  1.09898387 -0.88043963 -1.15569966 -0.47902261  0.27910369  0.06452473
 -0.88349744 -0.25195734 -1.84550506 -0.79369604]
[-0.08161665  4.18736714  1.05097756 -2.01196301  0.35337569  1.21077697
  1.64861977 -0.7817619  -1.25399235 -0.1488881  -0.5307951  -0.03884329
 -0.69929173  0.35911934 -1.38900847 -0.19848017]
[ 3.14591749  4.98039154  0.9180081  -2.2166257   2.75555299  1.26525025
  3.99960911 -0.06114521 -1.31128834  0.38659738 -1.18861037 -0.11592654
 -1.45312244 -0.44057882 -2.76665876 -0.75383907]
[-1.09623229  0.02249115  1.01064603 -0.48889478 -2.43928094  0.4306029
 -0.86078109 -0.16768997  0.17947136 -0.72920093  1.72441444  2.13564394
  0.3671333  -1.15963055  0.04563964  0.09121612]
[ 0.51981804  3.1344035   0.96858405 -2.37259597 -1.8771683   0.146196
  1.45519226  0.17835015 -1.77965308  0.74411546 -0.78133012 -0.72654193
 -2.35190915  1.81822291  1.24381956  1.26081215]
[-0.35831685  1.57780151 -1.52930012  0.00254734 -1.30785076  0.12948897
 -1.56001859  1.65707099  0.96633405 -0.80723558  0.18754443 -0.03061328
 -0.98275854  0.7911587  -0.0851965   0.07783308]
[ 1.41575371  0.44151735  1.01524957 -0.82838854 -2.95984344 -1.74978277
  0.08919802 -0.4953816  -1.60966353  0.85606404 -1.31303082  0.17032058
 -0.17741221  1.09734313  2.20254448  0.24777833]
[-2.0177969   1.13300827 -0.05847683  0.6546898   0.20786374 -0.18534806
 -0.24157692 -1.3463113  -1.03251529  0.32866917  0.19737541 -1.33039397
  0.35498706 -0.76753076  0.249384   -0.92971995]
[ 1.62865616 -1.81445588 -2.34187774 -1.51246466 -0.26950333  1.0518729
  3.22849332 -1.22566082  1.50206442 -1.59170423  0.23324049 -0.9641779
  3.23448923  0.02651377 -0.25451546  2.41802721]
[-0.24966375 -3.17453687  2.9905215  -2.9508601  -1.39882515 -1.74974629
  0.25759415  4.0915795  -1.49824563  2.73090768  1.29306504  0.36092648
 -1.8948996   1.88084424  0.27963686  1.39283466]
[-2.74684674 -0.89624419  0.05099595 -0.0345694   1.16129988 -1.09870966
 -1.19167716  1.08366178 -0.05385665  0.66886483  0.05785711 -1.44128535
  0.13384126  0.75855256  0.0317336  -1.07217943]
[-1.37901399 -0.52741326 -0.12221383 -0.60173386 -0.71579063 -0.04701894
 -0.10466962  0.76390821 -0.6888194   0.37748775  0.11133758 -1.59464618
  0.82613326 -1.28194108  0.22993914 -1.24857272]
[-1.23788286 -0.07317675 -0.59390591  0.41409463 -1.06364102 -1.34182809
 -0.49144431  0.28330907 -0.70441343  0.30634784  0.20596629 -1.99038501
  0.0609365  -1.0866938  -0.04637368 -1.45277554]
[-3.63248094 -1.50290969 -0.42722612 -0.02574232  1.06159902 -0.09475639
  0.01203906  1.81694002 -0.95341228  1.14340863  0.47046352 -0.36899907
 -0.0765617   0.26179531 -0.87268053 -0.52885265]
[-2.20717977  1.78588534 -1.99695132  1.17730332  1.28320787 -0.48928628
 -1.48100115  0.16143473 -0.31574745 -0.85466069  0.36653074 -1.33323759
  0.2292541   0.49142433  0.16956528 -0.21057875]
[-1.59071021  1.66556935 -0.93104464  1.15029686  0.94257279 -0.9793179
 -0.96654849 -0.48580642 -0.97106604 -0.46639072  0.74034478 -1.23889774
  0.53800026 -0.50342772 -0.26307531 -0.48961475]
[-5.13499478 -1.18681202  0.05532225  1.36802078 -0.08543362  0.41688369
  2.37429531  0.85930133  0.83230814 -1.22262206 -0.94511428  2.16402312
 -0.28040238 -0.15452737  0.58289047 -0.23189791]
[-4.22164787  0.06022221 -1.49216413  0.94827584  0.73487571  0.37301243
  0.17987657  0.47426973  0.1551837   0.72302494 -0.37051991 -0.10847433
  0.42342406  0.17272585  0.11113695  0.40369563]
[-4.51093637 -0.47760373  0.01854846  0.85236622 -0.04768036  0.36981932
  0.19562675 -0.24793734 -0.54629435  0.08770306  0.81010082  1.0103546
  0.23854803 -0.91861415  0.00721902 -0.21455702]
[-2.59279309 -1.45330245 -0.49845374  0.10445195 -0.79119156  1.61478218
 -0.52621718 -0.47517136  0.31311202  0.13605298 -0.66528665 -1.29067673
  0.28442856 -0.81832626 -0.28324933 -0.81291749]
[-1.00598886 -0.07684607  1.74107382 -0.82771013 -1.54746731  1.77706149
 -0.13963231 -0.47057337  1.08620975 -0.01407325 -0.57644279 -0.26304864
 -0.20470951 -0.66554493 -0.2402549  -0.53616362]
[ 3.20278086 -0.06198516 -3.19746981  0.02178899 -0.93821803  0.46326251
 -0.01087572  1.68545681  0.02822028 -0.47650572  0.21116511 -0.25221323
 -0.42179958 -0.24043946 -1.17518055 -0.37200175]
[-0.48981211 -1.32152756  0.37723797 -0.94543312 -1.93231919  2.02110361
 -1.01632989 -0.16114643  1.14367069 -0.33309295 -0.84443985 -0.09490274
  0.2104032  -0.08482819 -0.76134523 -0.13382244]
[ 1.24599871e+00  5.26816585e-01  1.15097895e+00  3.11346656e-01
 -2.63999209e+00 -7.43041992e-01 -6.99305998e-01 -2.79451564e-01
  4.56211637e-01  5.12865961e-01 -8.33739265e-01  4.28949503e-02
 -4.43340572e-04  2.88357097e-01  2.56416457e-02  1.01507342e-03]
[-1.701135    1.55654258 -0.86348745  0.12858476  0.40494567 -0.65010502
 -0.73444149 -0.27849694 -1.0726884   0.13235785  0.65339307 -0.98734829
  0.76680716 -1.09681621  0.05157823 -0.82699001]
[-2.19454477  1.59745025 -1.81429092  0.1835298   0.852717   -0.23570121
 -1.37127603  0.34974956 -0.48070039 -0.33780066  0.31053737 -1.08508137
  0.37447972 -0.14034936  0.37778138 -0.4760216 ]
[ 2.8549502  -0.66207202 -0.0801087   2.76072375 -2.31716542  1.33255716
 -1.13013276 -0.0593589  -0.40707255 -0.55478159  0.80702896 -0.39411902
 -1.11679657  0.82630034 -0.92318373  0.19685793]
[-1.1547215   1.40213553 -2.49174784 -0.34502681 -0.62589275  0.71862679
  0.21029525  0.02077066 -1.35433572 -0.39814986  0.19307511 -2.23879082
 -0.69027209 -0.19771526 -0.26142212 -0.29683553]
[-4.58405028 -0.82066397  0.34041254  1.67763998 -0.54787955  0.1648662
  2.13946487 -0.470511    1.73386963 -1.78083762 -1.73905617  2.09527449
 -0.2754231  -0.08310025  0.9173241  -0.39665296]
[ 2.79136235 -3.22479928 -0.61835661 -2.23330205  2.79245769  1.26218538
 -1.45258029 -0.68125204 -1.41750472 -1.11212525 -1.57298675  1.91072403
  0.41546571 -0.3943601  -1.70185114  0.42367515]
[ 3.88240706 -0.48870445  0.02120148  0.93604326 -1.43672887 -1.65509294
  0.96093413  0.01885571  0.45750674  0.54453724 -1.37993489 -0.3720022
  0.07856151 -0.42216431  0.06655377 -0.38275428]
[ 2.78245166  1.87194137 -3.74389245 -0.64775209 -0.20195268 -0.70411995
 -0.83419585  2.2655807   0.42268007 -1.61598345  0.30758991 -0.84726902
 -0.52009457  0.53534999  0.53302717  0.18101104]
[ 0.13639096  1.88720953 -1.72271234 -0.81968008 -1.31663404  0.33285063
 -0.97337596  1.45940944  0.59599697 -0.82836376 -0.45557392  0.02164399
 -0.26667809  1.42419013  0.6034177   0.46766774]
[ 1.49796434  0.22252547 -0.85170199  1.86704284 -1.62426472  1.85160399
 -0.74272171  1.15006015 -0.41660246 -0.7435211   1.16869609  0.10846242
 -1.0740025   0.47246408 -1.05304578  0.02981281]
[-3.81013265 -2.13674705 -1.29241062  0.4642877  -0.06696732  0.10042725
  0.00555671 -0.00434154 -1.03763524  0.7983097   1.37739366 -0.63685191
 -1.30450333  0.04063538 -0.1554256  -0.04558797]
[-4.03308987 -1.2010013   0.65355609  0.80229294  0.68101577 -0.63148978
  0.07291942  0.04071319 -0.89702251  1.06345179  0.2651422  -0.35881789
 -0.07335121  0.16913648 -0.06030211 -0.15878562]
[-2.37714464  1.05070913 -1.52941184  0.85018913  0.5523022  -0.57357618
 -1.13195145 -0.62084599 -0.35625557 -0.21853401 -0.04402152 -1.39085985
  0.38467074  0.13174067  0.57776669 -0.54953465]
[ 4.32314008 -1.21755689  0.31726216  2.8968169  -0.59994219  2.63951834
  0.79431731 -0.03104733 -0.92530197  0.1108322  -0.61054665 -0.88646028
 -0.86092328  0.60172071 -0.3829801   0.01076103]
[-4.83985064 -0.75441394 -0.74553143  1.43014986  0.17216125  0.05923312
  2.29003239  1.75825827  0.83214279 -1.35933979 -1.45175999  2.50093393
 -0.37497621  0.28083814  1.20492691 -0.3665968 ]
[ 2.856747   -3.08870906 -4.38291197 -1.92816101  0.4400475  -0.46344022
 -0.74595467 -2.29139145 -2.00604373 -1.73525439  0.55484683  0.66529052
 -2.69293359 -0.53577071 -0.71725266  0.29146951]
[ 3.12223747 -0.07698616 -4.04463934 -1.1206181  -1.42430087  0.96100384
  1.1040424   0.25240026  0.45264801  0.11842654 -0.7410481  -0.51527288
  2.07668808  0.42276442 -0.12211511  1.179069  ]
[ 3.30467668 -3.5887114  -4.25084952 -1.29088614  0.62248883 -0.34538265
 -0.83180049 -1.75877466 -1.23048244 -1.06062348  0.39158373  1.03010216
 -3.17819624 -0.67679251 -1.20102081  0.0254191 ]
[ 2.71451831 -2.25839771  3.57805523 -0.4197252   1.31526352  3.78156025
  0.15401079  1.50252968 -0.20679008 -0.09145345  2.81253955 -1.5859056
 -1.4858625  -0.5264912   3.2990785   0.54946664]
[-5.31295706 -0.90311631  0.07143011  1.49320721 -0.00635737  1.01238467
  2.38975846  0.07719283  0.59823519 -1.17542538 -0.87073239  1.96544382
 -0.53329864 -0.02869115  0.65645918 -0.08976625]
[ 3.19142298 -4.88636503 -1.06999168 -2.63391965  0.77773075  0.76880811
 -0.84079236  1.99035744 -0.87077282 -1.04275948 -1.66832245  0.65098403
 -0.88810266 -0.8125336  -2.19465154 -0.75810952]
[ 2.79162628  0.17102041 -0.67360857 -0.73446565 -0.63809752 -1.5142413
  0.87515681  3.5698163   0.52551863  0.58228191 -0.5901698  -0.24149713
  0.16035378 -1.04620808 -0.92133776 -1.55534107]
[-4.97538282 -0.81268929 -0.15779295  1.50734014 -0.02336208 -0.03824646
  1.25125458 -0.43762355 -0.08637507 -0.05143223 -0.30197726 -0.26709649
 -0.28138697 -0.15962898 -0.05080962 -0.11569135]
[-4.80584358 -0.2413502  -0.31964197  1.63449931  0.17510897  0.49945637
  1.75352073  0.66006919  0.43271962 -0.80789057 -1.25351194  2.84489333
 -0.32286832  0.06719159  0.76003812 -0.22459187]
[ 4.67442489 -2.07149443  0.30358208  1.46553034 -0.11714575  3.92298443
  1.84409861  1.00552129 -2.04415501 -0.18819029 -0.39420204  0.21505505
  0.57600635 -0.60856356  1.33996818 -1.01982205]
[ 1.7564206   0.29796858  1.8283896  -0.6003848  -3.27377053 -1.90728652
 -0.46774239 -0.17261821 -0.72274003  1.80156578 -1.2514782   0.0174588
 -1.51785396  1.76266239  1.31307202  1.16139007]
[-0.6582061   0.65446128  1.30574331  0.13055496 -0.84425156 -0.80768178
 -1.43990329 -1.13886262  1.08037983 -0.0477332  -0.41105915 -0.01316674
  0.20408236 -0.4750368  -0.79459692 -0.64427756]
[ 2.6657048   1.26102454 -0.13366391 -1.27083307  0.05854981 -2.00445216
  2.09837005  0.73162398  0.42563401 -1.59395869  0.28464143 -0.55214728
  1.57792363 -0.62805545  0.04814974  1.19449237]
[-2.85316957  1.32285112 -0.49144893 -0.76697607  1.12043505  0.54682385
  0.79765676 -1.40113571 -1.46662793  1.25420491 -0.39682544 -0.89426937
 -2.27181526  0.67830731  0.13963242 -0.19070584]
[-3.13635195  0.22236499 -0.58731331  0.08105277  0.87845504  0.7089911
 -0.88639735 -1.1222881   0.4594917   0.4874858  -0.32345304 -0.89638621
 -0.47153439 -0.42858837  0.46887263 -0.71693431]
[ 3.53883505 -1.7452466  -3.17031106  0.58077409 -1.78605915  0.4705105
  1.30157552 -0.86964293  1.42970219  0.95588678 -1.61910125 -0.70529065
  1.67105582  0.70712246 -0.39037349  1.00097087]
[ 1.99988812 -3.83876152  1.14265815 -2.73404757  1.06683915 -4.60805409
  4.02345942 -0.63532578 -1.08959232  0.75164455  2.25011584  0.08261077
 -1.71122421  1.24466755  2.67504166  1.30337263]
[ 2.05080466  0.8139927   0.89293344  0.54714573  1.93073624 -1.92327466
 -0.40524411 -1.18953547  1.61656143  1.32797362 -0.96950266  0.58613704
  1.03644196 -0.09616191  0.3158563  -0.34149143]
[ 0.55664983  1.03990219 -1.65465947 -0.95134242  1.0857365   0.05849109
 -1.26030699  0.51427035  2.90202372  0.14163268 -1.62698318 -0.24988964
  1.99125726  0.21560926 -0.09816889  0.73891861]
[ 0.08282658 -0.320351    1.93366331 -0.71401905 -2.79723564 -1.19543853
 -0.77506291 -0.62465345  0.46646092  1.23647869 -1.60798333 -0.37841842
 -1.30236653  1.00846073  0.72288871  0.46140342]
[-0.70887873  1.63146755  1.34903714 -0.19883052 -0.58238165  0.10570197
 -0.2845675  -1.29690917 -0.54214608  0.18844054 -0.55798571  0.123877
  0.61253346  0.29239807  0.20139757 -0.15747349]
[ 2.80259823  1.57935359 -2.83094972 -0.75585062  2.74467132 -1.94475341
 -0.90717139  4.48306632  1.30398754 -0.596238    0.24068251  0.04112843
 -0.16782047 -0.02308084 -1.37878014 -1.3324514 ]
[ 2.97527177 -1.12457174 -5.07924938 -0.98338736 -1.42327156  0.09797569
  0.80952599 -2.04164244  0.25014691  0.06038246  1.31015242 -0.64516368
  0.54733531 -0.3083384   0.28780407  1.00283867]
[-1.04555403  0.77754213 -2.39407619 -0.25318033  0.25020911 -0.98665851
 -0.10140046 -2.5149449  -0.43519464  1.05910526  1.55250202 -1.20222978
  1.30485138 -1.35533716  0.74932059 -0.07098685]
[ 2.79706599 -1.67228746 -4.90105873 -0.18616489 -1.22369936  1.95499198
  1.7512908  -2.43140668  2.9034408   5.14306564  1.45191413  1.4186546
 -0.17045103  1.16798555 -0.0385939   0.20489873]
[ 1.13873691 -0.09830192  1.75874027 -0.31779097 -2.64294847 -0.54432657
 -1.29071085 -0.62098672  1.62163847  0.39122542 -1.39153964 -0.39949305
 -0.08331903 -0.22309414 -0.39274932 -0.32782228]
[ 0.13618237  2.91785104 -0.11865743 -1.0255762  -1.52954613 -1.21842098
 -1.54267287 -0.21666845 -0.5269007  -1.25140152  3.31457135  2.89969477
  0.84081711 -1.41621138 -0.37237915  0.033766  ]
[-0.15011694  0.26162331  0.70753706 -0.42304341 -2.13272846 -1.10338284
 -0.4436895   0.5887846  -0.05428662  0.10829074 -0.638332   -0.46449059
  0.29921711  0.08589679 -0.10142988 -0.73290579]
[ 2.38563754 -0.53696353  0.75930727  0.70988027 -0.05975688 -2.50508968
  2.74909316 -0.51247342  1.48219313 -0.8878707  -0.52210973 -0.65198558
  0.8509863  -0.30557689 -0.29718876  0.83651712]
[-5.02768569 -0.38463717 -1.16022345  1.50441806 -0.45775598  0.33723724
  2.08757217  0.83486588  1.61341734 -1.74003757 -0.22199002  3.61846363
 -0.05405465  0.07801679  1.11187963  0.93015003]
[ 3.53228860e+00 -9.45450443e-02  2.94227405e+00  5.74561193e-01
  2.16915374e+00  2.91604948e+00 -1.31341004e+00  8.36291023e-01
 -1.78291370e-03 -2.26717046e-01  1.40230026e+00 -1.26018635e-01
  9.26134585e-01 -1.82753442e+00  3.24000246e+00  8.72330612e-01]
[-0.75859652  0.03635213  0.79820597  0.35729402 -2.14688752 -0.46822019
 -1.00421097 -0.77074815  1.22689908 -0.22873815 -0.48145278 -0.54668982
 -0.56411501 -0.44019501 -0.51938133 -0.61318174]
[-3.09252307 -1.07210726  1.2127707   0.10258713  0.42059327 -0.64353183
 -0.83126293 -0.88097532  0.05626822  0.6857761  -0.12887285 -1.20094581
  0.31055119 -0.18579022 -0.09893736 -0.9653518 ]
[-4.12545731 -1.7399254   0.03882194  0.48311687  0.73320686 -1.14955051
  0.52173802  1.57153254  0.18797845  0.2872671   0.36452625 -1.22901346
 -0.45587852  0.70900299 -0.14394605  0.15399568]
[-5.15667865 -0.19342282 -0.80420931  1.63569275  0.37955534  0.70140396
  1.32477029  0.82495992  0.64553645 -1.01203344 -1.33156377  2.51178687
 -0.50384957  0.4992565   0.85460767 -0.10778639]
[-7.24102427e-01 -6.50997167e-01  2.05322371e+00 -9.42033852e-01
  1.18463103e-03 -8.12954117e-01 -2.41744754e+00 -1.74236988e+00
  3.16483509e-01 -2.69547596e-01 -1.90698836e+00  8.62219460e-01
 -1.80428729e-01 -2.40096096e-01 -9.15892894e-01 -2.43309422e-01]
[-1.37825475  1.59399363 -0.97673694  0.1440297   0.51735647 -0.3209376
 -1.42322606  2.38218678  0.18033468  0.27125214  0.43296608  1.14830385
 -0.44707885  0.84237402 -0.5002736   1.06661928]
[ 2.77642118 -0.95106611  1.2367229  -2.3224683   1.30026593 -3.49396283
 -1.13011377 -1.93909721 -3.2074504   0.5027884  -2.38200285  0.98460508
 -1.11712863  1.27275454  1.13466624  1.46876316]
[-3.13182041 -0.28265229  0.54486065  1.59409503  0.32481703 -0.59423186
 -0.42074565 -1.19507025 -0.21357997  0.09183583 -1.23096358 -0.69694429
  0.67181309 -0.50737235  0.47366793 -1.22165551]
[ 3.5557141  -0.64575703  2.34701576  4.62490056  0.96164157 -1.78441209
  1.50475388 -0.63246838  0.71693545 -2.16217394  0.4412983  -1.22721433
  0.33890464  0.76600641 -0.46727957  1.76902429]
[ 1.25755652  2.93460395 -0.58773758  0.55349747  1.08487273 -0.48935358
 -2.80791661  1.57721488  1.18643156 -0.88193431 -0.55505029  0.65206412
  0.36202026  2.33592374 -0.39000956  1.07610934]
[ 2.70751789 -0.93064082  0.51818908 -1.298501    1.65926187 -2.63744572
 -0.67563145 -1.70507377 -2.92080825 -0.6723785  -2.62810437  1.62028742
  1.34479341 -0.74717143  1.37771403 -0.87227279]
[ 2.86902323  0.25760579 -1.25599514 -0.34911369  3.01429698 -2.09915949
  0.44545385 -2.05013916  1.47465512  1.32491425  1.3424061   1.42476768
 -0.61888836 -1.08162715  0.30932651 -0.39448664]
[-0.92145608  0.49260212  1.56363639  0.51923433 -0.52166764 -0.9573199
 -0.72300588  0.48813693 -0.47264872  1.39714369 -0.52379409  1.20492481
  0.55232332  0.30730679 -0.33989217  0.94616219]
[ 4.71434639  0.6423578  -0.33947534  2.57902295 -0.37198113  0.01263856
  0.27388678  1.93803792 -0.56260398 -0.6612096   1.63514672 -0.29073698
 -0.89103264 -1.11789028 -0.45630838 -0.40551411]
[ 3.66715717 -1.29088752  2.22412871  3.50920405  4.93554521 -1.80219593
 -2.0552465  -2.37529329  0.16038637 -0.82692365 -0.96096858  1.21648749
 -1.15409148  0.916322   -0.69959283  0.74712747]
[-0.5179897  -2.18228681  2.11239996 -2.50491388 -0.01246562  1.3383105
 -2.05455209 -0.09549949  0.71468863  0.03580278  0.39889824  0.05348149
  0.85599415  0.82527356 -1.13434283  0.00588577]
[ 3.95620101e+00  2.86946490e-01  2.99455799e+00  1.18252817e+00
  2.03907439e+00  2.35809176e+00  5.52503793e-01  1.01123114e-01
 -1.09247843e+00  1.26051936e-01  7.83026128e-01  3.87814419e-01
  1.02879701e+00 -1.12803281e+00 -2.69776131e-03 -1.10708001e-01]
[ 2.37737657  2.40938286  1.30165218  1.69601773  0.05883477  0.13198155
 -1.33618236  0.86521978 -0.56265932 -0.22686117  1.78830223  0.83138592
  0.14911489 -0.32489541 -0.77164801 -0.12196727]
[ 0.67563236  1.99921968 -0.58401304 -1.41978476 -1.63674683 -1.7807025
 -1.68425962 -2.21282394 -0.71329396 -0.84994087  4.52146959  3.301528
  0.17214883 -1.81126177  0.31223868  0.23414814]
[-2.37710199  1.16718257 -0.90115362  0.35138417  0.4339171  -0.44346181
 -0.33890322 -0.37569476 -0.92342428 -0.00899847  0.52900358 -0.78517944
  0.48120647 -0.93543846 -0.02656904 -0.85345003]
[ 1.30710771  0.09517302  3.33157682  0.82960264 -0.3928425   1.9040515
  1.55387708 -0.11710956  0.3865938  -1.09845369  1.39462665 -0.19615685
  0.19620989 -0.29618704 -0.16531163  1.02754758]
[-1.7105257   0.4665655  -1.77179356 -0.23849966  0.25665338 -0.5265183
  0.24480626 -2.34059476 -0.36080016  1.2399262   0.62831829 -0.83852219
  1.51496759 -0.89786746  0.93974198  0.02768448]
[ 0.59200998  1.51169843  0.89706203 -1.06602627 -0.06862132 -1.0650828
 -0.66720477  2.16275489  0.3390826   0.7527193  -0.19333073  0.8989518
  0.80449045 -0.30110177 -1.15909835 -1.08735561]
[-0.09309414  4.15448553  0.84792568 -1.72955523  0.36221499  0.83502764
  1.2208934  -0.43433189 -0.94861143 -0.19297282 -0.36604962 -0.02566288
 -0.31657147  0.59296944 -0.20318199  0.2422719 ]
[ 2.24276823  0.1878944   1.15392434  0.14773244 -2.74123753 -1.25268239
 -0.10199548  0.06829818 -0.54490263  0.70770883 -1.50565509  0.69302525
  0.74321078 -0.12247449  1.48691469 -0.93791426]
[-6.91628661e-02 -9.51600661e-01  3.37905627e+00 -1.47764501e+00
 -2.47109484e-01 -1.42522959e+00 -1.80060148e+00 -7.70942641e-01
  1.10430637e+00  7.31032752e-01  7.87021805e-04 -1.84229833e-01
  3.85662562e-01  8.59721659e-01 -7.09826417e-01 -3.80316047e-01]
[-4.25161325 -0.84223963  0.47865846  0.11110338  0.64942181 -0.73396874
  0.35875191  0.67160334 -1.3990014   1.418966    0.30034084 -0.12494261
 -0.80478413  0.67252864  0.39217686  0.28775684]
[ 3.97704871 -1.41962332 -1.5328863   1.97823852 -1.11413517  2.00106542
  0.43498959 -0.61993785  1.62434071  4.30198593  0.30402808  1.07465461
 -0.79577343  1.73767647 -0.67464392 -0.76718885]
[-0.21474935  0.58422803  1.91762874 -0.18737691 -0.81372824 -0.63183717
 -1.29997577 -1.13393645  1.23395714  0.43062557 -1.23958743  0.22486023
  0.72791245 -0.16367841 -0.54863409 -0.41790285]
[ 0.50889168  3.70661438  0.43362423 -1.76713593 -0.00941309 -0.28854367
  0.3105935  -0.08936547 -0.76346289 -0.2903295  -0.38991432  0.18850073
  0.39656857  0.63460639 -0.12736217  0.51557362]
[ 2.61807908  0.91820887  2.65205832  2.3696803  -0.14353647 -0.0892564
 -0.80242305 -0.62654758 -0.39127512  0.46289741  0.17815512  0.81944883
  0.54152115  0.47582208 -0.24489872  0.15543411]
[ 4.20387266  0.58483203  1.30765355  4.67795621  1.86608725 -1.53508924
 -0.99009611 -0.72893841 -0.57767037 -1.14047516  0.9832171  -0.40912932
  0.08356032  0.28518274 -0.86754924  0.26675521]
[ 2.47436607 -0.96748787  1.22754961 -2.24844826 -2.33218808  3.76884777
 -1.09720374 -0.03676434  1.42750921  0.15085038 -0.91380804 -0.49320401
 -0.07516209 -0.241504   -1.07739221 -0.14463258]
[ 3.74209924  0.81374462  2.6362296   2.50462865  1.42047985  0.6029194
  0.34497161 -0.63590778 -0.99576004  0.60616929 -0.19570871 -0.01585031
  0.44554702 -0.29878105  0.02480014 -0.25513581]
[ 1.70670881 -3.25395132  2.24982593 -1.63600566  0.55231073 -4.11547288
  1.17622524  1.48521731  2.59369584 -0.96770392  1.47030664 -2.51761154
 -0.33655861 -0.49578711 -1.85951623 -0.95400075]
[-0.40816469  2.14991457  0.3240921  -0.817196   -0.39317169 -0.33606255
 -0.53186117 -0.01748607 -0.43643981 -0.0909218  -0.0909282   0.8141627
  1.05211002  0.13442737 -0.06512221 -0.03903874]
[-1.80102885 -2.33686505  0.18154599 -2.30812192  1.3741254   1.93516244
 -0.59557048 -0.70936767 -2.4005222  -1.23518124  3.11723849 -0.16632544
  6.06683491  7.59208666 -0.62202943 -2.07790396]
[ 3.90032031  2.74939155 -0.08292699  1.18959187  3.63186807  1.68186446
  1.39481381 -0.65006482  3.10684104  5.69676397  2.42539438  2.48331165
 -1.27380771  0.51193161 -0.65623429 -1.7712839 ]
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="13">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>tsne <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, perplexity<span class="op">=</span><span class="dv">10</span>, early_exaggeration<span class="op">=</span><span class="dv">20</span>, metric<span class="op">=</span><span class="st">&#39;cosine&#39;</span>, random_state<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> tsne.fit_transform(rows)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>plt.xlim(features[:, <span class="dv">0</span>].<span class="bu">min</span>(), features[:, <span class="dv">0</span>].<span class="bu">max</span>())</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>plt.ylim(features[:, <span class="dv">1</span>].<span class="bu">min</span>(), features[:, <span class="dv">1</span>].<span class="bu">max</span>())</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> f <span class="kw">in</span> features:</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    plt.plot(f[<span class="dv">0</span>], f[<span class="dv">1</span>], <span class="st">&#39;o&#39;</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>plt.show(block<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_1b729b2b838b4d78ad1ff18fd8e0de37/2231266397eabf9c652f314914376a0e3b1ac87a.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="14">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>k_means <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">7</span>, init<span class="op">=</span><span class="st">&#39;k-means++&#39;</span>, n_init<span class="op">=</span><span class="st">&#39;auto&#39;</span>, max_iter<span class="op">=</span><span class="dv">300</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>k_means_fit <span class="op">=</span> k_means.fit(features)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>plt.xlim(features[:, <span class="dv">0</span>].<span class="bu">min</span>(), features[:, <span class="dv">0</span>].<span class="bu">max</span>())</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>plt.ylim(features[:, <span class="dv">1</span>].<span class="bu">min</span>(), features[:, <span class="dv">1</span>].<span class="bu">max</span>())</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> f <span class="kw">in</span> features:</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    plt.plot(f[<span class="dv">0</span>], f[<span class="dv">1</span>], <span class="st">&#39;o&#39;</span>)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>centroids <span class="op">=</span> k_means_fit.cluster_centers_</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> c <span class="kw">in</span> centroids:</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    plt.plot(c[<span class="dv">0</span>], c[<span class="dv">1</span>], <span class="st">&#39;+&#39;</span>, color<span class="op">=</span><span class="st">&#39;black&#39;</span>)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>plt.show(block<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_1b729b2b838b4d78ad1ff18fd8e0de37/3052966a76f7b5fed6d65d51cc69a649215400ba.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="15">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>predicted <span class="op">=</span> k_means_fit.predict(features)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>plt.xlim(features[:, <span class="dv">0</span>].<span class="bu">min</span>(), features[:, <span class="dv">0</span>].<span class="bu">max</span>())</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>plt.ylim(features[:, <span class="dv">1</span>].<span class="bu">min</span>(), features[:, <span class="dv">1</span>].<span class="bu">max</span>())</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, f <span class="kw">in</span> <span class="bu">enumerate</span>(features):</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> predicted[i] <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>        plt.plot(f[<span class="dv">0</span>], f[<span class="dv">1</span>], <span class="st">&#39;o&#39;</span>, color<span class="op">=</span><span class="st">&#39;red&#39;</span>)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> predicted[i] <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>        plt.plot(f[<span class="dv">0</span>], f[<span class="dv">1</span>], <span class="st">&#39;o&#39;</span>, color<span class="op">=</span><span class="st">&#39;orange&#39;</span>)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> predicted[i] <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>        plt.plot(f[<span class="dv">0</span>], f[<span class="dv">1</span>], <span class="st">&#39;o&#39;</span>, color<span class="op">=</span><span class="st">&#39;yellow&#39;</span>)</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> predicted[i] <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>        plt.plot(f[<span class="dv">0</span>], f[<span class="dv">1</span>], <span class="st">&#39;o&#39;</span>, color<span class="op">=</span><span class="st">&#39;green&#39;</span>)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> predicted[i] <span class="op">==</span> <span class="dv">4</span>:</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>        plt.plot(f[<span class="dv">0</span>], f[<span class="dv">1</span>], <span class="st">&#39;o&#39;</span>, color<span class="op">=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> predicted[i] <span class="op">==</span> <span class="dv">5</span>:</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>        plt.plot(f[<span class="dv">0</span>], f[<span class="dv">1</span>], <span class="st">&#39;o&#39;</span>, color<span class="op">=</span><span class="st">&#39;purple&#39;</span>)</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> predicted[i] <span class="op">==</span> <span class="dv">6</span>:</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>        plt.plot(f[<span class="dv">0</span>], f[<span class="dv">1</span>], <span class="st">&#39;o&#39;</span>, color<span class="op">=</span><span class="st">&#39;magenta&#39;</span>)</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>centroids <span class="op">=</span> k_means_fit.cluster_centers_</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> c <span class="kw">in</span> centroids:</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>    plt.plot(c[<span class="dv">0</span>], c[<span class="dv">1</span>], <span class="st">&#39;+&#39;</span>, color<span class="op">=</span><span class="st">&#39;black&#39;</span>)</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>plt.show(block<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_1b729b2b838b4d78ad1ff18fd8e0de37/af8fb5ea3a6d212a361b93dc310923b2859cb594.png" /></p>
</div>
</div>
<div class="cell markdown">
<p>Now that the clusters have been organized and plotted on the graph,
we can try to identify or interpret meaning from the assignment of each
sample to a cluster. Since there are 7 clusters, we can try to select
features that can be split into 7 different classes to predict meaning
for the clusters. Features that are split in 7 different classes are
size and intelligence. We can aggregate the ratio of similar predictions
in each cluster for each class for size and intelligence to see how
strongly our clusters are associated with those features.</p>
</div>
<div class="cell code" data-execution_count="16">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>df_new <span class="op">=</span> pd.read_csv(<span class="st">&#39;DogBreeds.csv&#39;</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>df_new</span></code></pre></div>
<div class="output execute_result" data-execution_count="16">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Origin</th>
      <th>Type</th>
      <th>Unique Feature</th>
      <th>Friendly Rating (1-10)</th>
      <th>Life Span</th>
      <th>Size</th>
      <th>Grooming Needs</th>
      <th>Exercise Requirements (hrs/day)</th>
      <th>Good with Children</th>
      <th>Intelligence Rating (1-10)</th>
      <th>Shedding Level</th>
      <th>Health Issues Risk</th>
      <th>Average Weight (kg)</th>
      <th>Training Difficulty (1-10)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Affenpinscher</td>
      <td>Germany</td>
      <td>Toy</td>
      <td>Monkey-like face</td>
      <td>7</td>
      <td>14</td>
      <td>Small</td>
      <td>High</td>
      <td>1.5</td>
      <td>Yes</td>
      <td>8</td>
      <td>Moderate</td>
      <td>Low</td>
      <td>4.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Afghan Hound</td>
      <td>Afghanistan</td>
      <td>Hound</td>
      <td>Long silky coat</td>
      <td>5</td>
      <td>13</td>
      <td>Large</td>
      <td>Very High</td>
      <td>2.0</td>
      <td>No</td>
      <td>4</td>
      <td>High</td>
      <td>Moderate</td>
      <td>25.0</td>
      <td>8</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Airedale Terrier</td>
      <td>England</td>
      <td>Terrier</td>
      <td>Largest of terriers</td>
      <td>8</td>
      <td>12</td>
      <td>Medium</td>
      <td>High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>7</td>
      <td>Moderate</td>
      <td>Low</td>
      <td>21.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Akita</td>
      <td>Japan</td>
      <td>Working</td>
      <td>Strong loyalty</td>
      <td>6</td>
      <td>11</td>
      <td>Large</td>
      <td>Moderate</td>
      <td>2.0</td>
      <td>With Training</td>
      <td>7</td>
      <td>High</td>
      <td>High</td>
      <td>45.0</td>
      <td>9</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Alaskan Malamute</td>
      <td>Alaska USA</td>
      <td>Working</td>
      <td>Strong pulling ability</td>
      <td>7</td>
      <td>11</td>
      <td>Large</td>
      <td>High</td>
      <td>3.0</td>
      <td>Yes</td>
      <td>6</td>
      <td>Very High</td>
      <td>Moderate</td>
      <td>36.0</td>
      <td>8</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>154</th>
      <td>Wire Fox Terrier</td>
      <td>England</td>
      <td>Terrier</td>
      <td>Energetic</td>
      <td>7</td>
      <td>14</td>
      <td>Small</td>
      <td>Moderate</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>7</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>8.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>155</th>
      <td>Wirehaired Dachshund</td>
      <td>Germany</td>
      <td>Hound</td>
      <td>Wiry coat</td>
      <td>7</td>
      <td>13</td>
      <td>Small</td>
      <td>Moderate</td>
      <td>1.5</td>
      <td>With Training</td>
      <td>7</td>
      <td>Moderate</td>
      <td>High</td>
      <td>8.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>156</th>
      <td>Wirehaired Pointing Griffon</td>
      <td>Netherlands</td>
      <td>Sporting</td>
      <td>Shaggy beard</td>
      <td>7</td>
      <td>13</td>
      <td>Medium</td>
      <td>High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>7</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>20.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>157</th>
      <td>Xoloitzcuintli</td>
      <td>Mexico</td>
      <td>Non-Sporting</td>
      <td>Hairless variety</td>
      <td>7</td>
      <td>15</td>
      <td>Small-Large</td>
      <td>Low</td>
      <td>2.0</td>
      <td>With Training</td>
      <td>8</td>
      <td>Low</td>
      <td>Moderate</td>
      <td>25.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>158</th>
      <td>Yorkshire Terrier</td>
      <td>England</td>
      <td>Toy</td>
      <td>Long silky coat</td>
      <td>8</td>
      <td>13</td>
      <td>Toy</td>
      <td>High</td>
      <td>1.0</td>
      <td>Yes</td>
      <td>7</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>2.5</td>
      <td>6</td>
    </tr>
  </tbody>
</table>
<p>159 rows × 15 columns</p>
</div>
</div>
</div>
<div class="cell code" data-execution_count="17">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>index_0 <span class="op">=</span> np.where(predicted <span class="op">==</span> <span class="dv">0</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>index_1 <span class="op">=</span> np.where(predicted <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>index_2 <span class="op">=</span> np.where(predicted <span class="op">==</span> <span class="dv">2</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>index_3 <span class="op">=</span> np.where(predicted <span class="op">==</span> <span class="dv">3</span>)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>index_4 <span class="op">=</span> np.where(predicted <span class="op">==</span> <span class="dv">4</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>index_5 <span class="op">=</span> np.where(predicted <span class="op">==</span> <span class="dv">5</span>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>index_6 <span class="op">=</span> np.where(predicted <span class="op">==</span> <span class="dv">6</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="18">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(index_0)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>(array([  1,  23,  25,  35,  43,  58,  62,  63,  65,  66,  75,  76,  78,
        87, 104, 113, 140, 142]),)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="19">
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>cluster_0_rows <span class="op">=</span> df_new.iloc[index_0[<span class="dv">0</span>].tolist()]</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>cluster_0_rows</span></code></pre></div>
<div class="output execute_result" data-execution_count="19">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Origin</th>
      <th>Type</th>
      <th>Unique Feature</th>
      <th>Friendly Rating (1-10)</th>
      <th>Life Span</th>
      <th>Size</th>
      <th>Grooming Needs</th>
      <th>Exercise Requirements (hrs/day)</th>
      <th>Good with Children</th>
      <th>Intelligence Rating (1-10)</th>
      <th>Shedding Level</th>
      <th>Health Issues Risk</th>
      <th>Average Weight (kg)</th>
      <th>Training Difficulty (1-10)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>Afghan Hound</td>
      <td>Afghanistan</td>
      <td>Hound</td>
      <td>Long silky coat</td>
      <td>5</td>
      <td>13</td>
      <td>Large</td>
      <td>Very High</td>
      <td>2.0</td>
      <td>No</td>
      <td>4</td>
      <td>High</td>
      <td>Moderate</td>
      <td>25.0</td>
      <td>8</td>
    </tr>
    <tr>
      <th>23</th>
      <td>Bouvier des Flandres</td>
      <td>Belgium</td>
      <td>Herding</td>
      <td>Beard and mustache</td>
      <td>7</td>
      <td>11</td>
      <td>Large</td>
      <td>Very High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>8</td>
      <td>High</td>
      <td>Moderate</td>
      <td>34.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Briard</td>
      <td>France</td>
      <td>Herding</td>
      <td>Long protective coat</td>
      <td>7</td>
      <td>12</td>
      <td>Large</td>
      <td>High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>8</td>
      <td>Moderate</td>
      <td>Low</td>
      <td>35.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>35</th>
      <td>Chesapeake Bay Retriever</td>
      <td>USA</td>
      <td>Sporting</td>
      <td>Waterproof coat</td>
      <td>7</td>
      <td>11</td>
      <td>Large</td>
      <td>Moderate</td>
      <td>2.5</td>
      <td>Yes</td>
      <td>7</td>
      <td>Moderate</td>
      <td>Low</td>
      <td>30.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>43</th>
      <td>Curly-Coated Retriever</td>
      <td>England</td>
      <td>Sporting</td>
      <td>Curly water-resistant coat</td>
      <td>7</td>
      <td>12</td>
      <td>Large</td>
      <td>Moderate</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>7</td>
      <td>Low</td>
      <td>Low</td>
      <td>32.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>58</th>
      <td>Flat-Coated Retriever</td>
      <td>England</td>
      <td>Sporting</td>
      <td>Shiny black coat</td>
      <td>9</td>
      <td>11</td>
      <td>Large</td>
      <td>Moderate</td>
      <td>2.5</td>
      <td>Yes</td>
      <td>8</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>32.0</td>
      <td>5</td>
    </tr>
    <tr>
      <th>62</th>
      <td>German Shorthaired Pointer</td>
      <td>Germany</td>
      <td>Sporting</td>
      <td>Versatile hunter</td>
      <td>8</td>
      <td>13</td>
      <td>Large</td>
      <td>Low</td>
      <td>2.5</td>
      <td>Yes</td>
      <td>8</td>
      <td>Moderate</td>
      <td>Low</td>
      <td>26.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>63</th>
      <td>German Wirehaired Pointer</td>
      <td>Germany</td>
      <td>Sporting</td>
      <td>Weather resistant coat</td>
      <td>7</td>
      <td>13</td>
      <td>Large</td>
      <td>Moderate</td>
      <td>2.5</td>
      <td>Yes</td>
      <td>8</td>
      <td>Moderate</td>
      <td>Low</td>
      <td>27.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>65</th>
      <td>Golden Retriever</td>
      <td>Scotland</td>
      <td>Sporting</td>
      <td>Golden coat</td>
      <td>10</td>
      <td>11</td>
      <td>Large</td>
      <td>High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>8</td>
      <td>High</td>
      <td>Moderate</td>
      <td>29.0</td>
      <td>4</td>
    </tr>
    <tr>
      <th>66</th>
      <td>Gordon Setter</td>
      <td>Scotland</td>
      <td>Sporting</td>
      <td>Black and tan coat</td>
      <td>8</td>
      <td>11</td>
      <td>Large</td>
      <td>High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>7</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>26.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>75</th>
      <td>Irish Red and White Setter</td>
      <td>Ireland</td>
      <td>Sporting</td>
      <td>Red and white coat</td>
      <td>8</td>
      <td>12</td>
      <td>Large</td>
      <td>High</td>
      <td>2.5</td>
      <td>Yes</td>
      <td>7</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>27.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>76</th>
      <td>Irish Setter</td>
      <td>Ireland</td>
      <td>Sporting</td>
      <td>Rich red coat</td>
      <td>8</td>
      <td>13</td>
      <td>Large</td>
      <td>High</td>
      <td>2.5</td>
      <td>Yes</td>
      <td>7</td>
      <td>High</td>
      <td>Moderate</td>
      <td>29.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>78</th>
      <td>Irish Water Spaniel</td>
      <td>Ireland</td>
      <td>Sporting</td>
      <td>Curly coat</td>
      <td>8</td>
      <td>11</td>
      <td>Large</td>
      <td>High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>7</td>
      <td>Low</td>
      <td>Low</td>
      <td>24.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>87</th>
      <td>Labrador Retriever</td>
      <td>Canada</td>
      <td>Sporting</td>
      <td>Water-resistant coat</td>
      <td>10</td>
      <td>11</td>
      <td>Large</td>
      <td>Moderate</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>8</td>
      <td>High</td>
      <td>Moderate</td>
      <td>30.0</td>
      <td>4</td>
    </tr>
    <tr>
      <th>104</th>
      <td>Otterhound</td>
      <td>England</td>
      <td>Hound</td>
      <td>Rough-coated</td>
      <td>7</td>
      <td>10</td>
      <td>Large</td>
      <td>Very High</td>
      <td>2.5</td>
      <td>Yes</td>
      <td>6</td>
      <td>High</td>
      <td>Moderate</td>
      <td>37.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>113</th>
      <td>Poodle (Standard)</td>
      <td>France</td>
      <td>Non-Sporting</td>
      <td>Curly coat</td>
      <td>9</td>
      <td>12</td>
      <td>Large</td>
      <td>Very High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>8</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>22.0</td>
      <td>5</td>
    </tr>
    <tr>
      <th>140</th>
      <td>Spinone Italiano</td>
      <td>Italy</td>
      <td>Sporting</td>
      <td>Shaggy coat</td>
      <td>7</td>
      <td>12</td>
      <td>Large</td>
      <td>High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>7</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>32.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>142</th>
      <td>Standard Poodle</td>
      <td>France</td>
      <td>Non-Sporting</td>
      <td>Intelligent</td>
      <td>9</td>
      <td>12</td>
      <td>Large</td>
      <td>Very High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>8</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>26.0</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell code" data-execution_count="20">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>cluster_1_rows <span class="op">=</span> df_new.iloc[index_1[<span class="dv">0</span>].tolist()]</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>cluster_2_rows <span class="op">=</span> df_new.iloc[index_2[<span class="dv">0</span>].tolist()]</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>cluster_3_rows <span class="op">=</span> df_new.iloc[index_3[<span class="dv">0</span>].tolist()]</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>cluster_4_rows <span class="op">=</span> df_new.iloc[index_4[<span class="dv">0</span>].tolist()]</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>cluster_5_rows <span class="op">=</span> df_new.iloc[index_5[<span class="dv">0</span>].tolist()]</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>cluster_6_rows <span class="op">=</span> df_new.iloc[index_6[<span class="dv">0</span>].tolist()]</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="21">
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>cluster_0_freq_size <span class="op">=</span> cluster_0_rows.Size.mode()</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cluster_0_freq_size)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>0    Large
Name: Size, dtype: object
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="22">
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>cluster_0_freq_int <span class="op">=</span> cluster_0_rows[<span class="st">&quot;Intelligence Rating (1-10)&quot;</span>].mode()</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cluster_0_freq_int)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>0    8
Name: Intelligence Rating (1-10), dtype: int64
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="23">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>cluster_1_freq_size <span class="op">=</span> cluster_1_rows.Size.mode()</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>cluster_1_freq_int <span class="op">=</span> cluster_1_rows[<span class="st">&quot;Intelligence Rating (1-10)&quot;</span>].mode()</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>cluster_2_freq_size <span class="op">=</span> cluster_2_rows.Size.mode()</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>cluster_2_freq_int <span class="op">=</span> cluster_2_rows[<span class="st">&quot;Intelligence Rating (1-10)&quot;</span>].mode()</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>cluster_3_freq_size <span class="op">=</span> cluster_3_rows.Size.mode()</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>cluster_3_freq_int <span class="op">=</span> cluster_3_rows[<span class="st">&quot;Intelligence Rating (1-10)&quot;</span>].mode()</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>cluster_4_freq_size <span class="op">=</span> cluster_4_rows.Size.mode()</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>cluster_4_freq_int <span class="op">=</span> cluster_4_rows[<span class="st">&quot;Intelligence Rating (1-10)&quot;</span>].mode()</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>cluster_5_freq_size <span class="op">=</span> cluster_5_rows.Size.mode()</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>cluster_5_freq_int <span class="op">=</span> cluster_5_rows[<span class="st">&quot;Intelligence Rating (1-10)&quot;</span>].mode()</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>cluster_6_freq_size <span class="op">=</span> cluster_6_rows.Size.mode()</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>cluster_6_freq_int <span class="op">=</span> cluster_6_rows[<span class="st">&quot;Intelligence Rating (1-10)&quot;</span>].mode()</span></code></pre></div>
</div>
<div class="cell code">
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>cluster_0_size_matches <span class="op">=</span> cluster_0_rows.loc[cluster_0_rows[<span class="st">&#39;Size&#39;</span>] <span class="op">==</span> cluster_0_freq_size.iloc[<span class="dv">0</span>]]</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>cluster_0_size_matches</span></code></pre></div>
<div class="output execute_result" data-execution_count="24">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Origin</th>
      <th>Type</th>
      <th>Unique Feature</th>
      <th>Friendly Rating (1-10)</th>
      <th>Life Span</th>
      <th>Size</th>
      <th>Grooming Needs</th>
      <th>Exercise Requirements (hrs/day)</th>
      <th>Good with Children</th>
      <th>Intelligence Rating (1-10)</th>
      <th>Shedding Level</th>
      <th>Health Issues Risk</th>
      <th>Average Weight (kg)</th>
      <th>Training Difficulty (1-10)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>Afghan Hound</td>
      <td>Afghanistan</td>
      <td>Hound</td>
      <td>Long silky coat</td>
      <td>5</td>
      <td>13</td>
      <td>Large</td>
      <td>Very High</td>
      <td>2.0</td>
      <td>No</td>
      <td>4</td>
      <td>High</td>
      <td>Moderate</td>
      <td>25.0</td>
      <td>8</td>
    </tr>
    <tr>
      <th>23</th>
      <td>Bouvier des Flandres</td>
      <td>Belgium</td>
      <td>Herding</td>
      <td>Beard and mustache</td>
      <td>7</td>
      <td>11</td>
      <td>Large</td>
      <td>Very High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>8</td>
      <td>High</td>
      <td>Moderate</td>
      <td>34.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Briard</td>
      <td>France</td>
      <td>Herding</td>
      <td>Long protective coat</td>
      <td>7</td>
      <td>12</td>
      <td>Large</td>
      <td>High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>8</td>
      <td>Moderate</td>
      <td>Low</td>
      <td>35.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>35</th>
      <td>Chesapeake Bay Retriever</td>
      <td>USA</td>
      <td>Sporting</td>
      <td>Waterproof coat</td>
      <td>7</td>
      <td>11</td>
      <td>Large</td>
      <td>Moderate</td>
      <td>2.5</td>
      <td>Yes</td>
      <td>7</td>
      <td>Moderate</td>
      <td>Low</td>
      <td>30.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>43</th>
      <td>Curly-Coated Retriever</td>
      <td>England</td>
      <td>Sporting</td>
      <td>Curly water-resistant coat</td>
      <td>7</td>
      <td>12</td>
      <td>Large</td>
      <td>Moderate</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>7</td>
      <td>Low</td>
      <td>Low</td>
      <td>32.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>58</th>
      <td>Flat-Coated Retriever</td>
      <td>England</td>
      <td>Sporting</td>
      <td>Shiny black coat</td>
      <td>9</td>
      <td>11</td>
      <td>Large</td>
      <td>Moderate</td>
      <td>2.5</td>
      <td>Yes</td>
      <td>8</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>32.0</td>
      <td>5</td>
    </tr>
    <tr>
      <th>62</th>
      <td>German Shorthaired Pointer</td>
      <td>Germany</td>
      <td>Sporting</td>
      <td>Versatile hunter</td>
      <td>8</td>
      <td>13</td>
      <td>Large</td>
      <td>Low</td>
      <td>2.5</td>
      <td>Yes</td>
      <td>8</td>
      <td>Moderate</td>
      <td>Low</td>
      <td>26.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>63</th>
      <td>German Wirehaired Pointer</td>
      <td>Germany</td>
      <td>Sporting</td>
      <td>Weather resistant coat</td>
      <td>7</td>
      <td>13</td>
      <td>Large</td>
      <td>Moderate</td>
      <td>2.5</td>
      <td>Yes</td>
      <td>8</td>
      <td>Moderate</td>
      <td>Low</td>
      <td>27.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>65</th>
      <td>Golden Retriever</td>
      <td>Scotland</td>
      <td>Sporting</td>
      <td>Golden coat</td>
      <td>10</td>
      <td>11</td>
      <td>Large</td>
      <td>High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>8</td>
      <td>High</td>
      <td>Moderate</td>
      <td>29.0</td>
      <td>4</td>
    </tr>
    <tr>
      <th>66</th>
      <td>Gordon Setter</td>
      <td>Scotland</td>
      <td>Sporting</td>
      <td>Black and tan coat</td>
      <td>8</td>
      <td>11</td>
      <td>Large</td>
      <td>High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>7</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>26.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>75</th>
      <td>Irish Red and White Setter</td>
      <td>Ireland</td>
      <td>Sporting</td>
      <td>Red and white coat</td>
      <td>8</td>
      <td>12</td>
      <td>Large</td>
      <td>High</td>
      <td>2.5</td>
      <td>Yes</td>
      <td>7</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>27.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>76</th>
      <td>Irish Setter</td>
      <td>Ireland</td>
      <td>Sporting</td>
      <td>Rich red coat</td>
      <td>8</td>
      <td>13</td>
      <td>Large</td>
      <td>High</td>
      <td>2.5</td>
      <td>Yes</td>
      <td>7</td>
      <td>High</td>
      <td>Moderate</td>
      <td>29.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>78</th>
      <td>Irish Water Spaniel</td>
      <td>Ireland</td>
      <td>Sporting</td>
      <td>Curly coat</td>
      <td>8</td>
      <td>11</td>
      <td>Large</td>
      <td>High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>7</td>
      <td>Low</td>
      <td>Low</td>
      <td>24.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>87</th>
      <td>Labrador Retriever</td>
      <td>Canada</td>
      <td>Sporting</td>
      <td>Water-resistant coat</td>
      <td>10</td>
      <td>11</td>
      <td>Large</td>
      <td>Moderate</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>8</td>
      <td>High</td>
      <td>Moderate</td>
      <td>30.0</td>
      <td>4</td>
    </tr>
    <tr>
      <th>104</th>
      <td>Otterhound</td>
      <td>England</td>
      <td>Hound</td>
      <td>Rough-coated</td>
      <td>7</td>
      <td>10</td>
      <td>Large</td>
      <td>Very High</td>
      <td>2.5</td>
      <td>Yes</td>
      <td>6</td>
      <td>High</td>
      <td>Moderate</td>
      <td>37.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>113</th>
      <td>Poodle (Standard)</td>
      <td>France</td>
      <td>Non-Sporting</td>
      <td>Curly coat</td>
      <td>9</td>
      <td>12</td>
      <td>Large</td>
      <td>Very High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>8</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>22.0</td>
      <td>5</td>
    </tr>
    <tr>
      <th>140</th>
      <td>Spinone Italiano</td>
      <td>Italy</td>
      <td>Sporting</td>
      <td>Shaggy coat</td>
      <td>7</td>
      <td>12</td>
      <td>Large</td>
      <td>High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>7</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>32.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>142</th>
      <td>Standard Poodle</td>
      <td>France</td>
      <td>Non-Sporting</td>
      <td>Intelligent</td>
      <td>9</td>
      <td>12</td>
      <td>Large</td>
      <td>Very High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>8</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>26.0</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell code" data-execution_count="31">
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>cluster_1_size_matches <span class="op">=</span> cluster_1_rows.loc[cluster_1_rows[<span class="st">&#39;Size&#39;</span>] <span class="op">==</span> cluster_1_freq_size.iloc[<span class="dv">0</span>]]</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>cluster_2_size_matches <span class="op">=</span> cluster_2_rows.loc[cluster_2_rows[<span class="st">&#39;Size&#39;</span>] <span class="op">==</span> cluster_2_freq_size.iloc[<span class="dv">0</span>]]</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>cluster_3_size_matches <span class="op">=</span> cluster_3_rows.loc[cluster_3_rows[<span class="st">&#39;Size&#39;</span>] <span class="op">==</span> cluster_3_freq_size.iloc[<span class="dv">0</span>]]</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>cluster_4_size_matches <span class="op">=</span> cluster_4_rows.loc[cluster_4_rows[<span class="st">&#39;Size&#39;</span>] <span class="op">==</span> cluster_4_freq_size.iloc[<span class="dv">0</span>]]</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>cluster_5_size_matches <span class="op">=</span> cluster_5_rows.loc[cluster_5_rows[<span class="st">&#39;Size&#39;</span>] <span class="op">==</span> cluster_5_freq_size.iloc[<span class="dv">0</span>]]</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>cluster_6_size_matches <span class="op">=</span> cluster_6_rows.loc[cluster_6_rows[<span class="st">&#39;Size&#39;</span>] <span class="op">==</span> cluster_6_freq_size.iloc[<span class="dv">0</span>]]</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="25">
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>cluster_0_int_matches <span class="op">=</span> cluster_0_rows.loc[cluster_0_rows[<span class="st">&quot;Intelligence Rating (1-10)&quot;</span>] <span class="op">==</span> cluster_0_freq_int.iloc[<span class="dv">0</span>]]</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>cluster_0_int_matches</span></code></pre></div>
<div class="output execute_result" data-execution_count="25">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Origin</th>
      <th>Type</th>
      <th>Unique Feature</th>
      <th>Friendly Rating (1-10)</th>
      <th>Life Span</th>
      <th>Size</th>
      <th>Grooming Needs</th>
      <th>Exercise Requirements (hrs/day)</th>
      <th>Good with Children</th>
      <th>Intelligence Rating (1-10)</th>
      <th>Shedding Level</th>
      <th>Health Issues Risk</th>
      <th>Average Weight (kg)</th>
      <th>Training Difficulty (1-10)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>23</th>
      <td>Bouvier des Flandres</td>
      <td>Belgium</td>
      <td>Herding</td>
      <td>Beard and mustache</td>
      <td>7</td>
      <td>11</td>
      <td>Large</td>
      <td>Very High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>8</td>
      <td>High</td>
      <td>Moderate</td>
      <td>34.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Briard</td>
      <td>France</td>
      <td>Herding</td>
      <td>Long protective coat</td>
      <td>7</td>
      <td>12</td>
      <td>Large</td>
      <td>High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>8</td>
      <td>Moderate</td>
      <td>Low</td>
      <td>35.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>58</th>
      <td>Flat-Coated Retriever</td>
      <td>England</td>
      <td>Sporting</td>
      <td>Shiny black coat</td>
      <td>9</td>
      <td>11</td>
      <td>Large</td>
      <td>Moderate</td>
      <td>2.5</td>
      <td>Yes</td>
      <td>8</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>32.0</td>
      <td>5</td>
    </tr>
    <tr>
      <th>62</th>
      <td>German Shorthaired Pointer</td>
      <td>Germany</td>
      <td>Sporting</td>
      <td>Versatile hunter</td>
      <td>8</td>
      <td>13</td>
      <td>Large</td>
      <td>Low</td>
      <td>2.5</td>
      <td>Yes</td>
      <td>8</td>
      <td>Moderate</td>
      <td>Low</td>
      <td>26.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>63</th>
      <td>German Wirehaired Pointer</td>
      <td>Germany</td>
      <td>Sporting</td>
      <td>Weather resistant coat</td>
      <td>7</td>
      <td>13</td>
      <td>Large</td>
      <td>Moderate</td>
      <td>2.5</td>
      <td>Yes</td>
      <td>8</td>
      <td>Moderate</td>
      <td>Low</td>
      <td>27.0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>65</th>
      <td>Golden Retriever</td>
      <td>Scotland</td>
      <td>Sporting</td>
      <td>Golden coat</td>
      <td>10</td>
      <td>11</td>
      <td>Large</td>
      <td>High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>8</td>
      <td>High</td>
      <td>Moderate</td>
      <td>29.0</td>
      <td>4</td>
    </tr>
    <tr>
      <th>87</th>
      <td>Labrador Retriever</td>
      <td>Canada</td>
      <td>Sporting</td>
      <td>Water-resistant coat</td>
      <td>10</td>
      <td>11</td>
      <td>Large</td>
      <td>Moderate</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>8</td>
      <td>High</td>
      <td>Moderate</td>
      <td>30.0</td>
      <td>4</td>
    </tr>
    <tr>
      <th>113</th>
      <td>Poodle (Standard)</td>
      <td>France</td>
      <td>Non-Sporting</td>
      <td>Curly coat</td>
      <td>9</td>
      <td>12</td>
      <td>Large</td>
      <td>Very High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>8</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>22.0</td>
      <td>5</td>
    </tr>
    <tr>
      <th>142</th>
      <td>Standard Poodle</td>
      <td>France</td>
      <td>Non-Sporting</td>
      <td>Intelligent</td>
      <td>9</td>
      <td>12</td>
      <td>Large</td>
      <td>Very High</td>
      <td>2.0</td>
      <td>Yes</td>
      <td>8</td>
      <td>Moderate</td>
      <td>Moderate</td>
      <td>26.0</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell code" data-execution_count="32">
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>cluster_1_int_matches <span class="op">=</span> cluster_1_rows.loc[cluster_1_rows[<span class="st">&quot;Intelligence Rating (1-10)&quot;</span>] <span class="op">==</span> cluster_1_freq_int.iloc[<span class="dv">0</span>]]</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>cluster_2_int_matches <span class="op">=</span> cluster_2_rows.loc[cluster_2_rows[<span class="st">&quot;Intelligence Rating (1-10)&quot;</span>] <span class="op">==</span> cluster_2_freq_int.iloc[<span class="dv">0</span>]]</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>cluster_3_int_matches <span class="op">=</span> cluster_3_rows.loc[cluster_3_rows[<span class="st">&quot;Intelligence Rating (1-10)&quot;</span>] <span class="op">==</span> cluster_3_freq_int.iloc[<span class="dv">0</span>]]</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>cluster_4_int_matches <span class="op">=</span> cluster_4_rows.loc[cluster_4_rows[<span class="st">&quot;Intelligence Rating (1-10)&quot;</span>] <span class="op">==</span> cluster_4_freq_int.iloc[<span class="dv">0</span>]]</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>cluster_5_int_matches <span class="op">=</span> cluster_5_rows.loc[cluster_5_rows[<span class="st">&quot;Intelligence Rating (1-10)&quot;</span>] <span class="op">==</span> cluster_5_freq_int.iloc[<span class="dv">0</span>]]</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>cluster_6_int_matches <span class="op">=</span> cluster_6_rows.loc[cluster_6_rows[<span class="st">&quot;Intelligence Rating (1-10)&quot;</span>] <span class="op">==</span> cluster_6_freq_int.iloc[<span class="dv">0</span>]]</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="33">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>cluster_0_total_size <span class="op">=</span> <span class="bu">len</span>(index_0[<span class="dv">0</span>])</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>cluster_0_match_size_len <span class="op">=</span> <span class="bu">len</span>(cluster_0_size_matches.index)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>cluster_0_size_accuracy <span class="op">=</span> cluster_0_match_size_len <span class="op">/</span> cluster_0_total_size</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The accuracy score of cluster 0 size feature: </span><span class="sc">{</span>cluster_0_size_accuracy<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>cluster_1_total_size <span class="op">=</span> <span class="bu">len</span>(index_1[<span class="dv">0</span>])</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>cluster_1_match_size_len <span class="op">=</span> <span class="bu">len</span>(cluster_1_size_matches.index)</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>cluster_1_size_accuracy <span class="op">=</span> cluster_1_match_size_len <span class="op">/</span> cluster_1_total_size</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The accuracy score of cluster 1 size feature: </span><span class="sc">{</span>cluster_1_size_accuracy<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>cluster_2_total_size <span class="op">=</span> <span class="bu">len</span>(index_2[<span class="dv">0</span>])</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>cluster_2_match_size_len <span class="op">=</span> <span class="bu">len</span>(cluster_2_size_matches.index)</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>cluster_2_size_accuracy <span class="op">=</span> cluster_2_match_size_len <span class="op">/</span> cluster_2_total_size</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The accuracy score of cluster 2 size feature: </span><span class="sc">{</span>cluster_2_size_accuracy<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>cluster_3_total_size <span class="op">=</span> <span class="bu">len</span>(index_3[<span class="dv">0</span>])</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>cluster_3_match_size_len <span class="op">=</span> <span class="bu">len</span>(cluster_3_size_matches.index)</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>cluster_3_size_accuracy <span class="op">=</span> cluster_3_match_size_len <span class="op">/</span> cluster_3_total_size</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The accuracy score of cluster 3 size feature: </span><span class="sc">{</span>cluster_3_size_accuracy<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>cluster_4_total_size <span class="op">=</span> <span class="bu">len</span>(index_4[<span class="dv">0</span>])</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>cluster_4_match_size_len <span class="op">=</span> <span class="bu">len</span>(cluster_4_size_matches.index)</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>cluster_4_size_accuracy <span class="op">=</span> cluster_4_match_size_len <span class="op">/</span> cluster_4_total_size</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The accuracy score of cluster 4 size feature: </span><span class="sc">{</span>cluster_4_size_accuracy<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>cluster_5_total_size <span class="op">=</span> <span class="bu">len</span>(index_5[<span class="dv">0</span>])</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>cluster_5_match_size_len <span class="op">=</span> <span class="bu">len</span>(cluster_5_size_matches.index)</span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>cluster_5_size_accuracy <span class="op">=</span> cluster_5_match_size_len <span class="op">/</span> cluster_5_total_size</span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The accuracy score of cluster 5 size feature: </span><span class="sc">{</span>cluster_5_size_accuracy<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a>cluster_6_total_size <span class="op">=</span> <span class="bu">len</span>(index_6[<span class="dv">0</span>])</span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a>cluster_6_match_size_len <span class="op">=</span> <span class="bu">len</span>(cluster_6_size_matches.index)</span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>cluster_6_size_accuracy <span class="op">=</span> cluster_6_match_size_len <span class="op">/</span> cluster_6_total_size</span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The accuracy score of cluster 6 size feature: </span><span class="sc">{</span>cluster_6_size_accuracy<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The accuracy score of cluster 0 size feature: 1.0
The accuracy score of cluster 1 size feature: 0.6071428571428571
The accuracy score of cluster 2 size feature: 0.6538461538461539
The accuracy score of cluster 3 size feature: 0.7777777777777778
The accuracy score of cluster 4 size feature: 0.5806451612903226
The accuracy score of cluster 5 size feature: 0.9130434782608695
The accuracy score of cluster 6 size feature: 0.9166666666666666
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="30">
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>cluster_0_match_int_len <span class="op">=</span> <span class="bu">len</span>(cluster_0_int_matches.index)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>cluster_0_int_accuracy <span class="op">=</span> cluster_0_match_int_len <span class="op">/</span> cluster_0_total_size</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cluster_0_int_accuracy)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>0.5
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="34">
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>cluster_0_match_int_len <span class="op">=</span> <span class="bu">len</span>(cluster_0_int_matches.index)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>cluster_0_int_accuracy <span class="op">=</span> cluster_0_match_int_len <span class="op">/</span> cluster_0_total_size</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The accuracy score of cluster 0 int feature: </span><span class="sc">{</span>cluster_0_int_accuracy<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>cluster_1_match_int_len <span class="op">=</span> <span class="bu">len</span>(cluster_1_int_matches.index)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>cluster_1_int_accuracy <span class="op">=</span> cluster_1_match_int_len <span class="op">/</span> cluster_1_total_size</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The accuracy score of cluster 1 int feature: </span><span class="sc">{</span>cluster_1_int_accuracy<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>cluster_2_match_int_len <span class="op">=</span> <span class="bu">len</span>(cluster_2_int_matches.index)</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>cluster_2_int_accuracy <span class="op">=</span> cluster_2_match_int_len <span class="op">/</span> cluster_2_total_size</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The accuracy score of cluster 2 int feature: </span><span class="sc">{</span>cluster_2_int_accuracy<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>cluster_3_match_int_len <span class="op">=</span> <span class="bu">len</span>(cluster_3_int_matches.index)</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>cluster_3_int_accuracy <span class="op">=</span> cluster_3_match_int_len <span class="op">/</span> cluster_3_total_size</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The accuracy score of cluster 3 int feature: </span><span class="sc">{</span>cluster_3_int_accuracy<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>cluster_4_match_int_len <span class="op">=</span> <span class="bu">len</span>(cluster_4_int_matches.index)</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>cluster_4_int_accuracy <span class="op">=</span> cluster_4_match_int_len <span class="op">/</span> cluster_4_total_size</span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The accuracy score of cluster 4 int feature: </span><span class="sc">{</span>cluster_4_int_accuracy<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>cluster_5_match_int_len <span class="op">=</span> <span class="bu">len</span>(cluster_5_int_matches.index)</span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>cluster_5_int_accuracy <span class="op">=</span> cluster_5_match_int_len <span class="op">/</span> cluster_5_total_size</span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The accuracy score of cluster 5 int feature: </span><span class="sc">{</span>cluster_5_int_accuracy<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a>cluster_6_match_int_len <span class="op">=</span> <span class="bu">len</span>(cluster_6_int_matches.index)</span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a>cluster_6_int_accuracy <span class="op">=</span> cluster_6_match_int_len <span class="op">/</span> cluster_6_total_size</span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The accuracy score of cluster 6 int feature: </span><span class="sc">{</span>cluster_6_int_accuracy<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The accuracy score of cluster 0 int feature: 0.5
The accuracy score of cluster 1 int feature: 0.7857142857142857
The accuracy score of cluster 2 int feature: 0.5769230769230769
The accuracy score of cluster 3 int feature: 0.5555555555555556
The accuracy score of cluster 4 int feature: 0.5806451612903226
The accuracy score of cluster 5 int feature: 0.391304347826087
The accuracy score of cluster 6 int feature: 0.375
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="37">
<div class="sourceCode" id="cb43"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The most common size for cluster 0 (red) is: </span><span class="sc">{</span>cluster_0_freq_size<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The most common size for cluster 1 (orange) is: </span><span class="sc">{</span>cluster_1_freq_size<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The most common intelligence for cluster 1 (orange) is: </span><span class="sc">{</span>cluster_1_freq_int<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The most common size for cluster 2 (yellow) is: </span><span class="sc">{</span>cluster_2_freq_size<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The most common size for cluster 3 (green) is: </span><span class="sc">{</span>cluster_3_freq_size<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The most common size for cluster 4 (blue) is: </span><span class="sc">{</span>cluster_4_freq_size<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The most common size for cluster 5 (purple) is: </span><span class="sc">{</span>cluster_5_freq_size<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The most common size for cluster 6 (magenta) is: </span><span class="sc">{</span>cluster_6_freq_size<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The most common size for cluster 0 (red) is: 0    Large
Name: Size, dtype: object
The most common size for cluster 1 (orange) is: 0    Small
Name: Size, dtype: object
The most common intelligence for cluster 1 (orange) is: 0    7
Name: Intelligence Rating (1-10), dtype: int64
The most common size for cluster 2 (yellow) is: 0    Medium
Name: Size, dtype: object
The most common size for cluster 3 (green) is: 0    Giant
Name: Size, dtype: object
The most common size for cluster 4 (blue) is: 0    Small
Name: Size, dtype: object
The most common size for cluster 5 (purple) is: 0    Medium
Name: Size, dtype: object
The most common size for cluster 6 (magenta) is: 0    Large
Name: Size, dtype: object
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Results and Analysis</p>
<ul>
<li>We found that the data of the dog breeds can be categorized into 7
clusters</li>
<li>The 7 clusters have a strong correlation with the size of the dog
breeds</li>
<li>There are a range of sizes that are similar to each other (large and
giant)</li>
<li>Versus some sizes very dissimilar to the large and giant dogs (small
and medium)</li>
<li>The orange and blue clusters which are most frequently represented
by small dogs are close together</li>
<li>The red, green and magenta clusters represent large dogs</li>
<li>The yellow and purple clusters represent medium dogs</li>
<li>The green cluster is located closest to the edge within all of the
large dog clusters which shows how it represents the giant dogs</li>
</ul>
</div>
</body>
</html>
